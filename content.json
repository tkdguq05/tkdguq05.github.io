{"pages":[{"title":"about","text":"","link":"/about/index.html"},{"title":"tags","text":"","link":"/tags/index.html"},{"title":"categories","text":"","link":"/categories/index.html"}],"posts":[{"title":"2019!","text":"첫 시작!데이터 사이언스 공부를 시작한지 1년이 훌쩍 넘었다. 기록을 하지 않으니까 정리도 되지않고 뭘 배웠는지도 잘 기억나지 않는다.꾸준히 기록해봐야겠다. 글을 꾸준히 쓰자 주 3회 목표","link":"/2019/01/11/2019/"},{"title":"Boosting","text":"부스팅 기법(Boosting)에 대해 알아보자Weak Learner부스팅 기법에 대해 알아보기 전에 알아야 할 몇가지 용어들이 있다. 그 중 하나가 Weak Learner이다.Weak Learner는 다른 말로 Simple Learner이라고도 불리우며, 간단한 학습기 정도로 보면 될 것이다. 대표적인 Weak Learner는 다음과 같다. Decision stumps : depth가 1인 decision tree Shallow decision trees Naïve Bayes Logistic regression 우리는 Weak Learner를 많이 가질 것이고, 많은 학습기들을 이용해서 예측작업을 할 것이다.Weak Learner들의 앙상블을 통해 어떤 결과를 예측해보려는 것이다. 이렇게 다수의 Weak Learner들을 이용해서 학습하면, input space의 다른 부분들을 보완해줄 수 있다. 부스팅에 대해서 공부할 때 배깅이 자주 등장하는데 차이를 비교해보자면 다음과 같다. Bagging 훈련 데이터에서 다수의 표본을 추출하고, 개별 트리의 결과를 병합하여 단일 예측 모델을 생성 각 bootstrap 과정이 독립적이므로 병렬 처리가 가능 Boosting Bagging과는 달리 순차적으로 시행되며 bootstrap 과정이 없음 Original dataset에서 약간의 수정을 거친 데이터를 개별적으로 학습한 후, 결합되어 강력한 분류기 생성 부스팅의 아이디어는 간단하다. 약한 학습기들을 이용해서 학습된 학습기들을 결합해 strong learner를 만드는 것이다. Classifier의 경우 학습기들의 결합방법은 Majority voting방식이 될 것이고, Regressor의 경우 학습기들의 결합방법은 평균이 될 것이다. 부스팅의 알고리즘도 심플하다. 앙상블 내, $t$번째 분류기 $c_t$와 $t+1$번째 분류기 $c_{t+1}$이 연관성을 가지고 생성하는 것이다. 훈련데이터 X의 샘플을 $c_t$가 옳게 분류하는 것과, 그렇지 않은 것으로 나눈다. 옳게 분류하는 샘플들은 인식이 가능하므로 가중치를 낮춘다. 틀리게 분류하는 샘플들은 가중치를 높인다. $c_{t+1}$학습시키기 위한 정책으로 sampling과정에서 가중치가 높은 샘플이 뽑힐 확률이 높아지게 한다. Ada Boost(Adaptive Boosting)Yoav Freund &amp; Robert Schapire가 제안하였고, Weak learner를 반복적으로 사용하고, 그 결과를 합하여 모델의 accuracy를 향상시킨다. AdaBoosting은 위에서 살펴본 알고리즘이 작동하는 방식과 거의 비슷하게 동작한다. 그림과 함께 살펴보자첫번째 그림에서 약한 학습기인, 결정 그루터기가 하나의 결정경계를 가지고 +와 -를 나누고 있다. 이렇게 나눴을 때 위쪽의 3개의 +들은 잘못 분류가 되어 가중치가 높아진다. 두번째 그림에서는 오른쪽의 - 두 개만 잘 분류가 되었고 결정경계 왼쪽의 대개의 -들은 잘못 분류가 되어버렸다. 이 역시 가중치가 높아지고 학습된 3개의 Weight를 결합해서 + -를 잘 분류해내는 하나의 강 분류기를 만들어낸다. 결국 Weak Learner들의 앙상블이다. 가중치 업데이트 규칙은 다음과 같다.$w^{(i)} = w^{(i)}$, $\\hat{y_j}{(i)}= y_{(i)}$ 일때$w^{(i)} = w^{(i)}exp(\\alpha_j)$, $\\hat{y_j}{(i)}\\neq y_{(i)}$ 일때그런 다음 모든 샘플의 가중치를 정규화 한다.(즉, $\\sum_{i}^{m}w^{(i)}$로 나눠준다.) 마지막으로 새 예측기가 업데이트된 가중치를 사용해 훈련되고 전체 과정이 반복된다. 새 예측기의 가중치가 계산되고 샘플의 가중치를 업데이트해서 또 다른 예측기를 훈련시키는 방식이다. Adaboost는 지정된 예측기 수에 도달하거나 완벽한 예측기가 만들어지면 중지된다. Adaboost의 예측은 $\\hat{y}(x)=\\sum_{i=1}^{N}\\alpha_j$로 이루어진다.($N$은 예측기의 수) Gradient Boosting그래디언트 부스팅은 Ada부스팅처럼 이전까지의 오차를 보정하도록 예측기를 순차적으로 추가한다. 하지만 Ada처럼 반복마다 샘플의 가중치를 수정하는 대신 이전 예측기가 만든 잔여 오차(residual error)에 새로운 예측기를 학습시킨다. 다시말해서 약한 분류기가 이전 학습에서 발견하기 어려웠던 문제성 관측값, 즉, 예측이 틀린 관측값에 집중하게 하는 것이다. 다른 boosting 기법처럼 모델을 단계적으로 구축해 나가는 것은 같지만 임의의 미분 가능한 손실 함수를 최적화하는 문제로 일반화한 방법이다. GB는 여러개의 간단한 모델의 ensemble을 학습한다. Motivation of Gradient Boosting($x_1$,$y_1$),($x_2$,$y_2$) …, ($x_n$,$y_n$) 총 n개의 데이터가 있고, 이 데이터를 이용하여 회귀모형 $F(x)$ 를 학습하는 프로젝트를 진행한다고 생각해보자. 팀원이 모델 $F$를 만들었다. 하지만 성능이 그다지 좋지 않다. $F(x_1)$ = 0.8의예측값을 생성한다. 하지만 실제 $y_1$ = 0.9이다. $y_2$ = 1.3인데, $F(x_2)$ = 1.4의 값이 나온다. 이 모델의 성능을향상시켜야 하는데 한가지 제약조건이 있다. 팀원이 만든 모델 $F$는 절대 건드리지 않고, 모델을 향상시켜야한다. 어떤 방법이 있을까? 방법은 간단하다. 원래 모델은 그냥 두고, 차이만큼을 더해주는 함수 $h(x)$를 만들어주면 되는 것이다.완벽하게 우리의 목적을 달성시키지는 못하지만, 근사적으로 달성할수는 있다. 그렇다면$h(x)$는 어떻게 구할 수 있을까?$h(x_1) = y_1 - F(x_1)$$h(x_2) = y_2 - F(x_2)$$…$$h(x_n) = y_n - F(x_n)$ 이므로,$(x1, y_1-F(x_1))$, $(x2, y_2-F(x_2))$,$…,$,$(x_n, y_n-F(x_n))$을 학습하면 된다. 학습데이터를 이용하여 75%정도의 정확도까지 모델을 학습하고, 나머지 미설명 부분은 오차항에 남겨둔다.$Y = F(x) + E$오차항을 이용하여 다른 모델을 학습시킨 후, 그 전 모델에서는 미설명 부분이었으나 이번 학습에서는 설명이 되는 부분을 찾아내 원 모델에 추가한다. 단, 추가 모델은 반드시 전체 정확도를 향상시켜야만 한다.$Gradeint(E) = G(x) + E2$ 모델이 약 80%의 정확도를 갖게 되면 식은 다음과 같게 된다.$Y + F(x) + G(x) + E2$ 이런 방법을 계속해서 사용해 나가고, GB는 단순 합보다 가중 평균을 사용하여(다른 모델보다 정확도가 높은 예측 결과를 가진 모델에 더 높은 중요도 점수를 부여) 모델의 정확도를 더 개선할 수 있다$Y=\\alpha{F(x)}+\\beta{G(x)}+\\gamma{H(x)} + E$ $…$ Gradient Boosting의 Loss Function손실 함수는 해결하려는 문제에 따라 다르다. 부스팅에서는 처음부터 최적화를 하는 것이 아니라, 각 단계별로 이전 단계에서 설명되지 못한 손실에 관해 최적화를 수행한다. 회귀 문제 : Least squares method (최소 자승법) 분류 문제 : Log loss function (로그 손실 함수) 손실 함수를 최소화하기 위해 약한 분류기를 추가할 가법 모델(additive model) 기존 트리는 변동이 없고 새로운 트리가 하나씩 추가된다. 기울기 하강 절차가 사용되어 트리가 추가될 때의 손실을 최소화한다. Leaf node마다 가중치, score가 부여가 된다. Gini계수 등을 사용하지 않는다.분류 / 회귀 : Sklearn에서는 (friedman) mse를 사용한다.","link":"/2019/05/15/Boosting/"},{"title":"Elice_Start","text":"엘리스 코딩을 구독했다.프로그래머스 문제를 쭉 풀면서, 코딩테스트를 몇번 보게 되면서 느낀 점은, 내가 알고리즘 기초가 부족하다는 것이었다. 문제를 보고 고민하는 시간이 너무 길었다. 고수들의 코드를 보면 고민한 시간은 잘 모르겠지만, 생각하는 방향이 딱딱 정해져서 배운 알고리즘과 자료구조 지식을 활용해서 답을 작성한 것이 눈에 띄었다. 반면에 나는 너무 막코딩하는게 아닌가 하는 생각이 들었다. 막코딩의 단점은 문제를 풀었어도 머리 속에 정리가 되지 않는다는 점이다. 머리에 남지 않으면 비슷한 문제가 나와도 틀릴 확률과 문제에 푸는 시간이 증가한다. 막코딩의 이러한 악효과를 차단하기 위해서 프로그래머스도 뒤져보고 엘리스도 뒤져보던 도중 엘리스의 프로그램 중 구독 시스템이 맘에 들어서 신청하게 되었다. 사실 엘리스는 양재 RNCD AI 실무자 양성 과정을 참여하고, 각종 무료 교육을 들으면서 친숙했다. 엘리스의 플랫폼에서는 메세지를 통해서 소통을 빠르게 할 수 있었던 것이 기억이 났다. 답답한 게 있으면 빠르게 물어보고 답을 얻어야 하는데 이런 점을 통해서 내가 원하는 바를 만족시킬 수 있을 것 같았다. 또한 개인적으로 문제를 다 풀고 100점이 나오면 토끼 애니메이션이 나오는데 이게 은근히 성취감을 불러일으킨다. 혼자 알고리즘 공부하다보면 문제를 깔끔하게 풀어도 ‘칭찬해 주는 사람도 없는데…’라는 생각이 항상 드는데, 토끼 애니메이션이 문제를 더 잘 풀고 싶게 하는 자극을 주는 게 참 맘에 들었다. 칭찬은 고래도 춤추게 한다고 하지 않은가. 나는 칭찬에 약하고 인정욕이 강한 동물이다. 어쨌든 큰 맘 먹고 10만원으로 퍼플키를 질렀다. 퍼플키를 지르게 되면 곧 튜터가 배정된다. 튜터는 쉽게 말해서 막히는 문제에 대해서 도움을 줄 수 있는 사람이다. 메세지를 통해서 소통하고, 문제가 있으면 답을 해준다. 아직 튜터에게 완전한 답을 받은 적은 없지만, 맘에 드는 시스템 중 하나다. 현재 수강 신청한 건 알고리즘 트랙(트랙으로 강의를 보거나, 구독을 하면 원하는 강의를 한달 동안 볼 수 있다.), 자료구조, 알고리즘1, 알고리즘2이다. 맘 같아서는 다 보고 싶은데, 실습 문제를 풀어야 하니 은근히 시간이 소요가 된다. 자료구조 먼저 끝내고 싶지만, 문제가 있는 것 같아서 알고리즘 트랙부터 끝내고 다른 강의들을 마저 들어야겠다.","link":"/2019/04/17/Elice-Start/"},{"title":"Information_Theroy_Entropy","text":"정보이론 기초, 정보량(Information)과 엔트로피(Entropy)에 대해 알아보자정보량 (Information)정보량은 말 그대로 얼마나 정보를 갖고 있는 지를 뜻하는 말이고 정보이론이란 불확실성을 다루는 학문이다. 하지만 일상에서 정보량에 대해서 접하기는 상당히 힘들고, 정보량이라는 단어를 일상에서 사용하는 사람은 매우 드물다. 알기 쉬운 예를 들어보자. 12간만에 친구들과 약속을 잡아서 놀기로 했다. 12일 13일 14일 15일 중으로 날짜를 잡기로 했고카카오톡 투표를 통해서 가장 많이 나온 날짜를 약속날로 잡자고 했다. 흔히 있는 상황이다. 약속날 후보로 5월 12일 13일 14일 15일이 있다고 해보자. 총 4개의 옵션이 있는 것이다. 근데 투표를 만든 사람이 자비롭게 중복투표를 허용해놨고, ‘음 난 다좋은데~’라고 생각하는 주관없는 친구가 모든 날짜를 다 눌러놨다고 생각해보자. 이 친구의 투표가 가진 정보량은 얼마일까?직관적으로 생각했을 때 0이다. 하지만 수학적으로 왜 그런 것일까? 정보량의 공식을 보자.정보량 $h(x) = \\sum_{x}log_2p(x)$ 이다. 이 공식을 토대로 주관없는 친구의 5월 12일 날짜에 대한 정보량을 구해보면,$p(x) = 1$이므로, $log_21 = 0$이란 값이 나온다.13일, 14일, 15일 모두 같은 결과가 나오고, 주관없는 친구의 투표에 대한 정보량은 0이다. 어떻게 보면 어떤 사람의 주관은 일정의 정보량을 뜻하는 듯하다. 아무거나 빌런은 결국 어떤 정보도 갖고 있지 않다는 것이다. 정보량은 여기서 주관을 뜻하기도 하지만, 보통 정보량은 놀라움의 정도를 뜻한다.축구 경기중에 골키퍼가 골을 넣는 사건은 굉장히 놀랍다. 이는 굉장히 정보량이 많다는 것을 뜻한다.왜냐면 정보량은 확률에 반비례하기 때문이다. 이번에는 예를 바꿔서, 우리가 쉽게 알 수 있는 주사위 case를 갖고 와 보자.주사위를 던져서 짝수가 나타날 사상 $E_1$의 정보량은 몇일까?공식에 의해서 $p(x) = {1\\over2}$이므로$P(E_1) = {1\\over2}\\longrightarrow I = -log_2{1\\over2}=1(bit)$ 가 된다. 엔트로피(Entropy)엔트로피는 흔히 열역학에서 자주 볼 수 있는 단어지만, 정보이론에서도 사용되는 말이기도 하다. 엔트로피라는 말에 대해서는 정보이론의 아버지인 Shannon이 정립하였다. 엔트로피의 공식을 먼저 확인해보자.$H(X) = -\\sum_{X}P(X)log_2P(X)$이다. 확률과 통계를 기본부터 잘 다져온 사람이라면 익숙한 공식이 눈에 들어올 것이다.바로 기댓값이다. 수식을 그럼 천천히 다시봤을때, 엔트로피 공식이 뜻하는 것은 바로 확률분포 $P(X)$에 대한 기댓값이다. 확률분포가 있어야 정의가 될 수 있다. 확률 분포의 불확실한 정도를 뜻하는 것이라고 생각하면 된다. 엔트로피는 정보이론에서 사용되는 단어이므로, 이 역시 불확실도를 나타내는 척도로 사용된다.직관적으로 이해하기 위해 그림을 통해 살펴보자. 위 그림에서 보면 왼쪽의 분포는 몰려있고, 즉 정규분포로 따지자면 표본오차가 작은 모양이고, 오른쪽의 분포는 넓게 퍼진, 표본오차가 매우 큰 모습이다. 정보이론을 따라 분포를 다시 보면 왼쪽의 그림은 불균형한 분포로 불확실성이 적은 모양이다. 다시말해 엔트로피 값이 낮은 분포이다. 반면에 오른쪽 그림은 균등한 분포이며, 어떤 값이 나올지 모르는, 불확실성이 높은 모양이다. 즉, 엔트로피 값이 높은 분포라고 할 수 있다. 결론적으로, 엔트로피는 확률분포 P(X)에서 일어날 수 있는 모든 사건들의 정보량의 기댓값으로, P(X)의 불확실성 정도를 평가하는 척도로 사용된다. 엔트로피와 관련된 것으로 크로스 엔트로피(Cross-Entropy)가 있는데, 이것은 다음 포스트에 적도록 하겠다. P.S 다시 엔트로피와 크로스 엔트로피에 대해 공부한 이유는, 면접을 최근에 보게 되었는데 이 부분에 대해서 제대로 공부를 하지 못해 대답을 우물쭈물 했기 때문이다. 데이터 사이언스를 공부하면서 느끼는 것은 항상 이런 것이다. 내가 진짜 알고있는지 아닌지 확인하기 어렵다는 것이다. 최대한 많이 부딪혀 봐야겠다. 그것이 캐글이 되었든, 아니면 면접이 되었든, 실제로 일을 하는 것이든, 직접 경험해 봐야 많이 필요성을 느낄 수 있고 많이 배울 수 있게 되는 것 같다.","link":"/2019/05/14/Information-Theroy-Entropy/"},{"title":"Elice_Coding_Word_Pattern","text":"엘리스 코딩 단어 패턴을 풀어봤다 단어 패턴 문자열(패턴) 하나와 문자열의 배열 하나가 주어집니다.패턴 문자열의 각각의 문자 하나는, 두번째 문자열 배열의 각각의 문자열 하나에 대응 될 수 있습니다.해당 배열이 해당 패턴으로 표현 되는지 아닌지의 여부를 확인하는 함수를 만들어 보세요. 예를 들어서, aabb 와 [‘elice’, ‘elice’, ‘alice’, ‘alice’] 가 주어졌을 경우에는 함수가 True를 반환해야 합니다. 이 경우에는 a가 elice에, b가 alice에 대응되도록 하면 배열을 해당 패턴으로 표현 하는 것이 가능하기 때문이죠. 반면, aabb 와 [‘elice’, ‘alice’, ‘elice’, ‘alice’] 가 주어졌을 경우에는 함수가 False를 반환해야 합니다.모든 문자는 영어 소문자라고 가정합니다. 문제를 보고 쉬울거라고 생각했다. 패턴을 쪼개서 각 단어에 매칭을 시켜주면 간단히 해결될 것 같았다.하지만 패턴을 쪼개서 단어에 매칭 시키는 게 간단한 문제가 아니었다. 지금은 a와 b뿐이지만 만약에 단어리스트가 주어지는개 100개라면 abcd…로 매칭시키는게 힘들다.물론 그 정도까지로 테스트 케이스가 나올 것 같지는 않지만… 따라서, 일일이 패턴을 매칭시켜서 판단하는 건 힘들다고 판단해서 이렇게 가는 건 아니라고 생각했고다른 방향을 모색했다. 그러던 중에 불현듯 패턴과 단어리스트를 zip해보고 싶어졌다. 일단 길이는 서로 무조건 같을 거니까.그리고 패턴이 일치하는 것을 찾는 거니까 set을 하면 의미있는 결과가 나올 듯 싶었다.코드와 결과는 다음과 같다.123pattern = \"aabb\"strList = [\"elice\", \"elice\", \"alice\", \"alice\"] 1set(zip(pattern, strList)) 1Out : {('a', 'elice'), ('b', 'alice')} 잘 생각해보니, set을 한 pattern하고 길이가 똑같을 것 같았다. 직관적으로 그런 생각이 들었다.일단 테스트로 다음과 같은 코드를 작성해봤다.12pattern1 = \"abab\"strList1 = \"elice\", \"elice\", \"alice\", \"alice\" 1set(zip(pattern1, strList1)) 1Out : {('a', 'alice'), ('a', 'elice'), ('b', 'alice'), ('b', 'elice')} 역시 단어리스트의 패턴이 다르면 주어진 패턴의 set과는 길이가 달랐다. 그래서 전체코드로는 다음과 같이 작성했다.1234567891011def wordPattern(pattern, strList): return len(set(pattern)) == len(set(zip(pattern, strList)))def main(): print(wordPattern(\"aabb\", [\"elice\", \"elice\", \"alice\", \"alice\"])) # should return True print(wordPattern(\"abab\", [\"elice\", \"elice\", \"alice\", \"alice\"])) # should return False if __name__ == \"__main__\": main() 제출결과 빵끗 웃는 토끼가 나왔고, 테스트 점수 100점이 나왔다.","link":"/2019/04/17/Elice-Coding-Word-Pattern/"},{"title":"Programmers 124 나라의 숫자를 풀어보자","text":"프로그래머스 코딩테스트 연습문제 124 나라를 풀어봤다124 나라참고[https://thisisablog.tistory.com/14]124 나라가 있습니다. 124 나라에서는 10진법이 아닌 다음과 같은 자신들만의 규칙으로 수를 표현합니다. 124 나라에는 자연수만 존재합니다.124 나라에는 모든 수를 표현할 때 1, 2, 4만 사용합니다.예를 들어서 124 나라에서 사용하는 숫자는 다음과 같이 변환됩니다. 10진법 124 나라 1 1 2 2 3 4 4 11 5 12 6 14 7 21 8 22 9 24 10 41 자연수 n이 매개변수로 주어질 때, n을 124 나라에서 사용하는 숫자로 바꾼 값을 return 하도록 solution 함수를 완성해 주세요. 문제를 보고 패턴을 찾아야겠다는 생각부터 했다.3의 배수로 끊어지고, 끝자리가 1, 2, 4로 반복된다는 것을 파악했다. 끝자리는 그럼 1,2,4를 돌려주는 것으로 끝낼 수 있는데, 이제 앞자리가 문제가 된다.앞자리 패턴을 찾기 위해서 문제 표에는 10까지만 나와있지만, 21까지 구해봤다.21까지 쭉 따라 쓰다보니, 앞자리 역시 1,2,4가 반복되고 있다는 것을 파악했다.맨 뒷자리 1,2,4가 끝나면 그 다음 자리 index가 하나 올라가고 그 앞의자리도 마찬가지였다. 그렇다면, 뒤에서부터 자리 수를 채워주는 게 낫다고 생각했고다 채워준 다음에 뒤집어 버리는 방식을 택했다.그래서1[::-1] 을 이용해 줬고 코드는 다음과 같이 작성했다. 1234567891011121314151617181920212223def solution(n): if n&lt;3: return n elif n==3: return 4 result='' index=['4','1','2'] rem=0 quo=0 while n&gt;3: rem=n%3 quo=n//3 print(rem,quo) result+=index[rem] print('res = ',result) if rem==0: quo-=1 n=quo print('n={}, rem={}, result={}'.format(n, rem, result)) result+=str(n) result=result.replace('3','4') return result[::-1]","link":"/2019/02/25/Programmers/"},{"title":"Time Series Analysis Begins","text":"Dive into 시계열 데이터 분석시계열 데이터 분석에 대해서 공부해보자!저번 주부터 고대하던 시계열 분석에 대해서 본격적으로 공부해보게 되었습니다. 공부한 내용에 대해서 차근차근 정리를 해보는 시간을 갖겠습니다. 분석적 사고의 필요성시계열 분석에 앞서 강조하는 부분이 있었습니다. 데이터 분석에는 6가지 사이클이 있습니다. 문제정의 데이터 수집 데이터 전처리 데이터 정리 데이터 분석 결과 정리 그 중 가장 중요한 것은, 데이터 분석이 아니라 분석적 사고의 필요성입니다. 특히 데이터 사이언티스트에게 중요한 덕목으로서 강사님께서 강조해 주셨는데요, 결국은 문제 정의를 잘하는 것이 중요하다는 것이었습니다. 문제가 잘 정의되면 데이터를 어디서 갖고 올지 어떤 알고리즘을 사용할지 등이 정리가 될 수 있습니다. 사실 캐글 = 데이터사이언스로 보는 사람들이 많은데, 엄밀히 따지면 캐글은 알고리즘을 공부할 수 있는 대회일 수 있습니다. 이미 사전에 문제정의가 끝나고 데이터를 잘 모으고 정리되어서 캐글쪽에 전달되기 때문에 정말 필요한 능력인 문제정의 능력을 키우기는 힘들 수 있습니다.(개인적으로 가장 신선한 충격을 받았던 설명이었습니다) 문제 정의 후에는 이것을 고객들이나 관리자에게 잘 전달해주어야 합니다. 그래서 중요한 것은 설득 및 설명 능력입니다. 사실, 데이터분석 관련지식(이론), 프로그래밍 활용능력(실습) 등은 금방 늘어날 수 있는 능력이지만, 잘 설득하고 이해하기 쉽도록 설명하는 능력은 정말 키우기 어렵습니다. 어쩌면 데이터 사이언티스트에게 커뮤니케이션 능력은 잘 키울 수 없기에 더 중요하지 않을까 생각되기도 합니다. 정확한 문제 정의의 중요성앞서 말씀 드린 것처럼, 정확하게 문제를 정의하고 분석을 시작해야 합니다. 이를 위해서는 가설을 설정하고 검정하는 것이 필요하게 됩니다. 가설 설정의 세가지 조건은 다음과 같습니다. 가설 설정 세가지 조건 상호배반적 증명가능성 구체성 상호배반성은 나의 주장과 대립 주장이 모호함이 없어야 한다는 것으로, 서로 겹치는 영역이 없어야 된다는 것을 말합니다. 증명가능성은 성급화 일반화에 빠지지 않기 위해서는 증명 가능한 것이나, 범위로 내세워야 한다는 것을 말합니다. 마지막으로 구체성은 충분히 구별되고 실현가능한 표현으로 정의되어야 한다는 것입니다. 검정가설을 세웠으면, 이제 그 가설이 맞는지 검정을 해야 합니다. 주의해야할 점은 모집단에 대한 것입니다. 모집단은 논란이 있을 수 있지만, 관찰이 불가능한 것입니다. 이상적인 샘플 집단이기 때문입니다. 그렇기 때문에 우리는 항상 샘플을 갖고 분석을 할 수 밖에 없습니다. 샘플에 Bias가 있다면, Bias를 제거하고 사용합니다. 귀무가설과 대립가설은 통계에서 정말 자주 등장하는 개념입니다. 하지만 익숙하지 않은 단어들이기 때문에 항상 헷갈리는에요, 귀무가설은 기존의 주장(대립 주장), 대립가설은 내 주장 이라고 생각하면 사고하기 편리합니다. 귀무가설과 대립가설을 세웠다면, 이제 통계량을 보고 어떤 가설이 맞는지 확인해야 합니다. 이때 우리가 확인하는 통계량을 검정 통계량이라고 합니다. 대립가설과 귀무가설을 비교하기 위한 검증지표값으로 흔히 ‘점추정’이라고 부릅니다. 검정통계량이 발생가능한 구간에 대해서도 용어가 정리되어 있는데, 이것을 신뢰 구간이라고 부릅니다. 또 귀무가설이 참일 때 검정통계량으로 대립가설이 발생활 확률을 말하는 p-value가 있습니다. 일반적으로 p-value 기준으로 0.05보다 크면 대립가설을 기각하고, 0.05보다 작으면 대립가설을 채택합니다. 통계량분석 단계별 의사결정을 위해서는 수학/통계적 언어를 이해하는 것이 필요합니다. 변동/산포 특성, 지표의 변동성을 나타내는 통계량에는 분산과 표준편차가 있습니다. 분산은 편차제곱의 합을 데이터의 수로 나눈 값이고, 표준편차는 분산에 루트를 씌운 값입니다. (참고로 편차는 관측값과 평균의 차이입니다) 분포의 형태 특성을 나타내는 것으로는 대표적으로 Skewness와 Kurtosis가 있습니다. 왜도와 첨도라고 부를 수 있습니다. 왜도는 평균을 중심으로 데이터가 좌우로 편향되어 있는 정도를 말하고, 첨도는 뾰족한 정도로, 사실 더 중요한 것은 tail의 fat함을 보는 데 사용될 수 있습니다. fat-tail하다면 정규성 가정이 깨지게 되므로(정규성 가정 중 하나 : 분포의 tail은 슬림하다, kurtosis값은 0에 가까울 수록 좋다) 만든 모델이 제대로 작동하지 않을 가능성이 높습니다. 시계열 데이터와 횡단면 데이터이제 데이터에 대한 얘기를 시작하겠습니다. 횡단면 자료(Cross-Sectional data)는 일정시점에서 하나 이상의 변수에 대해 수집된 자료를 말합니다. (예: 2016년 전국 16개 시도의 GRDP와 최종소비) 시계열 데이터는 일별, 주별, 월별, 분기별, 연도별 등 시간에 걸쳐 수집한 자료로 거시경제변수를 측정한 자료에서 많이 발생하는 데이터 입니다. 시계열 데이터는 보통의 데이터에 비해서 레코드(또는 로우)에 타임스탬프 또는 각 시간구간에 따른 집계 레벨(분별, 시간대별, 일별, 주별, 월별, 분기별, 년도별)에 대한 순서가 있는 시간값을 함께 가지고 있습니다. 시계열 데이터는 횡단면 데이터에 비해 고려해야 할 시간축이 하나 더 있는 것이 문제이며 시간축이 선후관계를 가지는 것, 그리고 시간축에 대한 것을 드릴다운하거나 다시 롤업(roll-up)해서 집계 응집도를 높여야 할 수 있습니다.http://intothedata.com/02.scholar_category/timeseries_analysis/ 시계열 데이터 분석을 위한 준비는 이것으로 어느정도 마무리 된 것 같습니다. 이외에도 Anaconda 설정이나, Numpy, Pandas를 다루는 부분이 있지만 블로그 글에서는 생략하겠습니다. 다음 포스팅 부터는 본격적인 시계열 데이터의 계절성이나 주기의 차이점, Residual을 주의깊게 관찰해야 하는 이유 등에 대해서 다뤄보겠습니다.","link":"/2019/08/25/Time-Series-Begins/"},{"title":"Fearuture_Selection_Information_Value","text":"Feature Selection에 Information Value를 이용해보자.Information Value를 이용한 방법 Kaggle이나 데이터 분석을 하다보면 성능을 높이기 위해 여러가지 feature들을 만들어낸다. 그런데 feature를 무조건 많이 만든다고 성능이 올라갈까? 아니다. target에 대한 영향력이 큰 feature들이어야 성능에 영향을 줄 수 있을 것이다. 그렇다면 중요한 건, 만들어낸 feature들을 어떻게 평가할 것인가이다. Kaggle에서 Feature Selection 하는 방법들을 보면 gbm모델들의 Feature Importance를 이용하거나 DecisionTree나 RandomForest의 Classifier 객체의 feature_importances_ 메서드를 활용해 Feature Importance를 구해서 비교하는 모습들이 자주 보인다. 하지만 또 다른 방법으로, Information Value를 이용한 Feature Selection을 소개해보고자 한다. 1. Information Value (정보 가치)모델에서 변수의 사용유무를 판단하는 feature selection에서 유용한 방법이다. 주로 모델을 학습하기전 첫 단계에서 변수들을 제거하는 데 사용한다. 최종 모델에서는 대략 10개 내외의 변수를 사용하도록 한다(여러개 만들어 보고 비교해보는 것이 좋다). IV와 WOE 신용채무능력이 가능한(good) 고객과 불가능한(bad) 고객을 예측하는 로지스틱 회귀 모델링과 밀접한 관계가 있다. 신용 정보 관련분야에서는 good customer는 부채를 갚을 수 있는 고객, bad customer는 부채를 갚을 수 없는 고객을 뜻한다. 일반적으로 이야기할 때는 good customer는 non-events를 의미하고 bad customer는 events를 의미한다. 신용 관련 분야 ${WOE} = ln{\\frac{\\text{distribution of good}}{\\text{distribution of bad}}}$ ${IV} = \\sum{(\\text{WOE} \\times (\\text{distribution of good} - \\text{distribution of bad}))}$ 일반적 ${WOE} = ln{\\frac{\\text{distribution of non-events}}{\\text{distribution of events}}}$ ${IV} = \\sum{(\\text{WOE} \\times (\\text{distribution of non-events} - \\text{distribution of events}))}$ Information Value 값의 의미 Information Value 예측력 0 to 0.02 무의미 0.02 to 0.1 낮은 예측 0.1 to 0.3 중간 예측 0.3 to 0.5 강한 예측 0.5 to 1 너무 강한 예측(의심되는 수치) Information Value를 통해서 ‘이 feature를 꼭 사용해야하나?’에 대해 어느정도 답을 내릴 수 있다. Information Value가 0.5~1.0인 구간을 보면, 강한 예측이지만 의심되는 수치라고 되어있다. 처음보면 이게 무슨 의미인지 잘 이해가 안될 것이다. ‘너무 예측을 잘하는데 수치를 의심하라고?’ 하지만 잘 생각해보자. IV는 WOE를 활용한다. WOE는 good과 bad의 분포를 이용하는데, 데이터가 good으로 쏠려있을 경우 WOE는 무조건 잘 나올 수 밖에 없고, 이에 따라 IV값도 잘 나오게 된다. 따라서, IV의 값을 볼 때는 데이터가 어떻게 되어있는지 먼저 살펴보는 게 중요하다. 2. German Credit Data 이용해보기12path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data'dataset = pd.read_csv(path, delimiter=' ', header=None) Column이 제대로 되어있지 않기 때문에 노가다로 넣어준다.1234567891011121314151617181920212223COL = [ 'Status_of_existing_checking_account', 'Duration_in_month', 'Credit_history', 'Purpose', 'Credit_amount', 'Savings_account_bonds', 'Present_employment_since', 'Installment_rate_in_percentage_of_disposable_income', 'Personal_status_and_sex', 'Other_debtors_guarantors', 'Present_residence_since', 'Property', 'Age_in_years', 'Other_installment_plans', 'Housing', 'Number_of_existing_credits_at_this_bank', 'Job', 'Number_of_people_being_liable_to_provide_maintenance_for', 'Telephone', 'foreign_worker', 'Target'] Target값을 0, 1로 만들어준다.1dataset['Target'] = dataset['Target'] - 1 Information Value를 구하는 코드12345678910111213141516171819202122232425262728293031max_bin = 10 # 전체 데이터의 예측력에 해를 가하지 않는 한에서 구간을 테스트하였습니다. 통상적으로 10개로 나눔, 15개 20개 다 나눠보고# 값이 잘나오는 bin을 선택함def calc_iv(df, col, label, max_bin = max_bin): \"\"\"IV helper function\"\"\" bin_df = df[[col, label]].copy() # Categorical column if bin_df[col].dtype == 'object': bin_df = bin_df.groupby(col)[label].agg(['count', 'sum']) # Numerical column else: bin_df.loc[:, 'bins'] = pd.qcut(bin_df[col].rank(method='first'), max_bin)# bin_df.loc[:, 'bins'] = pd.cut(bin_df[col], max_bin) bin_df = bin_df.groupby('bins')[label].agg(['count', 'sum']) bin_df.columns = ['total', 'abuse'] bin_df['normal'] = bin_df['total'] - bin_df['abuse'] bin_df['normal_dist'] = bin_df['normal'] / sum(bin_df['normal']) bin_df['abuse_dist'] = bin_df['abuse'] / sum(bin_df['abuse']) bin_df['woe'] = np.log(bin_df['normal_dist'] / bin_df['abuse_dist']) bin_df['iv'] = bin_df['woe'] * (bin_df['normal_dist'] - bin_df['abuse_dist']) bin_df.replace([np.inf, -np.inf], 0, inplace=True) bin_df = bin_df[bin_df['total'] &gt; 0] iv_val = sum(filter(lambda x: x != float('inf'), bin_df['iv'])) return bin_df, col, iv_val``` ```pythonch_df, ch, ch_i_val = calc_iv(dataset,'Credit_history', 'Target')ch_df total abuse normal normal_dist abuse_dist woe iv Credit_history A30 40 25 15 0.021429 0.083333 -1.358123 0.084074 A31 49 28 21 0.030000 0.093333 -1.134980 0.071882 A32 530 169 361 0.515714 0.563333 -0.088319 0.004206 A33 88 28 60 0.085714 0.093333 -0.085158 0.000649 A34 293 50 243 0.347143 0.166667 0.733741 0.132423","link":"/2019/04/25/Fearuture-Selection-Information-Value/"},{"title":"My SQL Workbench Bug issue","text":"MySQL Workbench에서 쿼리를 날렸는데 결과창이 안나온다면!, For MAC OSXsource from : [https://stackoverflow.com/questions/45967413/results-grid-not-showing-on-mysql-workbench-6-3-9-for-macos-sierra]Thank you Yogev! 빅데이터 시대에 SQL공부가 필수적이다. 머신러닝, 딥러닝 뭐 할게 너무 많지만 일단 데이터를 이해하기 위해서는 SQL공부를 먼저 해야한다고 생각한다. 이런 마음에 SQL을 공부하기로 마음먹고 세달전에 샀던 데이터 분석을 위한 SQL 레시피를 다시 폈더랬다. 책은 매우 훌륭했다. 기본적인 SQL뿐 아니라, 내가 관심있었던 SparkSQL, Big Query에 대해서도 다뤄주고 있었다. 눈으로 SQL을 슬슬 할 때쯤, SQL을 직접 입력해보고 결과를 보고 싶어졌다. 소스코드가 있나 뒤져봤더니, 한빛 미디어에서 제공해 주는 코드가 있었다. 신나게 받아놓고 1년전에 세팅해둔 Mysql 서버를 실행시켰다. 뭐 잡 에러 덩어리가 많았지만 우여곡절 끝에 해결하고 드디어 MySQL Workbench로 들어가서 쿼리를 날렸다. Success!가 나왔다. 음, 근데 결과창이 보이지 않는다. 바로 StackOverFlow를 뒤져봤다.쿼리 옆에 있는 돋보기를 눌러보고 Result Grid를 눌러보랜다. 안된다. Mac에 있는 버그라며 쿼리 박스에 마우스를 신중히 갖다대고 바를 늘려보랜다. 회색화면만 나온다. 껐다 다시 키면 될 것이란다. 바뀐 게 없다. 아, 모든 게 거짓말 같았다. 오늘은 만우절ㅎㅎ* 이렇게 6시간 넘게 삽질을 지속하다가, 빛 갓 Yogev의 Stackoverflow 글을 보게 되었다. 요약하자면 수정된 버전이 올라와 있다는 말이다.‘아니 최신 버전을 받았는데 왜 또 안됐었던 거지???’ 이해가 안되긴 하지만빛요게프 선생님께서는 친절히 공유경제의 장점에 대해 설파하고 계시었다. upvote를 찍어드리기 위해서 stackexchange에 가입했고 upvote를 꾸우우욱 눌러드렸다. 해결방법 : [https://dev.mysql.com/downloads/workbench/] 다운 후그대로 덮어쓰기 (Workbench 삭제 안해도 된다!)","link":"/2019/04/01/My-SQL-Workbench-Bug-issue/"},{"title":"SQL_Recipe_01","text":"데이터 분석을 위한 SQL 레시피 with MySQL데이터 분석을 위한 SQL 레시피의 3장에 있는 코드 내용들을 실습하고 MySQL코드로 변형시켜보았다.데이터 분석을 위한 SQL 레시피 책에서는 PostgreSQL, Redshift, BigQuery, Hive, SparkSQL의 코드를 다룬다. 책에 있는 코드는 어떤 건 그대로 쳤을 때 돌아가고, 몇몇 개는 MySQL 쿼리대로 수정을 해주어야 한다. 3장의 mst_users_with_dates 테이블을 가지고 실습을 진행한다.실습 진행 전에 테이블을 만들어준다. 123456DROP TABLE IF EXISTS mst_users_with_dates;CREATE TABLE mst_users_with_dates ( user_id varchar(255) , register_stamp varchar(255) , birth_date varchar(255)); 1select * from mst_users_with_dates; 위 코드로 테이블이 잘 만들어졌는지 확인해본다. 잘 만들어졌으면, 데이터를 삽입한다.123456INSERT INTO mst_users_with_datesVALUES ('U001', '2016-02-28 10:00:00', '2000-02-29') , ('U002', '2016-02-29 10:00:00', '2000-02-29') , ('U003', '2016-03-01 10:00:00', '2000-02-29'); 먼저 날짜 데이터들의 차이를 계산해보자. 현재 날짜와 등록한 날짜를 빼주는 방식이다.1234select user_id, CURRENT_DATE AS today, date(timestamp(register_stamp)) AS regitser_date,datediff(CURRENT_DATE(), date(register_stamp)) AS diff_daysfrom mst_users_with_dates ; 이렇게 만들어주면 원하는 결과가 나온다. 책에 있는 결과와 조금은 다를 수 있는데, 왜냐하면 CURRENT_DATE를 하면 현재의 날짜를 가져와 주기 때문에, 책에 있는 2017-02-05가 아니라, 지금 작성하고 있는 2019-05-21로 계산된다. 여기까지는 datediff함수가 MySQL에도 있기 때문에 책에 있는 그대로 쳐도 잘 돌아간다. 이번에는 사용자의 생년월일로 나이를 계산해보자.나이를 계산하기 위한 전용함수가 구현되어 있는 것은 PostgreSQL뿐이다. PostgreSQL에는 age함수가 구현이 되어있어 편하게 나이를 구할 수 있다. MySQL의 경우에는 책에 있는 코드를 MySQL의 언어로 변형시켜 주어야 한다. 12345SELECT user_id, CURRENT_DATE AS today, date(register_stamp) as register_date, birth_date,(YEAR(CURRENT_DATE)-YEAR(birth_date))- (RIGHT(CURRENT_DATE,5)&lt;RIGHT(birth_date,5)) AS age,(YEAR(register_stamp)-YEAR(birth_date))- (RIGHT(register_stamp,5)&lt;RIGHT(birth_date,5)) AS register_ageFROM mst_users_with_dates; 책에 있는 코드와 다른점은 EXTRACT를 사용하지 않았다는 것이다. MySQL에는 EXTRACT가 없기 때문에 년도를 이용해 일일이 계산해 주어야 한다. YEAR함수를 이용해 년도만 가져와서 계산해준다. 주의해야 할 점은, YEAR함수에 today를 넣어주는 게 아니라 CURRENT_DATE를 넣어주어야 한다는 것이다. today를 넣어주면 syntax에러가 발생한다. 하지만 YEAR로 계산한 경우 연 부분만의 차이가 계산되므로, 해당 연의 생일을 넘었는지 제대로 계산이 되지 않는 문제가 발생한다. 12345SELECT user_id,substring(register_stamp, 1, 10) as register_date, birth_date, floor(( cast(replace(substring(register_stamp, 1,10), '-', '') AS unsigned) - cast(replace(birth_date, '-', '') AS unsigned)) / 10000) as register_age, floor(( cast(replace(CAST(CURRENT_DATE as signed), '-', '') as unsigned) - cast(replace(birth_date, '-', '') AS unsigned)) / 10000) as current_agefrom mst_users_with_dates; 이 코드로 실행시켜주면 문제가 해결된다. MySQL에서는 CAST함수 실행시에 주의해야 할 점이 있는데, 보통 프로그래밍 언어에서는 Integer나 String등으로 타입을 정해주는데, MySQL에서는 UNSIGNED—&gt;INTEGER이고, SIGNED—&gt;STRING임을 명심해야 한다. 코드를 바꿔주고 실행하면 문제없이 돌아가는 것을 확인할 수 있다.","link":"/2019/05/21/SQL-Recipe-01/"},{"title":"글또 3기에 들어서면서... 상반기 회고와 다짐","text":"상반기 회고와 나의 다짐상반기 회고 (2019.01.01 ~ 2019.06.24, 도서관)새해 첫 날은 스페인에서 보냈었네요, 공부만 하다가 처음으로 짬이 나서! 계획했었던 영국~스페인 여행을 2주일 정도 갔었습니다. 항상 아침에 조깅을 하면서 ‘한국 돌아가서 뭘해볼까…’ 이런 고민들을 했었고 그 중 제일 처음으로 해야겠다고 생각했던 것이 블로그였습니다. 일단 블로그부터 제대로 구축하자! 라는 계획으로 hexo 블로그를 만들었고, 여러 테마들을 돌려보면서 괜찮은 것들을 살펴봤습니다. 한 한달정도 블로그랑 씨름하다보니 어느정도 구축이 되었고, 배운 내용들을 글로 정리하기 시작했습니다. 사실 올해에는 취업 생각이 없었습니다. 데이터 이론이나 알고리즘 등 준비해야 할 것도 많다고 생각했고, 개인 프로젝트도 더 필요하다고 느꼈습니다. 하지만 3월에 상반기 대기업 취업 공고가 나니까 마음이 급해지기 시작했죠. ‘내가 공부는 정말 많이 했지만 내가 진짜 제대로 알고 있는걸까?’, ‘이 상태로 취업은 가능할까?’, ‘공부를 이렇게 하는게 맞나?’ 이런 고민들이었습니다. 이런 고민들로 3월부터 6월 동안 취업준비를 급하게 시작했습니다. 결국 데이터 관련 일은 데이터를 직접 만져봐야 얻는 게 있다는 결론을 내렸기 때문입니다. 이력서도 많이 쓰고 면접도 많이 봤습니다. 첫 면접부터 마지막 면접까지 하나하나 기억이 다 나네요, 쓰라렸지만 좋은 경험을 많이 했다고 생각합니다. 사실 상반기 회고를 하면서 면접에 관해서 글이 길어졌는데, 너무 무거운 내용들이 많아서 일단 나중에 정리해서 업로드 할 생각입니다. 이번 글은 조금 가벼운 느낌으로! 그래서 상반기 회고를 다시 하자면 저는 도서관에서 거의 살았었습니다. 아침 일찍 나가서 저녁 늦게 까지 책을 쌓아놓고 노트북 두들기면서 한 자리에만 있었습니다. 그때 공부를 하면서 느낀 건 공부를 오래하고 싶더라도 체력이 부족하면 불가능 하다는 것이었습니다. 운동도 시작했고, 식단 조절도 해보면서 건강을 챙겼습니다. 우연히 운동 좋아하는 후배들을 알게 되면서 좋은 습관들을 쌓게 된 것 같네요. 글쓰는 습관취업 준비도 준비지만 또 다른 좋은 습관을 들이려고 노력한 것은 글쓰는 습관이었습니다. 배운 내용을 혼자 공부해서 갖고 있는 것보다, 글을 쓰고 공유하고, 얘기하는 것이 저에게 훨씬 더 큰 가치를 가져다 줄 수 있겠구나 하는 생각이 들었습니다. 부족하지만 이론을 정리한 걸 글로 작성하고, 알고리즘 문제 푼 것들도 어떤 생각의 흐름으로 풀었는지 기록했습니다. 이외로 면접 준비하면서 이걸 다시 보게 되니까 정리하는데 도움이 많이 되는 것 같았습니다. 특히 이론에 관해서 글을 쓸때는 완벽하게 알지 못하면 글을 쓰지 못하기 때문에, 어디가 부족한지 스스로 알 수 있게 되어서 더 좋은 것 같습니다. 그 외에 상반기에 했던 것들은 다 취업 준비가 대부분이었던 것 같네요. 회고를 해보니 너무 정신없이 살았던 것 같습니다. 정리 안되고 정신없는 거 별로 안 좋아하는데 상반기를 정리해보니 제 자신이 정리 안하고 살았었네요. 하반기에는 계획을 제대로 세워서 하나씩 클리어 하는 재미로 살아봐야겠습니다. 상반기 회고를 두 번 해보니 얻어지는 것이 있었습니다. 사실 취업준비를 하면서 많이 지쳤었거든요, 데이터 얘기만 들어도 싫고, 개발이나 알고리즘, 코드만 봐도 어지럽고 도망치고 싶었습니다. 하지만 취업도 했고, 상반기를 냉철하게, 처절하게 다시 들여다보고 나니, 다시 시작할 힘이 나는 느낌입니다. 바닥에 다시 내려왔고, 어디부터 공부를 해야할지 이제 감이 잡히는 느낌입니다. 어떤 글을 쓸까? / 다짐글또 3기를 하면서 가끔은 넋두리 같은, 오늘 같은 이야기를 하게 될 것 같고, 캐글 대회에 참여하고 잘 되거나, 안되었던 것들을 정리할 계획입니다. 또 일하면서 필요한 부분을 공부하면서, 예를들어 AWS(사실 GCP를 더 공부하고 싶었는데 ㅠㅠ 회사는 AWS를 쓰는군요…)나 Apache Spark, NoSQL(MongoDB) 등을 정리한 내용을 공유할 것 같습니다. 하반기에 계획했었던 일 중 하나가 글또 3기 들어가는 것이였는데요, 벌써 체크 하나하게 되어서 너무 기쁩니다. 최소 12개의 글을 쓰게 될텐데 그 과정이 의외로 도전적일 것 같아 재밌을 것 같네요. 도전적인 자세로 하반기를 살아봐야겠습니다. 내일은 월요일, 도전이 생각보다 꽤 빨리 시작되는 느낌입니다.","link":"/2019/07/07/geultto/"},{"title":"Python의 실수형에 대해서 알아보자","text":"컴퓨터 사이언스 부트캠프 with Python1. 실수 연산의 함정데이터 사이언스 공부를 하다보면 가끔 머리로 이해되지 않는 것이 생기곤 한다. 그 중 하나가 실수 연산에 대한 것이다.다음 예를 살펴보자 python(3.6.4)으로 다음과 같이 입력하자. 12345a = 0.01result = 0.0for i in range(100): result += a result result는 값이 어떻게 나오게 될까?위의 코드는 쉽게 말하자면 0.01을 100번 더한 것과 다를 게 없다.그렇다면 답은 1일 것이다. 하지만12&gt;&gt;&gt; result 1.0000000000000007 답은 1이 아니다. 만약 내가 조건문을 이용해서1==result 판단을 내렸다면 결과는 False로 나올 것이다. 1234a = 0.015625for i in range(100): result += aresult 1&gt;&gt;&gt;1.5625 그런데 이번 경우에는 생각과 같이 1.5625라는 결과가 나온다. 왜 갑자기 오차 하나 없이 깔끔하게 값이 나오는 것일까?왜 이런 일이 발생하는 것일까? 2. 부동소수점이 현상에 대해 이해하기 위해 부동소수점에 대해서 이해를 해야한다. 부동소수점에서 ‘부’는 부유한다는 말, 즉 떠다닌다는 말이다. 123.456을 다르게 표현해 보는 경우를 생각해보자123123.456 = 1.23456 * 10^2123.456 = 12.3456 * 10 ........ 위의 예시 말고도 다양한 방식이 있다. 소숫점이 둥둥 떠다니는 것 같이 움직인다. 그래서 이러한 실수 표현 방식을 부동소수점이라고 부른다. 3. 단정도와 배정도단정도(single-precision)는 실수를 32비트로 표현하며 부호 1비트, 지수부 8비트, 가수부 23비트로 구성되어 있다.배정도(double-precision)는 실수를 64비트로 표현하며 부호 1비트, 지수부 11비트, 가수부 52비트로 구성되어 있다.배정도가 단정도보다 두 배 정도의 비트 수가 많은데, 비트 수가 많은 만큼 정밀도가 높다고 할 수 있겠다. 파이썬은 배정도를 사용한다. 4. 1바이트 실수 자료형 설계하기\\pm 1.man \\times 2^{(exp-bias)}위의 수식은 실수 자료형을 표현한 수식이다. 1.man은 가수, 2는 밑수, exp-bias는 지수를 의미한다. 이 식을 이용해 7.75라는 10진수 실수를 1바이트 부동소수점으로 표현해보자. 4.1 10진수 실수를 2진수 실수로 바꾸기7.75 = 4 + 2 +1 +0.5 + 0.25= 2^2 + 2^1 + 2^0 + 2^{-1} + 2^{-2}=111.112진수로 바꾸면 111.11이란 값이 나온다. 4.2 정규화아 숫자를 정규화 해보자. 정규화란, 소수점 왼쪽에 위치한 가수 부분을 밑수보다 작은 자연수가 되도록 만드는 것이다.111.11을 정규화 하면 다음과 같다. 111.11 = 1.1111 \\times 2^24.3 메모리 구조정규화된 부동소수점 $1.111 \\times 2^2$를 앞의 수식과 비교해 보면man은 1111이고 exp-bias는 2이다.이제 메모리 구조를 정하고 man과 exp값만 저장하면 설계가 끝난다.이때 지수부와 가수부에 할당하는 비트 수에 따라 표현 범위와 정밀도가 결정된다. 1바이트 부동소수점 구조는 다음과 같다. 0 \\ 0000 \\ 000 \\ [부호(sign) \\ 지수부(exp) \\ 가수부에서 \\ man에 \\ 해당되는 \\ 부분] 첫번째 비트 : 부호 0은 양수, 1은 음수 가운데 4비트 : 지수부에 해당하며 exp 값이다. 0~15의 양수를 표현할 수 있다 $bias = 2^{지수의 비트수} -1$ 맨 뒤 3비트 : 가수부로 man 값을 저장함 $1.1111 \\times 2^2$를 1바이트의 메모리 구조로 변경해 보자. 부호비트는 0이다. $exp-bias$는 2이다. $bias$값이 7이므로 $exp$는 9가 된다.이것을 이진수로 나타내면 $1001_{(2)}$가 된다. 가수부에 할당된 비트는 3비트이다. 1111을 3비트에 넣을때는 뒷자리 1을 생략한다. 가수부는 111이다.0 \\ 1001 \\ 111 = 0100 \\ 1111이것을 16진수로 나타내면 0x4f가 된다.정리하자면 10진수 7.75를 $ 0100 \\ 1111 $로 나타낼 수 있고 이것을 다시 16진수로 나타내면 0x4f이다. 4.4 1바이트 부동소수점의 표현 범위 표현할 수 있는 가장 작은 수(지수부0001) $1.0000 \\times = 0.0156256$ 표현할 수 있는 가장 큰 수(지수부 1110) $1.111 \\times = 240$ 단, 지수부 비트가 모두 0일때와 모두 1일때는 0.0, 정규화 불가능, 무한대, NaN 같은 특별한 상황이므로 제외한다. 4.5 1바이트 부동소수점의 정밀도7.75를 변환하는 과정에서 3비트의 가수부데이터에 1을 누락해 가면서 가수부 공간에 담았던 것을 기억할 것이다.1을 누락하게 되면 0x4f는 7.75를 완벽하게 표현하지 못하게 된다. 1.111 \\times 2^2 = 1 \\times 2^2 + 1 \\times 2^1 + 1 \\times 2^{-1} = 7.5여기서 0.25만큼 차이가 나게되고, 그만큼 정밀도도 떨어지게 된다. 5. 정밀도에 대한 고찰5.1 엡실론실수 자료형에서 엡실론이란 1.0과 그 다음으로 표현 가능한 수 사이의 차이를 말한다. 12import syssys.float_info.epsilion 위 코드로 엡실론 값을 확인해 보자.배정도의 가수부는 52비트인 것을 기억할 것이다. 1.0을 배정도에 맞춰 표현하면$1.0000 ….. 0000(0:52개) \\times 2^0$배정도에서 1.0다음으로 표현할 수 있는 수는$1.0000 ….. 0000(0:51개) \\times 2^0$두 수의 차이는$1.0000 ….. 0000(0:51개) \\times 2^0$이 숫자를 10진수로 바꾸면 엡실론 값이 등장한다.$2.220446049250313 \\times 10^{-16}$ 5.2 엡실론과 정밀도엡실론을 이용하면 해당 실수 다음에 표현할 수 있는 수를 알아낼 수 있다.9.25라는 수를 부동소수점 방식으로 표현하면 $1.00101 \\times 2^3$이다.여기서 지수부분만 떼서 엡실론을 구하면 이 실수와 다음 표현 가능한 수 사이의 차이를 구할 수 있다.코드로 살펴보면, 123456789import sysep = sys.float_info.epsiliona= 9.25diff = (2**3)*epdiff&gt;&gt;1.7763568394002504e-15b = a + diffb&gt;&gt;&gt;9.250000000000002 0.000000000000002만큼 차이가 난다. 그렇다면 9.25에 diff보다 작은 값을 더하면 어떻게 될까?추측으로는 9.25가 나올 것 같다.확인해보자 12345a = 9.25half_diff = diff/2c = a + half_diffa == c&gt;&gt;&gt; True 추측과 같이 half_diff를 더하더라도 값의 변화가 없다.diff보다 작은 값을 더한 수를 부동소수점 방식에서는 표현할 수 없다는 말이다.다르게 말하자면 정밀도가 떨어진다는 말이다. 다음의 내용은 혼자서하는 괴발개발 블로그 https://aisolab.github.io/computer%20science/2018/08/07/CS_Real-number 에서 가져온 글이다.다음의 방법을 이용하면 상대오차(relative error) 가 엡실론보다 작으면 서로 같은 수라고 판단하는 function을 만듦으로써 위와 같은 문제를 해결할 수 있다. 1234a = 0.1 * 3b = 0.3print(a == b) 1False relative \\ error = {\\left\\vert x - y\\right\\vert \\over \\max(\\left\\vert x \\right\\vert , \\left\\vert y \\right\\vert)}123456789import sysdef is_equal(a, b): ep = sys.float_info.epsilon return abs(a - b) &lt;= max(abs(a), abs(b)) * epa = .1 * 3b = .3print(is_equal(a,b)) 1True","link":"/2019/01/19/float/"},{"title":"cross_entropy_KL_divergence","text":"Cross Entropy와 KL-Divergence에 대해서 알아보자Cross Entropy크로스 엔트로피에 대해서 알아보기 전에, 엔트로피 식을 다시한번 확인해 보자엔트로피는 $H(x)=-\\sum P(x)log_2P(x)$로 확률분포 $P(X)$에 대한 기댓값이다. 엔트로피는 확률분포가 있어야 정의가 될 수 있다. 확률 분포의 불확실한 정도를 뜻하는 것이라고 생각하면 된다. 이제 크로스 엔트로피 식을 확인해 보자$H(P,Q)=-\\sum_{X} P(x)logQ(x)$(자연로그 또는 이진로그)식을 자세히 보면, $P(x)$가 들어갈 자리에 $Q(x)$가 들어가 있다. 어떤 의미가 숨어져 있는 것 같은데, 이 수식이 의미하는 것이 무엇일까? 크로스 엔트로피(Cross Entropy)는 실제 데이터는 $P$의 분포로부터 생성되지만, 분포 $Q$를 사용해서 정보량을 측정해서 나타낸 평균적 bit수를 의미한다. 이제 수식이 눈에 들어오기 시작할 것이다. 실제 데이터는 분포 P로 부터 생성되는데, 우리가 실제 P에 대해서 몰라서 분포 Q의 정보(or 코딩 스킴)을 대신 활용하면 어떨까?에 대한 답으로써 만들어졌다고 생각하면 편할 것이다. 크로스 엔트로피는 $H(P,Q)$와 같이 나타내고 일반적으로 $H(P,Q) &gt;=H(P)$이다. 항상 크로스 엔트로피가 크거나 같을 수 밖에 없는 것은 데이터의분포를 Q로 가정한 코딩방식을 사용하게 되면, 실제의 분포 P를 가정한 코딩방식 보다 질의응답에 필요한 코드의 수(code length)가 많아지게 되기 때문이다. KL-DivergenceKL-Divergence는 쿨백 라이블러 발산이라고 불리기도 한다. 이 역시 수식으로 먼저 확인해 보자$D_{KL}(P||Q)=\\sum_{X}P(x)log {P(x)\\over{Q(x)}}$이다. 이 수식을 자세히 보면, Cross entropy 식이 들어가 있는 것을 확인 할 수 있다. 좀 더 풀어서 써보면 $D_{KL}(P||Q)=\\sum_{X}P(x)log{1\\over Q(x)}-P(x)log{1\\over P(x)}$로결국 $H(P,Q) - H(P)$, 즉 P와 Q의 크로스엔트로피에서 P의 엔트로피를 빼준 식이다. 이것은 결론적으로 Q를 이용한 정보량이 P의 분포와 얼마나 차이가 나는 지를 알려주는 것이다. 일종의 분포사이의 거리로 이해를 하면 된다. (KL divergence는 두 확률 분포 P와 Q의 차이를 측정한다. 하지만 엄밀히 말해서 거리는 아니다.) 다른 표현으로 데이터 인코딩 관점에서 보면 KL divergence는 데이터 소스의 분포인 P 대신 다른 분포 Q를 사용해서 인코딩하면 추가로 몇 bit의 낭비가 생기는지 나타낸다고 이해할 수 있다. KL-Divergence는 거리함수가 아니다. 왜냐하면 교환법칙이 성립하지 않기 때문이다. Reverse KL은 별도의 개념으로 사용된다. 하지만, 두 분포가 다를수록 큰 값을 가지며 둘이 일치할 때에만 0이 되기 때문에 거리와 비슷한 용도로 사용할 수 있다.[https://wiseodd.github.io/techblog/2016/12/21/forward-reverse-kl/] Cross Entropy와 KL-Divergence가 어떤 관계에 있느냐고 묻는다면, KL-Divergence의 앞쪽 수식에 크로스 엔트로피가 있으므로, 크로스 엔트로피가 작을 수록, KL-Divergence값이 작아진다. 즉, 두 분포가 가까워진다고 말할 수 있겠다.","link":"/2019/05/15/cross-entropy-KL-divergence/"},{"title":"Ensemble_Model","text":"Ensemble에 대해 자세히 알아보자 (Bagging, Bootstrap, 그리고 RandomForest)앙상블 모델에 대해서 공부하기 전에, 그 배경부터 알아볼 필요가 있다. NFL (No Free Lunch)No Free Lunch 이론은 David H. Wolpert가 정리한 이론으로 모든 문제에 대해 다른 모든 알고리즘을 능가하는 모델은 없다는 이론이다. ‘어떤 특정 정책에 의해 얼핏 보면 이득을 얻는 것 같지만, 그것은 한 측면의 이득일 뿐이고 반드시 이면에 다른 측면이 있고 그 측면에서 손해가 발생한다.’는 것이 핵심이다. 이 이론에 따라서 혼성모델의 필요성이 대두되었다. 혼성모델이란 여러 알고리즘을 결합하는 모델이다. 이 모델은 특정 문제가 주어진 상황에서 그 문제를 가장 높은 성능으로 풀 수 있는 알고리즘에 대한 필요성에 의해서 제시되었다. Resampling리샘플링은 데이터가 부족할 때 같은 샘플을 여러번 사용하는 것을 말한다. 성능 통계치의 신뢰도를 높이기 위해 사용된다. Resample을 하는 이유는 다음과 같다. 실제 상황에서는 만족할 만한 큰 샘플을 얻기가 힘들다. Bias-Variance Trade off를 통해 큰 샘플이 중요하다는 것을 알 수 있다. sample의 집합이 커지면 variance가 감소한다!, MSE도 감소한다! 모델의 선택은 별도의 검증이 필요하다.(검증용 데이터, 큰 샘플의 필요성) Bootstrap, Statistical term for “roll n-face dice n times”부트스트랩은 Resampling을 이용하여, 분류기의 성능을 측정하는 방법 중 하나이다. 통계에서는 추정치에 대한 검증용(가설 검증)으로 많이 사용된다. 부트스트랩의 장점은 한번도 뽑히지 않은 데이터가 발생한다는 것이다. 이를 통해 데이터를 아낄 수 있게 된다. Ensemble앙상블 모델은 혼성모델 중 하나이다. 앙상블은 두가지 방식이 존재한다. 같은 문제에 대해 서로 다른 여러 알고리즘이 해를 구하고, 결합 알고리즘이 그들을 결합하여 최종 해를 만드는 방식 문제와 유사한 여러 하위 문제들에 대해 하나의 알고리즘이 해를 구하고, 결합 알고리즘이 그들을 결합하여 최종 해를 만드는 방식 앙상블의 동기는 단순히 통계적, 수학적일 뿐만 아니라, 사람들의 심리 등 여러부분을 관통하는 내용이기도 하다.12어느 도시에서는 소를 광장에 매어 놓고 참가자들에게 체중을 추정하여 적어 내게 하고 실제 체중에 가장 가까운 사람에게상품을 주는 대회가 있다고 한다. 수백 명이 참가하는데 그들이 적어낸 숫자들을 평균해 보면 답과 아주 근사하다고 한다. 사람들은 중요한 결정을 할때 여러 사람의 의견을 들어보고 결정하려는 경향이 있고, 이런 경향은, 통계학이 아닌 다른 분야에서도 사용되는 개념이다. 다양성앙상블 모델의 핵심은 다양성이다. 앙상블에 참여한 모델이 모두 같은 결과를 낸다면, 그것은 앙상블 모델로써 어떠한 장점도 갖고 있지 않다. 한 분류기가 틀리는 어떤 문제를, 다른 분류기에서는 맞출 수 있어야 앙상블 모델로써 가치가 있을 것이다. 앙상블 분류기 시스템은 앙상블 생성, 앙상블 선택, 앙상블 결합의 단계를 거친다. 앙상블 생성 Resample을 이용해서 (Bagging, Bootstrap) 샘플 집합들을 생성하고, 분류기를 훈련한다. Feature Vector의 subspace를 이용해서 샘플 부분 집합을 생성하고 분류기를 훈련한다. 앙상블의 분류기는 요소분류기와 기초분류기로 구분된다. 앙상블 결합요소 분류기(기초 학습기)들의 출력을 결합하여 하나의 분류 결과를 만드는 과정이다.요소 분류기의 출력은 세가지의 방식으로 나뉜다. Class Label Majority Vote : class 라벨이 많이 나온 쪽으로 분류한다. Weighted Majority Vote : 성능 좋은 분류기에 가중치를 부여한다.(Adaboost) Behavior knowledge space(BKS/행위지식공간) : 경험한 케이스를 테이블로 갖고 분류기 결과를 보고 경험적으로 결정한다(테이블에서 찾아서). 다수결 방법의 성능을 고도화 할때 사용됨 Class Ranking Borda 계수 Class Probability Softmax Bagging (Bootstrap + Aggregating)부트스트랩을 다중 분류기 생성 기법으로 확장한 것이다. 부트스트랩 된 샘플 집합에서 훈련을 하고, 입력 값에 대해 분류기들의 평균값이나, 다수결 투표를 취한다. 샘플링은 복원추출하는 방식으로 하고, 훈련된 분류기의 결과를 모두 종합하기 때문에 Bagging이라고 부른다. 반복적인 복원 추출 (Bootstrap) 결과를 모두 종합 (Aggregation) Bagging, 배깅은 언제 사용할까?배깅은 편향이 작고 분산이 높은 모델에 사용하면 효과적이다. 트리 분류기와 같이 불안정성을 보이는 분류기에 큰 효과를 발휘 훈련 집합이 달라지면 차이가 큰 트리가 생성 ⇒ 다양성 확보 Bias를 변화시키지 않고 variance를 감소시킨다.(Bias를 쪼오오오오끔 희생한다.) 배깅은 분산을 감소시키기 위해, 훈련데이터에서 많은 샘플링을 하고(Bootstrap), 샘플들로 별도의 Decision Tree를 구성한 후, 회귀나 분류문제를 푸는데 사용된다. 회귀는 분류기 결과의 평균값을 사용하고, 분류는 최빈값을 취한다. 배깅은 이미 저분산 모델인 경우 별로 효과가 없다. Bias-Variance Tradeoff 를조금만 생각해보자. 분산이 이미 줄어있는 상태에서는 더 줄일 분산이 없다. 배깅은 오직 분산을 줄이는 데 효과적이다. Out-of-Bag (OOB) Error Estimation샘플에 대해 Bootstrap을 하게 되면 부트스트랩 샘플은 전체 훈련데이터의 약 63.2%를 차지하게 된다.(왜 그러한가에 답은 $\\lim_{n\\to\\infty} (1-{1\\over n})^n$을 풀면 답이 나온다. $1\\over e$로 0.378이 나온다. 자세한 내용은 링크를 참조하면 된다. [https://www.quora.com/Why-is-the-limit-1-frac-1-n-n-equal-to-frac-1-e]) 부트스트랩되지 않은 샘플들은 한번도 사용되지 않은 샘플들로 검증데이터에 활용할 수 있다. 이런 training observations은 out-of-bag observations이라고 불린다. OOB estimate of test error 부트스트랩 샘플을 이용하여 개별 학습기를 학습한 후, OOB에 속하는 샘플들에 대한 예측값을 모두 구한다. OOB의 실제 라벨값과 OOB의 예측값을 이용하여 OOB error를 구한다. 모든 부트스트랩 샘플 sets에 대하여 위의 과정을 반복하면, 샘플 sets 수 만큼의, errors를 모을 수 있다. OOB errors의 평균값을 이용하여 bagging 모델의 최종 테스트 error를 계산한다. Weakness of Bagging배깅은 엄청나게 효과적인 것처럼 보이지만 약점이 존재한다. 배깅은 feature를 모두 사용하고, row를 랜덤하게 선택하는 것이다. Decision Tree를 만든다고 해보자, 만약 영향력이 높은, Information Gain이 높은 모델을 사용한다고 했을때, 특정 Feature만 계속 선택되서 트리가 만들어질 가능성이 있다. 즉, 중요한 칼럼들이 트리의 초기 분기때 모든 표본에 그대로 존재하게 된다. 이렇게 되면 만들어진 대다수의 트리들의 결과가 비슷해진다. 이것이 반복되면 트리간의 상관관계가 발생해서 분산 감소의 효과가 줄어들게 된다.(배깅의 약점은 IID condition이다. IID 조건을 만족하는 경우 분산은 $Var={\\sigma^2\\over n}$이 되지만, IID를 만족하지 못하는 경우, 상관관계가 발생하여 $Corr = p$이라고 할때, $Var = p\\sigma^2$가 된다.) 그래서 혁신적인 아이디어와 함께 등장하게 된 것이 Random Forest이다. Random Forest랜덤 포레스트는 일반적으로 bagging 방법(또는 pasting)을 적용한 결정 트리의 앙상블이다.랜덤 포레스트 알고리즘은 트리의 노드를 분할할 때 전체 특성 중에서 최선의 특성을 찾는 대신 무작위로 선택한 특성 후보 중에서 최적의 특성을 찾는 식으로 무작위성을 더 주입한다. 트리를 더욱 다양하게 생성하고 (트리의 의존성을 낮추고, 다양성을 증가) 편향을 손해 보는 대신 분산을 낮추어 전체적으로 더 훌륭한 모델을 생성한다. Random Forest는 쉽게 말해 Tree 모델에 Bagging과 Subsampling기법을 사용한 모델이다.훈련 데이터에서 bootstrap 샘플을 뽑아내고, 노드 분기 시, 모든 Feature가 아니라, 일정 Feature만 사용하는 것이 특징이다. 이를 통해 Tree간의 Correlation을 줄이고, 분산을 감소시킬 수 있다. Subspace Sampling샘플링 시에는 일반적으로 전체 변수가 p라고 할 때, $m = \\sqrt{p}$를 사용한다.(m = p이면 Bagging이다. 또한 회귀에서는 경험적으로 $m ={p\\over3}$를 사용한다.) Random Forest 모델의 장단점?장점 : 굉장히 간편하다. 스케일링도 필요없고 파라미터 튜닝을 많이 안해도 성능이 뛰어나다. 의사결정의 트리의와 배깅의 단점은 극복하고 장점만을 가져온 것이라고 할 수 있다. 단점 : 차원이 높고 매우 희소한 데이터에서는 잘 작동하지 않는다. 이런 희소한 데이터에는 선형 모델이 더 적합할 수 있다.","link":"/2019/05/05/Ensemble-Model/"},{"title":"Classification Metrics","text":"Classification Metrics분류 모델의 평가지표에 대해서 알아보자Classification 모델을 만든 후에 모델의 성능이 어떤지 알기 위해서는 성능 평가 지표가 필요하다.분류 모델의 성능지표를 알아보면서, 데이터의 상태에 따라서 어떤 지표를 사용해야하는지 공부해보자. 0과 1로 결정값이 한정되는 이진 분류 성능 평가 지표에 대해서 집중적으로 다뤄보자. 분류 성능 평가 지표 정확도(Accuracy) 오차행렬(Confusion Matrix) 정밀도(Precision) 재현율(Recall) F1스코어 ROC AUC 정확도(Accuracy)정확도는 실제 데이터에서 예측 데이터가 얼마나 같은지를 판단하는 지표이다. Accuracy = {TP+TN\\over TP+TN+FP+FN}정확도는 직관적으로 모델 예측 성능을 나타내는 평가 지표이며, 기본적으로 많이 사용하는 지표중 하나이다.하지만 정확도는 치명적인 약점이 존재하는데, 바로 불균형한 데이터 셋에서는 제대로 평가가 안된다는 것이다. 예를 들어보자 1000개의 샘플에 10개만 문제가 있는 샘플이다. 이럴 경우에 엉터리 분류기, 즉 모든 샘플에 대해서 정상이라고 분류하는 분류기를 이용해서 분류하고 정확도로 성능 평가를 한다면, 결과는 990/1000, 99%의 정확도를 보이게 된다.엉터리 분류기가 과연 좋은 분류기일지 생각해보자. 만약 이 분류기에 문제가 있는 샘플을 더 추가한다면, 정확도는 기하급수적으로 떨어지게 될 것이다. 오차행렬(Confusion Matrix)오차행렬은 학습된 분류 모델이 예측을 수행하면서 얼마나 헷갈리고 있는지도 함께 보여주는 지표이다. 즉, 이진 분류의 예측 오류가 얼마인지와 어떤 유형의 예측 오류가 발생하고 있는지를 같이 나타내 주는 지표이다. 오차행렬은 다음과 같이 표현한다. Negative(0) Positive(1) Negative(0) TN(True Negative) FP(False Positive) Positive(1) FN(False Negative) TP(True Positive) 위의 표에서 진하게 표시된 것이 예측 클래스에 대한 것이고(Predicted Calss) 옅게 표시된 것이 실제 클래스(Actual Class)이다. TP는 예측값을 Positive값 1으로 예측했고, 실제 값 역시 Positive값 1 TN는 예측값을 Negative 0으로 예측했고, 실제 값 역시 Negative값 0 FP는 예측값을 Positive값 1으로 예측했고, 실제 값은 Negative 값 0 FN는 예측값을 Negative값 0으로 예측했고, 실제 값 역시 Positive값 1 오차행렬을 기반으로 해서 정확도의 식을 다시 보면 결국, True에 해당하는 값인 TP와 TN에 값이 좌우되고 있다는 것을 알 수 있다. 정확도 = 예측 결과와 실제 값이 동일한 건수 / 전체 데이터 수 라고 다시 말할 수 있다. 불균형한 이진 분류 데이터 셋에서는 Positive 건수가 매우 작기 때문에 이러한 데이터로 학습된 ML 알고리즘은 Positive보다는 Negative로 예측 정확도가 높아지는 경향이 발생한다. TN값이 높아진다는 것이다. 결과적으로 불균형 데이터 셋에서는 Positive에 대한 예측 정확도를 판단하지 못하고 Negative에 대한 예측 정확도만으로 분류의 정확도가 매우 높게 나타나는 수치적인 판단 오류를 일으키게 된다. 이런 판단 오류를 극복하기 위해서 정밀도(Precision)와 재현율(Recall)이 성능지표로 사용된다. 정밀도와 재현율 (Precision and Recall)정밀도와 재현율은 다음과 같은 공식으로 정의된다. Precision = {TP \\over FP+TP}Recall = {TP \\over FN+TP}정밀도는 예측을 Positive로 한 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율을 뜻한다. 정밀도의공식에서 분모는 예측을 Positive로 한 모든 데이터 건수이다. Positive 예측 성능을 더욱 정밀하게 측정하기 위한 평가 지표로 양성 예측도라고 불린다. 재현율은 실제 값이 Positive인 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율을 뜻한다. 공식의 분모는 실제 값이 Positive인 모든 데이터 건수이다. 민감도 또는 TPR(True Positive Rate)라고도 불린다. 정밀도와 재현율은 중요하게 생각하는 부분이 서로 다르기 때문에, 주어진 업무 특성에 따라서 특정 평가 지표가 더 중요한 지표로 간주될 수 있다. 재현율이 중요한 경우를 생각해보자. 재현율이 중요 지표로 사용되는 경우는 실제 Positive 양성 데이터를 Negative로 잘못 판단하게 되면 크리티컬한 영향이 발생하는 경우이다. 예를 들어 암 판단 모델은 재현율이 중요한데, 실제 Positive인 경우, 즉, 암환자를 Negative, 정상으로 분류하는 경우 오류의 대가가 생명이 될 수 있을 정도로 치명적이다. 만약 정상환자를 암환자로 분류하는 경우에는, 재검진을 하는 정도의 비용이 소모된다.(Positive—&gt;Negative로 잘못분류) 정밀도가 중요한 경우를 생각해보자. 스팸메일 여부를 확인하는 예를 들어보면, 실제 Positive인 스팸 메일을 Negative 정상 메일이라고 분류하게 되면 사용자가 불편함을 느끼는 정도지만, 정상메일을 Spam으로 분류해 버리면 업무메일 등이 스팸으로 처리되어 메일을 받지 못하게 돼 업무에 차질이 생길 수 있다.(Negative—&gt;Positive로 잘못분류) 정리하자면, 재현율이 더 중요한 경우, 실제 Positive 양성 데이터 예측을 Negative로 잘못 판단하게 되면 업무 상 큰 차질이 발생하는 경우 정밀도가 더 중요한 경우, 실제 Negative 음성 데이터 예측을 Positive로 잘못 판단하게 되면 업무 상 큰 차질이 발생하는 경우 공식을 다시살펴보면, Precision은 FN이 분모에 사용되고, Recall은 FP가 분모에 사용된다. 재현율은 FN을 낮추는 데, 정밀도는 FP를 낮추는 데 초점이 맞춰진다. 가장 좋은 것은 둘다 높은 것인데, 두 성능 지표가 상호 보완적이기 때문에 Trade off가 존재한다. 정밀도/재현율 트레이드 오프정밀도나 재현율은 분류의 결정 임계값을 조정해 정밀도나 재현율의 수치를 높일 수 있다. sklearn의 분류 모델들에서 threshold를 조절할 수 있는 파라미터를 찾아보면 된다. threshold값을 낮추면 보통 재현율 값이 올라가고 정밀도 값이 떨어진다. threshold값은 Positive 예측값을 결정하는 확률의 기준이 되고 낮출 수록 True값이 많아지기 때문이다. Positive 예측값이 많아지면 상대적으로 Recall 값이 높아진다. 양성 예측을 많이 하다보니 실제 양성을 음성으로 예측하는 횟수가 상대적으로 줄어들기 때문이다(FN값이 떨어진다). 임계값 증가하면 Negative 예측 값이 증가한다(FP값이 떨어짐) ==&gt; Precision 증가 임계값 감소하면 Positive 예측 값이 증가한다(FN값이 떨어짐) ==&gt; Recall 증가 정밀도와 재현율의 맹점Positive 예측의 임계값을 변경함에 따라 Precision과 Recall의 수치가 변경되는 것을 확인해 봤다. Threshold의 이런 변경은 업무 환경과 목적에 맞게 두 수치를 상호 보완할 수 있는 수준에서 적용되어야 한다. 단순히 성능지표로서 숫자를 올리는 수단으로 사용되면 안된다. 정밀도 100% 만들기확실한 기준이 되는 것만 Positive로 예측하고 나머지는 모두 Negative로 예측한다. 정밀도 = TP / (TP+FP) 이다. 예를 들어 암환자를 예측한다고 해보자. 전체환자 1000명 중에 확실한 Positive 징후만 가진 환자가 단 1명이라면(죽기 일보직전의) 한명만 Positive로 예측하고 나머지는 모두 Negative로 예측하더라도 FP는 0, TP는 1이기 때문에, 정밀도는 1/(1+0)으로 100%가 된다. Precision은 100%지만, 초기 암진단을 예측하는 경우는 희박하고, 위험한 정도의 암환자도 정상이라고 분류할 수 있기 때문에 좋은 분류기라고 할 수 없을 것이다. 재현율 100% 만들기모든 환자를 Positive로 예측하면 된다. 재현율 = TP / (TP+FN)이므로 전체 환자 1000명을 다 Positive로 예측하는 것이다. 이 중 실제 양성인 사람이 30명 정도라도 TN이 수치에 포함되지 않고 FN은 아예 0이므로 30/(30+0)으로 100%가 된다. 이렇게 되면 재현율은 100%지만 모델을 정말 신뢰할 수 있는지에 대해 의심이 발생할 것이다. 이런 모델은 정상인 사람도 암 환자로 예측하게 되므로, 재검사 비율을 매우 높이게 된다. 병원에서 재검사 비용을 대줘야 한다면, 혹은 환자로 분류된 사람이 재검사 비용을 내야 한다면, 병원이 손해를 막심하게 보거나, 고객들이 병원에 대해 신뢰를 하지 않을 것이다. 따라서 정밀도와 재현율을 적절하게 고려한 평가 지표가 필요하게 된다. F1 ScoreF1-Score는 정밀도와 재현율을 조화 평균한 지표이다. F1-Score는 정밀도와 재현율이 어느 한 쪽으로 치우치지 않는 수치를 나타낼 때 상대적으로 높은 값을 가진다. 공식은 다음과 같다. F1={2\\over{1\\over{recall}}+{1\\over{precision}}}=2\\times{precision*\\space recall\\over precision+recall}만일 A 예측 모델의 경우 Precision이 0.9, Recall이 0.1로 극단적인 차이가 나고, B 예측 모델은 Precision과 Recall이 0.5로 큰 차이가 없다면 A의 F1-Score는 0.18이고, B의 F1-Score는 0.5로 B의 모델이 좋은 점수를 얻게 된다. 사실 F1 Score는 Precision과 Recall에 동일한 가중치인 0.5를 적용한 값이다. F-Measure는 $\\beta$를 이용해 가중치를 조절한다. 공식을 살펴보자. $F_\\beta=$$(1+\\beta^2)(Precision * Recall)\\over{\\beta^2 Precision + Recall}$ $\\beta$가 1보다 크면 Recall이 강조되고 1보다 작으면 Precision이 강조된다. 1일때의 점수를 $F_1$점수라고 한다. ROC &amp; AUCROC곡선(Receiver Operation Characteristic Curve)은 수신자 판단 곡선으로, 2차대전 때 통신 장비 성능 평가를 위해 고안된 수치이다. 요즘에는 이진 분류의 성능 평가 지표로 자주 사용된다. ROC Curve는 FPR(False Positive Rate)이 변할 때 TPR(True Positive Rate)이 어떻게 변하는지를 나타내는 곡선이다. FPR을 x축으로, TPR을 y축으로 잡으면 FPR에 대한 TPR의 변화가 곡선 형태로 나타난다. TPR은 True Positive Rate의 약자이며, Recall을 나타낸다. 따라서 TPR은 TP/(TP+FN) 이다. 민감도라고도 불리며 민감도에 대응하는 지표로 TNR(True Negative Rate)이라고 불리는 특이성이 있다. 민감도(TPR)는 실제값 Positive가 정확히 예측되어야 하는 수준을 나타낸다.(질병이 있는 사람은 질병이 있는 것으로 양성 판정) 특이성은(TNR) 실제값 Negative가 정확이 예측되어야 하는 수준을 나타낸다.(정상인 사람은 정상으로 음성 판정) TNR은 TN/(TN+FP)이며 X축의 기준인 FPR은 FP/(FP+TN)이므로 1-TNR로 표현할 수 있다. ROC 곡선은 FPR을 0부터 1까지 변경하며 TPR의 변화 값을 구한다. Threshold값을 변경하면서, 처음에는 1로 지정해 FPR을 0으로 만든다. Threshold가 1일 때 Positive 예측 기준이 매우 높기 때문에 분류기가 Threshold보다 높은 확률을 가진 데이터를 Positive로 예측할 수 없다. 즉, 아예 Positive로 예측을 하지 않기 때문에 FP가 0이 되어 FPR이 0이된다. FPR = FP/(FP+TN) 반대로, FPR을 1로 만들려면 TN을 0으로 만들면 된다. Threshold를 0으로 지정하게 되면, 분류기가 모든 데이터에 대해서 Positive로 예측을 하게 된다. 이렇게 되면 Negative 예측은 없기 때문에 FPR이 1이 된다. 일반적으로 ROC Curve자체는 FPR과 TPR의 변화 값을 보는 데 이용하고, 분류의 성능 지표로 실제로 사용되는 것은 AUC(Area Under Curve)이다. 이 값은 ROC 곡선 밑의 면적을 구한 것으로, 일반적으로 1에 가까울수록 좋은 수치이다. AUC가 커지려면, FPR이 작은 상태에서 얼마나 큰 TPR을 구할 수 있는 지가 중요하다. 가운데 직선에서 멀어지고 좌상단 모서리로 곡선이 바짝 붙을 수록 직사각형에 가까운 곡선이 되어 면적이 1에 가까워진다. 가운데의 직선은 랜덤 수준의 이진 분류 AUC값으로 0.5이다.","link":"/2019/05/29/Metrics/"},{"title":"PCA","text":"Dimensional Reduction에 쓰이는 PCA에 대해 알아보자PCA(Principal Component Analysis)데이터 분석을 하다보면 답답한 경우가 자주 발생한다. 모델을 돌려야 하는데 feature가 너무 많아서 연산 코스트가 너무 많이 들고, 계산하는데 너무 오랜 시간이 걸리는 것이다. 결과를 봤더니, 복잡한 feature때문에 지저분하게 나오고, 노이즈도 많이 껴있는 것 같다. PCA는 이런 경우에 자주 사용되는 알고리즘이다. PCA는 그러니까 relative하지만 redundant한 feature를 제거하는데 자주 사용되거나 데이터를 단순화 할때 사용된다. 데이터를 단순화하는데는 다음의 두 가지 방법이 있다. 차원 축소(Dimensional Reduction) : 데이터를 표현하는 속성의 수를 축소 요소 분석(Factor Analysis) : 관찰 가능한 데이터 = 잠재적인 변수(latent variable)와 noise의 선형결합 우리는 차원 축소에 대한 내용을 살펴볼 것이다. 아까의 상황을 다시 가져와보자. 이전의 예에서 복잡한 feature들은 사실 highly correlated 되어 있기 때문에 문제가 있는 것이다. 변수들의 서로 연관되어 있으면 설명량은 올라가지만, 좋은 모델이라고 볼 수 없고, 어떤 변수가 타겟에 어떻게 영향을 주는지 알 수 없다. 불필요한(서로 연관되어 있거나, 결과와 상관없는) 변수들은, 변수들을 모으고 분석하는데 드는 비용을 증가시켜서, 예측 모델 또는 분류 모델을 만들 때 전체 비용을 증가시키는 원인이 된다. 따라서 불필요한 변수들을 제거할 필요가 있고, Machine Learning 영역에서는 본래 모델이 가지고 있던 성질이나 정확도를 최대한 유지하면서 차원을 줄이는 방법을 통하여 위에서 설명된 문제점을 해결하려고 한다. 모델의 차원(dimensionality)은 모델에 사용되는 독립(independence) 변수 또는 입력(input) 변수의 개수(number)를 의미한다. 우리가 GLM(Generalized Linear Model)을 사용하는 이유처럼 독립변수가 타겟에 미치는 영향을 제대로 알기 위해서 독립적인 변수가 필요한 것이다. 통계에서 항상 IID 조건을 사용하는 것과 의미가 비슷할 것이다. 정리하자면 PCA를 사용하는 이유는 다음과 같다. feature가 너무 많으면 연산에 사용되는 cost가 너무 높고, 시간도 너무 오래 걸리기 때문에, 변수들을 줄여줄 필요가 있다. 많은 feature들 중에서는 상관관계가 높은 feature들이 있다(high correlated). 이런 feature들은 모델의 설명량은 높일 수 있지만, 모델의 성능은 떨어트릴 수 있다. 또한 우리가 흥미 있어 하는 결과와 상관없는 변수들이 존재할 수 있는 상황이 발생할 수 있다. Dimensional ReductionDimensional Reduction의 핵심 아이디어는, 상관도가 높은(interrelated, correlated) 변수들이 많이 존재하는 데이터 집합의 차원(Dimensionality)을 줄이면서, 동시에 데이터 집합에 존재하고 있는 차이(Variation, 정보)를 최대한 유지하는 것이다. 즉, 차원을 줄이되 “정보 손실을 최소화”하는 것이다. 여기서 정보란 데이터간의 거리, 실제적인 위치를 정보라고 표현한다. 다시말하면 위치, 상대적인 거리를 뜻한다. 하지만 차원축소는 정보의 손실을 어느 정도 감수해야 한다. Dimensional Reduction은 원래 공간에서 데이터가 퍼져 있는 정도를 변환된(축소된) 공간에서 얼마나 잘 유지하느냐를 척도로 삼는다. 원래 공간의 정보가 변환된 공간에서 얼마나 잘 유지하는지는 변환된 공간에서의 데이터의 분산으로 측정한다. 따라서, 변환된 공간에서 데이터의 분산을 최대로 유지 할 수 있는 좌표축을 찾아야 한다. 즉, PCA는 원래 공간에서 데이터가 분산되어 있는 주요한 방향(Principal direction)을 찾는 것이 목표가 된다.여러축으로 구성되어 있는 데이터를 주성분 분석으로 통해 기존의 feature들과는 다른 새로운 축으로써 다시 구성해보되, 분산을 최대로 유지한다. PCA 수행방법PCA에서 데이터가 분산되어 있는 주요한 방향(Principal Component)을 찾는 단계는 다음과 같다. 데이터를 투영(Projection)하기 투영된 공간에서 분산 측정하기 분산의 최대치는 어떻게 찾는가? 데이터를 여러 축에 투영해보면서 투영된 공간에서 분산을 측정하고, 가장 분산이 큰 축을 선택하는 것이 바로 PCA이다.새로운 축이 $u$이라고 했을때, 축으로 이동된 새 데이터 포인트 $X_{new} = u^TX$이다. (𝕦t 𝕩= 𝕦 ⋅ 𝕩 cos𝜃= 𝕩 cos𝜃) 이제 투영된 공간에서 분산을 측정해보자. 먼저, PCA를 실행하기 전에 데이터의 평균(mean)과 분산(variance)를 정규화(standardization) 해 준다.(Pre-process the data) 데이터는 특성 벡터로 표현되는데, 특성 벡터의 각 원소들에서 각각의 평균과 빼 주고, 분산의 제곱근으로 나누어 준다. 정규화 과정에서 데이터에서 평균을 빼는것:데이터의 평균이 0이 되도록 만든다. 데이터에서 분산의 제곱근을 나누어 주는 것 : 데이터의 값들이 unit variance를 갖게 해 준다. 새 축으로 이동된 데이터의 분산 구하기각각의 attribute의 평균이 0이 되고, 분산이 1이 된다. 즉 같은 “scale”을 가지게 되어, attribute간의 비교가 가능 해진다.데이터 포인트 $x_{1}, x_{2}, x_{3}, x_{4}, x_{5}$가 있을 때, u의 축으로 투영된 데이터 포인트$x_{1}^Tu, x_{2}^Tu, x_{3}^Tu, x_{4}^Tu, x_{5}^Tu$의 분산을 구해보자. 먼저 평균값을 구해놓자. \\mu={1\\over{m}}\\sum_{i=1}^{m}x_i^Tu = 0투영된 공간에서의 기댓값은 0이다. 왜냐하면 데이터 포인트들은 이미 standardizing을 한 상태이기 때문이다. 평균의 평균을 구하니까 0이 되는 것이다. 분산을 구해보자. \\sigma^2={1\\over{m}}\\sum_{i=1}^{m}(x_i^Tu - \\mu)^2 ={1\\over{m}}\\sum_{i=1}^{m}(x_i^Tu)^2($\\mu$가 0이므로) ={1\\over{m}}\\sum_{i=1}^{m}(u^Tx_ix_i^Tu) = u^T({1\\over{m}}\\sum_{i=1}^{m}(x_ix_i^T))u($u$는 unit vector이다.) 이것은 결론적으로 =u^T({1\\over{m}}\\sum_{i=1}^{m}(x_i-\\mathbb{o})(x_i-\\mathbb{o})^T)u=u^T\\sum u식이 도출된다. Σ는 공분산 행렬로 기존 데이터의 공분산 행렬을 사용한다.결국 투영하려고 하는 축과 기존 데이터의 공분산 행렬의 곱으로 간단하게 새 축의 분산을 구할 수 있다. 분산의 최대치 구하기우리는 Principal Component, 즉, 주성분을 구하는 것이 목적이므로, 데이터의 분산이 최대가 되도록 만드는 축을 구해야 한다. 분산의 최대치를 구하기 위해서 변환된(투영된) 공간에서 분산을 최대화 해 줄 수 있는 벡터 $u$를 찾아야 한다. $u$는 unit vector라고 생각하자. 우리가 구하고자 하는 $u$는 방향이 중요하기 때문이다. 즉, $u^Tu = 1$이다. 따라서 문제는 $u$가 unit vector일 때의 $u^T\\sum u$의 최대값을 구하는 조건부 최적화 문제가 된다. \\max u^T\\sum us.t \\space u^Tu=1이 문제는 라그랑지 승수 (Laglange Multiplier)를 이용해 해결 할 수 있다. \\mathcal{L}(u,\\lambda)= u^T\\sum u - \\lambda(u^Tu-1)$\\mathcal{L}(u,\\lambda)$를 미분해서 $u$의 최대치를 구한다. 이렇게 구한 식을 나타내면 u^T\\sum u = u^T\\lambda u=\\lambda u^T u=\\lambda즉, 분산을 최대화 하는 문제는 Σ의 eigenvalue를 최대화 하는 문제가 된다. argmax_{u}u^T\\sum u = argmax_{u}\\lambda따라서, 변환된(축소된) 공간에서 분산의 최대값은 Σ의 eigenvalue의 최대값이다. 분산의 최대값은, 𝕦가 Σ의 eigenvalue 중 가장 큰 값을 가지는 eigenvalue에 대응되는 eigenvector일 때 달성된다. 우리는 이것을 주성분이라고도 부른다. 이 다음의 주성분을 구하는 것은 간단하다. D차원에서 주성분은 데이터 공분산 행렬의 가장 큰 eigenvalue에서 부터 D번째로 큰 eigenvalue까지에 대응되는 D개의 eigenvector가 될 것이다.","link":"/2019/05/23/PCA/"},{"title":"programmers Carpet","text":"프로그래머스 코딩테스트 연습문제 카펫을 풀어봤다카펫 문제 설명 Leo는 카펫을 사러 갔다가 아래 그림과 같이 중앙에는 빨간색으로 칠해져 있고 모서리는 갈색으로 칠해져 있는 격자 모양 카펫을 봤습니다. Leo는 집으로 돌아와서 아까 본 카펫의 빨간색과 갈색으로 색칠된 격자의 개수는 기억했지만, 전체 카펫의 크기는 기억하지 못했습니다. Leo가 본 카펫에서 갈색 격자의 수 brown, 빨간색 격자의 수 red가 매개변수로 주어질 때 카펫의 가로, 세로 크기를 순서대로 배열에 담아 return 하도록 solution 함수를 작성해주세요. 제한사항 갈색 격자의 수 brown은 8 이상 5,000 이하인 자연수입니다.빨간색 격자의 수 red는 1 이상 2,000,000 이하인 자연수입니다.카펫의 가로 길이는 세로 길이와 같거나, 세로 길이보다 깁니다. 문제는 완전탐색으로 풀라고 하는 것 같았지만, 이 문제는 수학적으로 풀 수 있을 것 같았다.Brown과 Red를 이루는 수를 Red의 m과 n으로 표현해보고 (Red = (m x n)꼴, m&gt;n) 나온 (m,n)꼴에 +2를 해주면,return값이 (m+2,n+2) 나오게 된다는 것을 깨달았다. 하지만 문제가 있었다. 이 경우는 Red가 Square꼴이 아닐 때만 해당했던 것이었다.Red가 Square꼴일 경우, m과 n으로 문제를 풀 수 없다. 이 경우는 다른 케이스를 생각해 봐야 한다.R을 (nxn)꼴이면 Brown이 4(n+1)로 나온 다는 것을 알아야 한다.return은 처음의 케이스와 같이 2만 더해주면 된다. 첫번째 케이스의 경우를 n에 대해서 쭉 풀어주면 이차방정식 꼴이 나온다.아마도 테스트 케이스는 근이 정수로 나올 것 같아서 중근이나 허근이 나올 경우를 제외한, 근의 공식을 코딩해서 함수화 하였다.12345678910def fun(a,b,c): D=b*b-4*a*c if D&gt;0: x1=round((-b-D**0.5)/2*a) x2=round((-b+D**0.5)/2*a) if x1&gt;x2: return [x1+2,x2+2] else : return [x2+2,x1+2] 그 다음 두번째 케이스로 넘어가는 것이 중요했는데, Brown과 Red를 받았을 때, 특히 Red를 가지고 제곱수인지 판별하는 함수가 필요했다. 만약 Red가 제곱수라면 Red에 루트를 씌워서 값을 받아 2만 더해주면 될 것이고, 제곱수가 아니라면 위의 함수를 이용해서 return을 받으면 된다.그래서 제곱수 판별하는 함수를 다음과 같이 작성했다.1234import numpy as npdef issquare(n): if int(n ** 0.5) ** 2 == n : return int(np.sqrt(n)) 마지막으로 solution 함수에서는 이 함수들을 모두 합쳐주고 조건문을 통해서 return값을 다르게 받아준다.123456789def solution(brown, red):# return이 제곱 수 아닐 때 if issquare(red) : return [issquare(red) + 2,issquare(red) + 2] else: a = 1 b = (4-brown)/2 c = red return fun(a,b,c) 정리 : 코딩 연습을 꾸준히 해야하는 것이 느껴진 문제였다. 제곱수를 판별하는 문제나, 이차방정식의 해를 구하는 문제는 연습문제로 간간히 나오던 것이었다. 기초적인 문제가 제대로 학습이 되어있지 않으면, 문제 푸는데 굉장히 오랜 시간이 걸리지 않을까 생각했다. 기본적인 문제도 중요하다!","link":"/2019/04/12/programmers-carpet/"},{"title":"programmers the Biggest Number","text":"프로그래머스 코딩테스트 연습문제 가장 큰 수를 풀어봤다가장 큰 수 문제 설명 0 또는 양의 정수가 주어졌을 때, 정수를 이어 붙여 만들 수 있는 가장 큰 수를 알아내 주세요. 예를 들어, 주어진 정수가 [6, 10, 2]라면 [6102, 6210, 1062, 1026, 2610, 2106]를 만들 수 있고, 이중 가장 큰 수는 6210입니다. 0 또는 양의 정수가 담긴 배열 numbers가 매개변수로 주어질 때, 순서를 재배치하여 만들 수 있는 가장 큰 수를 문자열로 바꾸어 return 하도록 solution 함수를 작성해주세요. 제한 사항 numbers의 길이는 1 이상 100,000 이하입니다.numbers의 원소는 0 이상 1,000 이하입니다.정답이 너무 클 수 있으니 문자열로 바꾸어 return 합니다. 처음 이 문제를 봤을 때, ‘어 permutation 쓰면 끝이네 개꿀ㅎㅎ’ 이런 생각이 들었다.바로 itertool을 import 해서 1234567891011from itertools import permutationsdef solution(numbers): str_list = [] for i in numbers: str_list.append(str(i)) first=list(map(''.join, permutations(str_list))) int_list = [] for li in first: int_list.append(int(li)) answer = sorted(int_list, reverse=True)[0] return str(answer) 이런 코드를 작성해서 제출했다. 결과는!! 시간초과가 떠 버렸다. 효율성이 제로라는 말이다.검색해보니 permutation은 필요하지 않은 부분까지 순열 조합을 만들어 내기 때문에굉장히 비효율적인 코드라는 것을 알아냈다. ‘그렇다면 순열같이 코드를 짜되 효율적으로 작성해야 한다는 것인가?’ 라는 고찰과 함께코딩을 시작했고 하루를 날렸다. 당연했다. 문제푸는 방향이 완전히 잘못되었었다. 효율적으로 순열조합 만드는 코드를 짠다면 내가 라이브러리를 새로 만드는 수준인 것이었다. 방향을 다시 생각해봤다.사실 이 문제를 풀다보면 list에 있는 원소를 편하게 처리하기 위해 str으로 바꿔야 하고 비교하기 위해int로 다시 바꿔줘야 하는 번거로움이 있다. 그런데 굳이 int—&gt;str 이런식으로 바꿔줄 필요가 없다. 왜냐하면 정수모양의 str도 정수 값이 증가함에 따라 메모리 값도 증가하기 때문이다. 이를 id()를 통해 확인해 볼 수 있다. 12345print(id('1'))print(id('2'))print(id('3'))print(id('4'))print(id('5')) 123456Out:43800979284380098040438011123243801112884379241192 이를 이용해서 문제를 푼다면 다음과 같은 코드를 작성할 수 있다. 12345def solution(numbers): numbers = list(map(str, numbers)) numbers.sort(key=lambda x : x*3, reverse = True) answer = str(int(''.join(numbers))) return answer 결론 : 메모리 값에 대한 지식이 있다면, 훨씬 간단하게 문제를 해결할 수 있다!","link":"/2019/04/12/programmers-the-Biggest-Number/"},{"title":"Multi Armed Bandit 알고리즘?","text":"이 글의 주 소스 링크를 먼저 밝힙니다. 원작자에게 먼저 허락을 구하고 글을 작성했습니다.https://www.kaggle.com/ruslankl/how-to-deal-with-multi-armed-bandit-problem Multi Armed Bandit(MAB) 란?마케팅이든 아니면 의학적인 실험에서든 사용자에게 어떤 게 가장 좋은 것 인지 확인하는 방법은 무엇일까요?바로 Multi Armed Bandit Algorithm입니다. 특히 Thompson Sampling이라는 기법과 같이 사용된다면 굉장히 효과적으로 가장 좋은 선택이 무엇인지 알아낼 수 있습니다.(실제로 추천 알고리즘의 Cold Start 문제 등에 효과적으로 적용되고 있는 알고리즘 중 하나입니다.) 마케팅 캠페인을 한다고 합시다. 마케팅 캠페인에서는 보통 CTR(Click Through Rate)을 이용해서 광고가 효과적인지 판단하곤 합니다.(물론 마케팅 회사마다 케이스 바이 케이스이긴 합니다만, 일단 CTR이라고 가정하고 넘어가 봅시다) CTR 예시, 어떤 광고가 100번 노출되고 유저가 10번 클릭을 한다면, 이 광고의 CTR은 10/100으로 0.1입니다. 이야기가 나온김에 Regret도 같이 설명하자면, Regret은 가능한 CTR중 최고의 CTR과 지금 있는 CTR을 빼준 값입니다. 광고 A의 CTR이 0.1이고 B가 0.3이라고 할 때, A를 보여줬을 때 Regret은 $0.3 - 0.1 = 0.2$가 됩니다. 이제 광고에 대한 여러 안들이 있고, 어떤 광고가 가장 효과적인지 확인하려고 합니다. 하지만 광고에 대해서 어떤 사전 정보도 없다면 어떨까요?, 어떻게 여러 대안중에 효과적인 광고를 골라낼 수 있을까요? 이럴 때는 보통 사용하는 방법이 A/B test입니다. A/B 테스트는 말 그대로 A안과 B안을 노출시켜서(노출 비율은 정할 수 있다) 두 집단의 각각 다른 효과를 확인하기 위해서 사용되는 방법입니다. (wiki 설명 : A/B 테스트는 변수 A에 비해 대상이 변수 B에 대해 보이는 응답을 테스트하고, 두 변수 중 어떤 것이 더 효과적인지를 판단함으로써 단일 변수에 대한 두 가지 버전을 비교하는 방법이다, https://ko.wikipedia.org/wiki/A/B_%ED%85%8C%EC%8A%A4%ED%8A%B8) ‘아 그럼 A/B 테스트 하고 좋은 거 그냥 뽑으면 되겠네!’라고 생각할 수 있겠지만, 회사에서 이 테스팅을 진행한다고 생각해 봅시다. 주의할 점이 있습니다. A안을 기존에 하던 광고라고 하고 B를 실험하는 광고라고 해봅시다. A안 광고를 통해서는 꾸준히 매출을 기록하고 있고, B안은 아직 확실하지 않습니다. B가 아마 효과적이라고 하는데 아직 의심스럽습니다. 만약 테스팅을 하는데 B의 효과가 너무 떨어진다면 어떨까요? 기존 광고 효과의 목표치에 도달하지 못한다. 매출이 떨어진다. 고객이 실망하고 이탈한다. 이런 상황이 가능하지 않을까요? 그래서 MAB에서 중요한 것은, Exploration과 Exploitaion입니다. 한국어로 쉽게 말하면, 탐색하기와 뽑아먹기 입니다. 쉽게 탐색과 이용이라고 하겠습니다. Exploration은 탐색하는 것입니다. 새로운 안에 대해서 계속 테스트하고 실험해 보는 것입니다.Exploitation은 이용하는 것입니다. 즉, 기존에 효과적이었던 광고를 계속 하는 것입니다.결국 A/B테스트이든, MAB이든 중요한 것은, 이 비율을 적절하게 맞춰서 탐색을 간결하게 하고 최대한 효과적으로 이용할 수 있는 대안을 선정하는 것입니다. MAB, 즉 Multi Armed Bandit 알고리즘은 여러 대안들(슬롯머신의 Arm에서 이름을 따왔습니다)을 자동으로 실험하고 최적의 광고를 탐색과 이용사이에서 균형을 잡으면서 빠르게 찾는데 좋은 알고리즘입니다. Multi Armed Bandit 알고리즘들은 몇 가지 종류가 있습니다만 거의 모든 알고리즘은 위에서 소개한 Regret을 줄이는 것을 목표로 하고 있습니다. 주요 알고리즘들은 다음과 같습니다. Random Selection Epsilon Greedy Thompson Sampling Upper Confidence Bound (UCB1) 이 알고리즘들을 가지고 실험을 하기 전에 CTR을 사전에 설정해 둘 필요가 있습니다. 설정해둔 CTR로 광고가 주어졌을 때 클릭에 대한 시뮬레이션을 진행할 수 있습니다. 먼저 CTR을 비현실적이지만 0.45와 0.65로 설정하겠습니다. 1ACTUAL_CTR = [.45, .65] 1. Random SelectionRandom Selection은 말그대로 탐색을 하지 않고 동전 튕기기를 이용해서 앞면이면 광고0, 뒷면이면 광고1을 보여주는 알고리즘입니다. 정말 간단합니다! 123456789101112131415161718192021222324252627282930313233343536373839n=1000regret = 0total_reward = 0regret_list = []ctr = {0: [], 1:[]} #lists for collecting the calculated CTRindex_list = [] # lists for collecting the number of randomly choosen Ad#initial values for impressons and clicksimpressions = [0,0]clicks = [0,0]for i in range(n): random_index = np.random.randint(0,2,1)[0] # randomly choose the value between [0,1] index_list.append(random_index) impressions[random_index] += 1 did_click = bernoulli.rvs(actual_ctr[random_index]) if did_click: clicks[random_index] += did_click if impressions[0] == 0 : ctr_0 = 0 else : ctr_0 = clicks[0]/impressions[0] if impressions[1] == 0: ctr_1 = 0 else : ctr_1 = clicks[1]/impressions[1] ctr[0].append(ctr_0) ctr[1].append(ctr_1) ## calculate the regret and reward regret += max(actual_ctr) - actual_ctr[random_index] regret_list.append(regret) total_reward += did_click 123Ad #0 has been shown 48.4 % of the time.Ad #1 has been shown 51.6 % of the time.Total Reward (Number of Clicks): 546 CTR이야 0.65, 0.45를 잘 찾아간다지만, 중요한 것은 Regret입니다. Regret함수를 보면 함수값이 거의 100대에 육박하는 것을 볼 수 있습니다. 좀 더 좋은 알고리즘을 통해서 Regret을 낮출 필요가 있겠습니다. 마케팅 예산이 무한대라면 그냥 마구잡이로 보여주고 CTR을 측정해서, 높은 CTR을 보이는 광고안을 선정하면 그만입니다. 하지만 일개 사원인 우리들은 예산을 최대한 아껴서 좋은 효율적인 광고를 통해 매출을 극대화 해야하는 사람들입니다. 그렇다면 좀 더 좋은 알고리즘을 살펴보겠습니다. 2. Epsilon GreedyEpsilon Greedy 알고리즘은 Random Selection에서 한 단계 업그레이드 된 모델입니다.이 알고리즘은 탐색과 이용의 비율을 어느정도 조정한다는 것이 큰 특징입니다. ~15%까지는 Exploration ~85%까지 Exploitation 로직은 다음과 같습니다. 초기 몇번 까지는 Exploration(초기 값이 중요!) 각 Exploration마다 최고 점수를 받는 variant 고르기 Epsilon 설정 (1-E)%의 winning variant를 고르고 다른 옵션에는 E%를 설정한다. 1234567891011121314151617181920e = 0.05n_init = 100impressions = [0,0]clicks = [0,0]for i in range(n_init): random_index = np.random.randint(0,2,1)[0] impressions[random_index] += 1 did_click = bernoulli.rvs(actual_ctr[random_index]) if did_click: clicks[random_index] += did_click ctr_0 = clicks[0] / impressions[0]ctr_1 = clicks[1] / impressions[1]win_index = np.argmax([ctr_0, ctr_1])print('After', n_init, 'initial trials Ad #', \\ win_index, 'got the highest CTR', round(np.max([ctr_0, ctr_1]),2), '(Real CTR value is', actual_ctr[win_index], ')' 12345678910111213141516171819202122232425262728293031323334regret = 0total_reward = 0regret_list = []ctr = {0 : [], 1: []}index_list = []impressions = [0,0]clicks = [0,0]for i in range(n): epsilon_index = random.choices([win_index, 1-win_index], [1-e, e])[0] index_list.append(epsilon_index) impressions[epsilon_index] +=1 did_click = bernoulli.rvs(actual_ctr[epsilon_index]) if did_click : clicks[epsilon_index] += did_click if impressions[0] == 0 : ctr_0 = 0 else : ctr_0 = clicks[0]/impressions[0] if impressions[1] ==0 : ctr_1 = 0 else : ctr_1 = clicks[1]/impressions[1] ctr[0].append(ctr_0) ctr[1].append(ctr_1) regret += max(actual_ctr) - actual_ctr[epsilon_index] regret_list.append(regret) total_reward += did_click 123Ad #0 has been shown 6.2 % of the time.Ad #1 has been shown 93.8 % of the time.Total Reward (Number of Clicks): 642 Random Selection model보다는 훨씬 괜찮은 결과가 나왔습니다. 간단한데 결과는 훨씬 좋아지네요. 하지만 탐색시의 winning variant는 최적의 variant가 아닐 수 있습니다. 사실 suboptimal variant로 탐색 한 것입니다. 이것은 regret을 올리고 보상을 감소시킬 수 밖에 없습니다. 큰 수의 법칙에 따르면, 초기 시도를 많이 할수록, winning variant를 찾을 가능성이 커집니다. 하지만 마케팅에서는 큰 수의 법칙에 결코 따를 수가 없을 겁니다. 우리는 일개 사원… 이 알고리즘의 좋은 점은 어떤 비율을 설정할 수 있다는 것입니다. 각기 다른 epsilon값을 선택함으로써 얼마나 자주 winning ad를 보여줄 수 있는지 조정할 수 있는 것입니다. 좀 더 좋은 알고리즘을 살펴볼까요? 3. Thompson Samling 50% Exploration 50% ExploitationThompson Sampling의 탐색 부분은 Epsilon-greedy알고리즘보다 복잡합니다. 이 알고리즘은 단순히 epsilon을 정하는 것이 아니라, Beta distribution을 이용하기 때문입니다. 왜냐하면 광고를 클릭하는 것은 베르누의 과정에 속하기 때문입니다.(클릭했다, 안했다는 1,0으로 표현 가능합니다) 하지만 톰슨 샘플링은 일반적으로 어떤 분포, 어떤 파라미터에서든지 샘플링이 가능하다. 이게 가장 큰 장점 중 하나라고 생각합니다. 참고로 Beta 분포는 alpha와 beta 파라미터로 분포의 모양을 조절한다.(prior 조정 가능) 로직은 다음과 같습니다. alpha와 beta를 고른다. $\\alpha=prior+hits$, $\\beta=prior+misses$로 계산한다. 우리의 경우는 hits는 클릭 수를 말하고, misses는 클릭없이 impression된 경우를 말합니다(클릭 없는 노출). prior는 CTR에 대한 prior정보가 있으면 유용합니다. 우리는 갖고 있지 않으므로 1.0을 사용할 것 입니다.. CTR을 추정합니다. 실제 CTR을 베타 분포에서 샘플링하고 $B(\\alpha_i,\\beta_i)$에서, 추정 CTR이 가장 높은 것을 선택한다. 2-3을 반복한다. 1234567891011121314151617181920212223242526272829regret = 0total_reward = 0regret_list = []ctr = {0 : [], 1: []}index_list = []impressions = [0,0]clicks = [0,0]priors = (1,1)#randomly choose the first shown adwin_index = np.random.randint(0,2,1)[0] for i in range(n): impressions[win_index] += 1 did_click = bernoulli.rvs(actual_ctr[win_index]) if did_click : clicks[win_index] += did_click ctr_0 = random.betavariate(priors[0] + clicks[0], priors[1] + impressions[0] - clicks[0]) ctr_1 = random.betavariate(priors[1] + clicks[1], priors[1] + impressions[1] - clicks[1]) win_index = np.argmax([ctr_0, ctr_1]) index_list.append(win_index) ctr[0].append(ctr_0) ctr[1].append(ctr_1) regret += max(actual_ctr) - actual_ctr[win_index] regret_list.append(regret) total_reward += did_click 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556x = np.arange (0, 1, 0.01)y = beta.pdf(x, priors[0]+clicks[0], priors[1] + impressions[0] - clicks[0])y /= y.max() ## normalizedata1 = go.Scatter(x=x, y=y, name='(Ad #0)', marker = dict(color=('rgba(10, 108, 94, 1)')), fill='tozeroy', fillcolor = 'rgba(10, 108, 94, .7)')data2 = go.Scatter(x = [actual_ctr[0]] * 2, y = [0, 1], name = 'Actual CTR #0 Value', mode='lines', line = dict( color = ('rgb(205, 12, 24)'), width = 2, dash = 'dash'))y = beta.pdf(x, priors[0]+clicks[1], priors[1] + impressions[1] - clicks[1])y /= y.max()data3 = go.Scatter(x=x, y=y, name='(Ad #1)', marker = dict(color=('rgba(187, 121, 24, 1)')), fill='tozeroy', fillcolor = 'rgba(187, 121, 24, .7)')data4 = go.Scatter(x = [actual_ctr[1]] * 2, y = [0, 1], name = 'Actual CTR #1 Value', mode='lines', line = dict( color = ('rgb(205, 12, 24)'), width = 2, dash = 'dash'))layout = go.Layout(title='Beta Distributions for both Ads', xaxis={'title': 'Possible CTR values'}, yaxis={'title': 'Probability Density'})fig = go.Figure(data=[data1, data2, data3, data4], layout=layout)# fig = tools.make_subplots(rows=1, cols=2, print_grid=False, shared_xaxes=False,# subplot_titles=('Beta Distribution (Ad #0)','Beta Distribution (Ad #1)'))# fig.append_trace(data1, 1, 1)# fig.append_trace(data2, 1, 1)# fig.append_trace(data3, 1, 2)# fig.append_trace(data4, 1, 2)# fig['layout'].update(showlegend=False)iplot(fig, show_link=False) 123Ad #0 has been shown 4.2 % of the time.Ad #1 has been shown 95.8 % of the time.Total Reward (Number of Clicks): 647 지금까지 본 regret중 가장 낮은 regret을 확인할 수 있습니다. 이 알고리즘은 지속적으로 탐색합니다. 자연스럽게 Beta distribution을 이용해 가장 가치가 높은 샘플을 가져와서 이용할 수 있습니다. Beta distribution Ad#1은 더 높고 좁은 분포를 갖고 있습니다. 이것은 샘플된 값들이 항상 Ad#0보다 높을 것이라는 것을 의미합니다. 결국 Ad#1이 우리가 원하는 광고임을 빠르게 파악할 수 있습니다. UCB (Upper Confidence Bound) 50% Exploration 50% ExploitationThompson Sampling과 달리 UCB는 불확실성에 더 초점을 맞춥니다. 한 variant에 대해 더 불확실 할 수록, 더 탐색을 해야만 하는 알고리즘입니다. 알고리즘은 가장 높은 UCB가 나오는 variant를 선택합니다. UCB를 통해 가장 높은 보상이 나올 것이라고 생각되는 variant를 고르는 것입니다. UCB = \\bar x_i + \\sqrt{\\frac{2 \\cdot \\log{t}}{n}}이 수식을 따르며 뒤에 term에 따라 UCB의 파생 알고리즘들이 등장하게 됩니다. $\\bar x_i$ CTR이 i번째 단계일 때,$t$ - 모든 variant에 대해 impression을 다 더한 숫자이다.$n$ - 선택된 variant에 대해 impression을 다 더한 숫자이다. 로직은 직관적입니다. UCB를 모든 변량들에 대해 구합니다. 가장 높은 UCB를 가진 변량을 선택합니다. 1번으로 다시 돌아갑니다. 123456789101112131415161718192021222324252627282930313233regret = 0 total_reward = 0regret_list = [] index_list = [] impressions = [0,0] clicks = [0,0]ctr = {0: [], 1: []}total_reward = 0for i in range(n): index = 0 max_upper_bound = 0 for k in [0,1]: if (impressions[k] &gt; 0): CTR = clicks[k] / impressions[k] delta = math.sqrt(2 * math.log(i+1) / impressions[k]) upper_bound = CTR + delta ctr[k].append(CTR) else: upper_bound = 1e400 if upper_bound &gt; max_upper_bound: max_upper_bound = upper_bound index = k index_list.append(index) impressions[index] += 1 reward = bernoulli.rvs(actual_ctr[index]) clicks[index] += reward total_reward += reward regret += max(actual_ctr) - actual_ctr[index] regret_list.append(regret) 123Ad #0 has been shown 19.2 % of the time.Ad #1 has been shown 80.80000000000001 % of the time.Total Reward (Number of Clicks): 596 결과는 다음과 같습니다. Regret이 생각보다 높네요, UCB알고리즘도 현업에서 자주 사용하는 알고리즘입니다만, 이 알고리즘은 가장 기본적인 알고리즘이기 때문에 그런 것 같습니다. 결론 및 성능 비교이제 살펴봤던 모든 알고리즘의 성능을 비교해 볼 시간입니다. 기대가 되네요, 나온 결과를 시각화를 해서 살펴 보겠습니다. 1000번의 시도에 어떤 광고를 얼마나 노출시켰는 지에 대한 막대그래프입니다.Random Selection은 CTR이 낮은 광고를 너무 많이 노출 시켰네요, 그 다음은 UCB1, Epsilon Greedy, Thompson Sampling 순 입니다. Thompson Sampling이 가장 좋네요! 하지만 놀라운 것은 Epsilon Greedy입니다. 정말 간단한 알고리즘인데 성능이 좋군요. 다음 자료는 Regret에 대한 것입니다. 시도가 늘어날 수록, Random Selection이나 UCB는 쭉 쭉 증가하는 것이 보입니다. 하지만 Thomspon Sampling은 굉장히 안정적으로 Regret이 유지되네요. 마지막은 1000번의 시도에서 총 몇번의 클릭을 받았는가에 대한 시각화 자료입니다. 클릭이 많다면 더 효과적으로 실험을 하면서 광고를 했다고 할 수 있겠네요. 역시 Thompson Sampling이 가장 많은 클릭 수를 얻었습니다. 그 다음은 Epsilon Greedy, UCB1, Random Selection 순 입니다. 물론 Regret이 낮다고 가장 높은 보상이 있는 것은 아닙니다. 이 실험에서는 우연히 Thompson Sampling이 Regret도 낮고, 높은 보상을 얻었습니다. 알고리즘은 적절한 광고를(right ads) 보여줄 뿐 이고, 유저가 클릭하는 것은 보장하지 않습니다. 일반적으로 Thompson Sampling이 좋은 결과를 보여줍니다. 하지만 다른 알고리즘을 보면서 어떻게, 그리고 언제 그 알고리즘이 유용할지 생각해봐야 합니다. 어떤 문제를 풀 지는 각 개인 마다 다르기 때문에, 여러 알고리즘들 중에서 문제에 적합한 것을 선택할 수 있어야 합니다. 어떤 사전 정보를 갖고 있고, 알고리즘 적용 후에 어떤 정보를 알고싶은지를 명확하게 설정하는 것이 더 중요하다고 할 수 있겠습니다.","link":"/2019/07/18/Bandit/"},{"title":"클래스에 대해서 알아보자","text":"Class는 객체지향 프로그래밍에서 가장 중요하고도 까다롭다.흔히 말하는 상속이 무엇인지, 어떤 상황에서 상속을 하는지, 상속을 할 수 없을 때는객체 관계를 어떻게 표현하는지 알아보자. 클래스 관계클래스 관계를 나타내는 방법으로 IS-A와 HAS-A가 있다. 1.1 IS-A : 상속IS-A는 ‘은 ~의 한 종류다’를 말한다. 노트북과 컴퓨터를 예를 들어보자. 노트북은 컴퓨터의 한 종류일까?그렇다. 이런 관계일 경우 Computer와 laptop 클래스는 IS-A관계라고 말할 수 있다.IS-A관계 인지 아닌지 분간이 안된다면, ‘한 종류다’라는 의미가 있는지 생각해 보자. 이런 IS-A관계를 프로그램에서 표현할 때는 상속을 사용한다. 상속은 IS-A관계에서 설계가 쉽다. 상속을 하는 클래스와 상속을 받는 클래스를 나눠 볼 수 있는데 표현은 다음과 같다. 상속을 하는 클래스 기본 클래스 부모 클래스 슈퍼 클래스 상속을 받는 클래스 파생 클래스 자식 클래스 서브 클래스 코드로 laptop과 computer 클래스를 설계해 보자.12345678910class Computer: def __init__(self, cpu, ram): self.CPU = cpu self.RAM = ram def browse(self): print('browse') def work(self): print('work') 이 코드에서 인스턴스 멤버는 CPU와 RAM이다. 인스턴스 메서드는 browse()와 일을 하는 work()이다.노트북은 컴퓨터의 모든 멤버와 메서드를 가진다. 노트북에도 CPU와 RAM이 있고, 같은 일을 하기 때문이다.어떤 객체가 다른 객체의 모든 특성과 기능을 가진 상태에서 그 외에 다른 특성이나 기능을 가지고 있다면 상속해서 쓰는게 편하다. 노트북 클래스를 설계해보자1234567class Laptop(Computer): def __init__(self, cpu, ram, battery): super().__init__(cpu, ram) self.battery = battery def move(self, to): print('move to {}'.format(to)) 노트북의 클래스 옆에 Computer가 붙은게 보인다. 이는 컴퓨터 클래스를 상속하겠다는 뜻이다.이렇게 되면 노트북은 컴퓨터 클래스가 가진 모든 멤버와 메서드를 가지게 된다. 노트북도 browse()와work()가 가능하다는 말이다. 확실히 손이 덜 피곤하다는 게 느껴질 것이다. super는 무엇일까? 이것은 기본 클래스를 의미한다. 기본 클래스는 위에서 써놨듯이, 상속을 하는 클래스, 즉컴퓨터 클래스를 가리킨다. CPU와 RAM은 기본 클래스의 생성자를 이용해 초기화가 되었기 때문에 남은 한 멤버인 battery만 할당해 주면 된다. 그리고 노트북에만 있는 move메서드를 입력해준다. 이렇게 되면, 노트북만의 메서드를 하나 갖게 된다. 테스트 코드는 다음과 같다.123456if __name__ == \"__main__\": lap = Laptop('intel', 16, 'powerful') lap.browse() lap.work() lap.move('office') ` 1.2 HAS-A : 합성 또는 통합HAS-A관계는 ‘~이 ~을 가진다 혹은 포함한다’를 의미한다. Computer는 CPU와 RAM을 가지는데,여기서 이 관계를 HAS-A관계라고 부를 수 있다. 경찰과 총의 관계를 생각해보자. 경찰은 총을 가지고 있다. 경찰과 총은 HAS-A관계가 성립한다.주의해야할 점이 있는데, HAS-A관계에는 합성과 통합이라는 표현방법이 존재한다. 컴퓨터와 CPU의 관계를 합성으로 표현하고, 경찰과 총의 관계를 통합으로 표현해보자.12345678910class CPU : pass class RAM : pass class Computer : def __init__(self): self.cpu = CPU() self.ram = RAM() Computer는 인스턴스 멤버 cpu를 가진다. 생성자에서 CPU 객체를 생성해서 멤버 cpu에게 할당한다.이렇게 되면 Computer라는 객체가 생성이 될 때, CPU와 RAM이 같이 생성이 되고, 사라질때 같이 사라지게 된다. 이 둘의 관계는 매우 강한 관계를 맺고 있다고 할 수 있다. 이런 관계를 합성이라고 한다. 경찰과 총의 관계를 살펴보자123456789101112131415161718192021222324class Gun : def __init__(self, kind): self.kind = kind def bang(self): print('bang bang') class Police : def __init__(self): self.gun = None def acquire_gun(self, gun): self.gun = gun def release_gun(self): gun = self.gun self.gun = None return gun def shoot(self): if self.gun: self.gun.bang() else : print(\"Unable to shoot\") 이 관계에서는 Police 객체가 만들어질 때 Gun 객체를 가지고 있지 않다. 이후 acquire_gun()메서드를통해서 Gun 객체를 멤버로 가지게 된다. 이 관계 역시 HAS-A이다. 또한 release_gun()으로 가진 총을반납할 수도 있다. 이 두 메서드를 이용해 총을 가진 경찰, 총이 없는 경찰 모두를 표현할 수 있다. 하지만 컴퓨터 클래스와 다른 점은, 경찰은 언제든지 Gun을 가질 수 있고 해제할 수 있다는 점이다.관계가 컴퓨터에 비해 훨씬 약하다는 느낌이 들 것이다. 이런 약한 관계를 통합이라고 부른다. 2. 메서드 오버라이딩과 다형성(Polymorphism)OOP에서 가장 중요한 개념은 다형성이다(polymorphism). 나는 이 ‘폴리몰피즘’에 대해 노이로제가 걸렸었던 적이 있다.고려대에서 진행한 Bigdata X Campus 교육에서였다. 파이썬 강의를 들으면서 강사는 “뽈리몰피즘! 뽈리몰피즘이 중요하죠!” 라고 열변을 토했고, 매 강의마다 항상 강조되었었다.‘도대체 polymorphism이 뭐길래’ 라는 생각이 들었었고, 이 책을 보면서 그 갈증이 어느정도 해결이 되었다. 다형성이란 ‘상속 관계에 있는 다양한 클래스의 객체에서 같은 이름의 메서드를 호출할 때, 각 객체가 서로 다르게 구현된 메서드를 호출함으로써 서로 다른 행동, 기능, 결과를 가져오는 것’을 의미한다. 이를 구현하기 위해서는 파생 클래스 안에서 상속받은 메서드를 다시 구현하는 메서드 오버라이딩이라고 부른다. 2.1 메서드 오버라이딩먼저 코드를 살펴보자.123456789101112131415class CarOwner: def __init__(self, name): self.name = name def concentrate(self): print('{} can not do anything else'.format(self.name))class Car: def __init__(self, owner_name): self.owner = CarOwner(owner_name) def drive(self): self.owner.concentrate() print('{} is driving now.'.format(self.owner.name)) drive()메서드를 보면 Car 객체는 반드시 차 주인인 CarOwner객체가 운정해야 하고 차 주인은 운전에만집중해야 한다. drive()메서드가 나오자마자 CarOwner객체의 concentrate()메서드를 호출해서 차 주인이 운전외에는 아무것도 못하게 한다. 이번에는 자율주행차를 만들어보자123class SelfDrivingCar(Car): def drive(self): print('Car is driving by itself') 자율주행차에는 상속받은 drive가 어울리지 않는다. 새롭게 바꿔줄 필요가 있다. drive()메서드를 제외하고는 나머지 멤버와 메서드는 그대로 사용한다. 이러한 경우에는 drive()메서드만 클래스 안에서 재정의해준다. 이렇게 클래스 안에서, 맘에 들지 않는 메서드를 재정의 하는 것을 메서드 오버라이딩이라고 한다.자율주행차의 차 주인은 더 이상 운전에 집중하지 않아도 된다. 따라서 오버라이딩된 drive()메서드에서는concentrate()를 호출하지 않는다. 여기서 정리해보자면, drive()메서드는 같은 이름이지만 객체에 따라 다른 기능을 하게 된다. 이처럼같은 이름의 메서드를 호출해도 호출한 객체에 따라 다른 결과를 내는 것을 다형성이라고 한다. 2.2 다형성다형성에 대해 좀 더 깊이 알아보자.12345678910111213141516171819202122232425262728class Animal: def eat(self): print('eat something')class Lion(Animal): def eat(self): print('eat meat') class Cow(Animal): def eat(self): print('eat grass') class Human(Animal): def eat(self): print('eat meat and grass')if __name__ == \"__main__\": animals = [] animals.append(Lion()) animals.append(Cow()) animals.append(Human()) for animal in animals: animal.eat() 이 코드의 Animal 클래스에는 eat()메서드가 있다. 모든 동물은 반드시 먹어야 한다는 가정이다.하지만 동물마다 먹는 종류는 다르기 때문에 육식 동물의 대표로 사자를 설정했고, 초식 동물의 대표로 소를설정했다. 그리고 잡식 동물로 사람을 설정했다. 나는 소고기를 쌈싸먹는 것을 좋아한다. 코드의 반복문의 마지막 부분에서 animal.eat()은 다형성을 구현한 부분이다. animals 리스트에서 객체를 하나씩 불러와 eat()메서드를 호출할 때, 메서드를 호출한 쪽에서는 육식동물인지 초식동물인지 잡식인지 고민할 필요가 없다. 각 객체는 오버라이딩된 메서드를 호출하기 때문이다. 그렇게 되면 여기서는 그냥 무엇인가를 먹는 동물은 없다. 그러니까 Animal은 eat something하는 게 있는데 사용하는 동물이 아무도 없다. 안써버리자니 문제가 되고, 뭔가 낭비같다. 이럴 때는 Animal 클래스를 추상 클래스로 만들면 된다. 추상 클래스는 독자적으로 인스턴스를 만들 수 없고 함수의 몸체가없는 추상 메서드를 하나 이상 가지고 있어야 한다. 또한 이 클래스를 상속받는 파생 클래스는 추상 메서드를 반드시 오버라이딩 해야한다. 당연히 아무것도 없으니까! Animal을 추상 클래스로 변경해보자.1234567from abc import *class Animal(metaclass = ABCMeta): @abstractmethod def eat(self): pass ... 먼저 abc모듈을 가져온다.(abstract base class) 그 후 @abstractmehod 데코레이터를 붙여준다.여기서 메서드 구현하는 부분을 pass로 비워두면 eat()은 추상 메서드가 된다.이제 Animal을 상속받는 모든 파생 클래스는 eat()을 오버라이딩 해야한다. 클래스 설계 예제클래스를 설계할 때느느 다음 두가지를 고려해야 한다. 공통 부분을 기본 클래스로 묶는다. 부모가 추상클래스인 경우를 제외하고, 파생 클래스에서 기본 클래스의 여러 메서드를 오버라이딩한다면 파생 클래스는 만들지 않는 것이 좋다. Character 클래스 만들기게임 캐릭터를 만들어보면서 클래스를 정리해보자.게임에 등장하는 캐릭터는 플레이어 우리 자신과 몬스터이다.모든 캐릭터(추상 클래스)는 다음과 같은 특성을 지닌다. 인스턴스 멤버 : 이름, 체력, 공격력을 가진다. 인스턴스 메서드 : 공격, 공격당했을 때는 피해를 입는다.(모두 추상 메서드로 구현한다.) 123456789101112131415161718from abc import *class Character(metaclass = ABDMeta): def __init__(self, name, hp, power): self.name = name self.hp = hp self.power = power @abstractmethod def attack(self, other, attack_kind): pass @abstractmethod def get_damage(self, power, attack_kind): pass def __str__(self): return '{} : {}'.format(self.name, self.HP) 3.2 Player 클래스 만들기플레이어는 다음과 같은 특성이 있다. 추가되는 멤버 : 플레이어는 다양한 공격 종류를 담을 수 있는 기술 목록이 있다. attack : 플레이어는 공격할 때 공격 종류가 기술 목록 안에 있다면 상대 몬스터에게 피해를 입힌다. get_damage : 플레이어가 피해를 입을 때 몬스터의 공격 종류가 플레이어의 기술 목록에 있다면 몬스터의 공격력이 반감되어 hp의 절반만 깎인다. 12345678910111213141516171819class Player(Character): def __init__(self, name = 'player', hp = 100, power = 10, *attack_kinds): super().__init__(name, hp, power) self.skills = [] for attack_kind in attack_kinds: self.skills.append(attack_kind) def attack(self, other, attack_kind): if attack_kind in self.skills: other.get_damage(self.power, attack_kind) def get_damage(self, power, attack_kind): if attack_kind in self.skills: self.HP -= (poewr/2) else : self.HP -= power 코드에서 살펴보면 플레이어는 캐릭터를 상속했다. 3.3 Monster, IceMonster, FireMonster 클래스 만들기몬스터에는 불 몬스터와 얼음 몬스터가 있으며 다음과 같은 특징이 있다. 추가되는 멤버 : 공격 종류를 가진다. 불 몬스터는 Fire, 얼음 몬스터는 Ice를 가진다. 공통 메서드 : 두 몬스터는 같은 행동을 한다. attack : 공격 종류가 몬스터의 속성과 같다면 공격한다. get_damage : 몬스터는 자신과 속성이 같은 공격을 당하면 체력이 오히려 공격력만큼 증가한다. 그렇지 않으면 체력이 공격력만큼 감소한다. 여기서 고민해야 할 점이 있다. FireMonster 클래스와 IceMonster 클래스를 Character 클래스에서 상속받아 구현할지, Moster 클래스라는 부모 클래스를 따로 만들어야 할지.설명에 따르면 추가되는 멤버도 겹치고, fireball()메서드를 제외한 나머지 메서드도 겹친다. 그러면 공통되는 부분을 기본 클래스로 만들고 이를 상속받는 게 좋을 것 같다. 몬스터를 만들고 몬스터는 캐릭터 클래스를 상속받을 것이다. 그리고 몬스터 클래스를 상속받아 각 몬스터를 만들어보자. 1234567891011121314151617181920212223242526272829303132class Monster(Character): def __init__(self, name, hp, power): super().__init__(name, hp, power): self.attack_kind = 'None' def attack(self, other, attack_kind): if self.attack_kind == attack_kind: other.get_damage(self.power, attack_kind) def get_damage(self, power, attack_kind): if self.attack_kind == attack_kind: self.HP += power else : self.HP -= power def get_attack_kind(self): return self.attack_kind class IceMonster(Monster): def __init__(self, name = 'Ice monster', hp = 50, power = 10) super().__init__(name, hp, power) self.attack_kind = 'ICE' class FireMonster(Monster): def __init__(self, name = 'Fire monster', hp= 50, power = 20) super().__init__.(name, hp, power) self.attack_kind = 'FIRE' def firebreath(self): print('firebreath') 불 몬스터와 얼음 몬스터는 몬스터 클래스를 상속 받았고 추가되거나 변경되는 부분만 수정했다. 12345678910111213141516171819202122232425if __name__ == \"__main__\": player = Player('sword master', 100, 30, 'ICE') monsters = [] monsters.append(IceMonster()) monsters.append(FireMonster()) for monster in monsters : print(monster) for monster in monsters: player.attack(monster, 'ICE') print('after the plater attacked') for monster in monsters: print(monster) print('') print(player) for monster in monsters: monster.attack(player, monster.get_attack_kind()) print('after monsters attacked') print(player) 4. 연산자 오버로딩연산자 오버로딩은 클래스 안에서 메서드로 연산자를 새롭게 구현하는 것으로 다형성의 특별한 형태이다.연산자 오버로딩을 사용하면 다른 객체나 일반적인 피연산자와 연산을 할 수 있다. 12345678910111213141516171819class Point: def __init__(self, x=0, y=0): self.x = x self.y = y def set_point(self, x, y): self.x = x self.y = y def get_point(self): return self.x, self,y def __str__(self): return '({x}, {y})'.format(x = self.x, y = self.y) if __name__ == \"__main__\": p1 = Point(2,2) p2 = p1 + 3print(p2) 결과를 실행해 보면 에러가 발생할 것이다. Point와 int 객체 사이는 덧셈을 할 수 없다고 나온다. 123456789 def __add__(self, n): x = self.x + n y = self.y + n return Point(x,y) if __name__ == \"__main__\": p1 = Point(2,2) p2 = p1 + 3 print(p2) 이렇게 add메서드를 추가해보자. 예약한 함수를 사용해서 x좌표와 y좌표에 인자 n을 더한 새로운 x와 y로새로운 객체를 만들어 반환한다.실행 결과는 (5,5)가 나오게 된다. 1234if __name__ == \"__main__\": p1 = Point(2,2) p2 = 3 + p1 print(p2) 계산이 안된다. int와 Point의 순서가 바뀌면 에러가 발생한다.연산자 오버로딩을 하나 더 해주자. 123456789 def __radd__(self, n): x = self.x + n y = self.y + n return Point(x,y)if __name__ == \"__main__\": p1 = Point(2,2) p2 = 3 + p1 print(p2) 1(5,5) __radd__()메서드를 이용해서 연산이 돌아가도록 만들었다.","link":"/2019/01/28/class/"},{"title":"지도 학습과 쉬운 모델을 사용하는 이유에 대해서","text":"출처 : [파이썬 라이브러리를 활용한 머신러닝] 지도 학습에 대해서 알아보자도마뱀 책의 지도 학습에는 상당한 분량의 내용이 있지만, 그 중 쉬운 모델, 선형모델과 나이브 베이즈 모델에 대해서 살펴볼 것이고, 왜 굳이 쉬운 모델을 사용해야 하는지에 대해서 알아보려 한다. 그 전에 잠깐 KNN(K-Nearest Neighbors)알고리즘에 대해서 살펴보자. K-NN (k-Nearest Neighbors)K-NN알고리즘은 가장 간단한 머신러닝 알고리즘 중 하나이다.이 알고리즘은 말 그대로 훈련 데이터셋에서 가장 거리가 가까운 데이터 포인트, ‘최근접 이웃’을 찾는다. K-NN을 이용해서 분류와 회귀를 할 수 있다.간단히 분류만 알아보자 123from sklearn.model_selection import train_test_splitX, y = mglearn.datasets.make_forge()X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0) 12from sklearn.neighbors import KNeighborsClassifierclf = KNeighborsClassifier(n_neighbors=3) 데이터를 불러왔고, 알고리즘을 임포트 해서 인스턴스화 하였다.여기서 n_neighbors=3이라고 설정했는데 이 뜻은 데이터 포인트 주위의 이웃을 세 개만 보겠다는 뜻이다. 이웃의 수는 적을 수록 모델을 복잡하게 만드는 것이며, 많아질 수록 모델을 단순하게 만든다. 이웃의 수가 많아지게 되면 결정 경계는 부드러워진다. 이웃의 수가 하나라면, 이 모델은 훈련 데이터에서 완벽하게 예측을 할 수 있게 된다. 하지만 이웃의 수가 늘어나면, 모델은 단순해지고 훈련 데이터의 정확도는 떨어지게 된다. 일반화 되는 것이다. 1clf.fit(X_train, y_train) 1print('prediction of test set : {}'.format(clf.predict(X_test))) 이렇게 예측을 하고 결과값을 뽑아낼 수 있다. 예측을 하는 방법은, 테스트 세트의 각 데이터 포인트에 대해 훈련 세트에서 가장 가까운 이웃을 계산하고 가장 많은 클래스를 찾는 방식이다. 정리를 해보자면, K-NN 분류기의 중요변수는 두 개이다. 데이터 포인트 사이의 거리를 재는 방법 이웃의 수거리를 재는 방법은 주로 유클리디안 거리 방식을 사용한다. 일반적으로 노름(Norm)이라고 알려져 있는 방식이다. K-NN의 장점은 이해하기 매우매우매우 쉬운 모델이라는 것이다. 그리고 별로 조정할 것 없이 꽤 성능이 잘 나온다. 그래서, 이 알고리즘은 복잡한 알고리즘을 적용하기 전에 시도할 수 있는 좋은 시작점이 될 수 있다. K-NN을 한번 돌려보면서 데이터를 파악해 볼 수 있는 것이다. 하지만 K-NN은 데이터 셋이 매우 커지면 예측이 느려진다. 또한 전처리하는 과정이 중요하다. 유클리디안 거리를 재는 방식이기 때문에, 특성마다의 값의 범위가 달라지면 범위가 작은 특성에 영향이 매우 커지게 된다. 그래서 K-NN을 사용하기 전에는 Scaling해주는 작업이 필요하다. 또한 K-NN은 많은 특성을 가진 데이터 셋에는 잘 동작하지 않고, Sparse한 데이터 셋에서는 잘 동작하지 않는다. 결국 전처리가 중요한 모델이다. K-NN은 그래서 단점이 꽤 있는 모델 중에 하나이다. 이해하긴 쉬워도 예측이 느린편이고, 많은 특성을 처리해야 하는 작업에 어울리지 않아, 현업에서는 잘 사용되지 않는다. 그래서 단점이 별로 없는 모델을 사용하게 되는데, 그것이 바로 선형 모델이다. 선형 모델, Linear Model회귀의 경우 선형 모델을 위한 일반화된 예측 함수는$\\hat{y}$ = $w$$\\times$ $\\vec{x}$ + b 이다.여기서 w는 기울기이고 b 는 절편값이 된다. 회귀를 위한 선형 모델은 특성이 하나일 땐 직선, 두 개일 땐 평민이며, 더 높은 차원일 경우에는 hyperplane이 되는 특징을 갖고 있다. 특성이 많은 데이터 셋이라면 선형 모델은 매우 훌륭한 성능을 낼 수 있다. 특히 훈련 데이터보다 특성이 더 많은 경우에 선형 함수로 모델링이 잘 된다. 최소제곱법선형 회귀는 OLS(Ordinary Least Squares)라고도 불리며, 가장 간단하고 오래된 회귀용 알고리즘이다. 선형 회귀는 MSE(Mean Square Error)를 최소화 하는 파라미터 w와 b를 찾는다. 평균제곱오차는 예측값과 타깃값의 차이를 제곱하여 더한 후에 샘플의 개수로 나눈 것이다. 선형 회귀는 매개 변수가 없다, 이것은 장점이기도 하고 복잡도를 제어할 별 방법이 없다는 것을 뜻하기도 한다. 선형 모델은 다음과 같이 만들 수 있다. 12345from sklearn.linear_model import LinearRegressionX, y = mglearn.datasets.make_wave(n_samples=60)X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=43)lr = LinearRegression().fit(X_train, y_train) 데이터 셋이 복잡해 지면서 모델은 과대적합이 될 가능성이 높아진다. 이럴 때 규제가 필요하게 되는데,주로 사용되는 모델은 릿지 회귀이다. Ridge Regularization릿지 회귀에서의 가중치 선택은 훈련 데이터를 잘 예측하기 위해서와 더불어 추가 제약 조건을 만족시키기 위한 목적도 있다. 가중치의 절댓값을 가능한 한 작게 만드는 것이다. 즉, w의 모든 원소가 0에 가깝게(0이 되지는 않는다.) 되길 원한다. 이렇게 되면, 모든 특성이 출력에 주는 영향을 최소한으로 만들게 된다.(기울기가 작아진다.) 이것을 Regularization이라고 부른다. Ridge Regularization은 L2규제라고 부르기도 한다.L1은 Lasso이다. 123from sklearn.linear_model import Ridgeridge = Ridge().fit(X_train, y_train)print('훈련 세트 점수 :{:2f}'.format(ridge.score(X_train, y_train))) 릿지 회귀는 다음과 같이 사용할 수 있다.릿지를 사용하게 되면 모델이 더 일반화 되어서 테스트 셋에서 성능이 좋게 된다.사용자는 하이퍼 파라미터 alpha로 훈련세트의 성능 대비 모델을 얼마나 단순화할지를 정할 수 있다. alpha값을 높이면 규제를 높여서 일반화에 도움을 주는 것이고, alpha를 낮추면 규제를 낮춰서 모델을 복잡하게 만드는 것이다. Lasso라쏘는 L1규제라고도 하며, 릿지와의 차이점은, 라쏘는 어떤 계수는 정말 0이 된다는 점이다. 모델에서 완전히 제외되는 특성이 발생한다. Feature Selection이 자동적으로 이루어지게 되는데, 중요특성을 뽑고 싶다면 Lasso를 활용해도 된다. 실제로 라쏘와 릿지 중에서는 릿지를 더 선호한다. 하지만 특성이 많고 그중 일부분만 중요하다면 Lasso가 더 좋을 수도 있다. 또한 특성이 줄어들어 쉽게 해석할 수 있기 때문에, 라쏘가 사용되는 경우도 있다. 하지만 최상의 방법은 Elastic Net으로 L1과 L2를 섞은 것이다. 둘의 매개변수를 잘 조정하면 최상의 결과가 도출될 수 있다. Naive Bayes 분류기나이브 베이즈는 선형 모델과 매우 유사하다. 훈련 속도도 빠르고 단순하지만 성능이 좋은 편이다. 하지만 일반화 성능은 조금 뒤진다. scikit-learn의 나이브 베이즈에는 Gaussian, Multinomial, Bernoulli 총 세가지가 구현되어 있다. Gaussain은 연속적인 어떤 데이터에도 적용할 수 있고, Bernoulli는 이진 데이터를, Multinomial은 카운트 데이터에 적용된다. 가우시안은 연속, 베르누이와 다항은 이산 데이터에 적용된다고 생각하면 된다. MultinomialNB와 BernoulliNB는 모델의 복잡도를 조절하는 알파 하이퍼파라미터를 갖고 있다. 알파가 주어지면 알고리즘이 모든 특성에 양의 값을 가진 가상의 데이터 포인트를 알파 개수만큼 추가한다. 이렇게 되면 통계 데이터가 완만해진다. 알파가 크면 더 완만해지고 모델의 복잡도는 낮아진다. 하지만 알파는 성능에 크게 기여하지 않는다. GaussianNB는 대부분 고차원인 데이터셋에 사용하고, 다른 나이브 베이즈 모델들은 텍스트 같은 희소한 데이터를 카운트 하는데 사용된다. MultinomialNB는 0이 아닌 특성이 많은 데이터셋(큰 문서)에서 Bernoulli보다 성능이 좋다. 나이브 베이즈 모델과 선형 모델의 장단점은 비슷하다. 훈련과 예측 속도가 빠르고 훈련 과정을 이해하기가 쉽다. 일단 한번 빠르게 돌려보고 과정을 보면서 데이터에 대해 이해할 수 있게 된다는 것이다. 또한 희소한 고차원 데이터에서 잘 작동하고 비교적 하이퍼 파라미터에 민감하지 않다. 선형 모델로 일단 한번 훅 돌려보고 너무 오래 걸린다 싶으면 나이브 베이즈 모델을 시도해서 돌려볼만 하다.","link":"/2019/02/28/supervised-learning/"},{"title":"객체 지향 프로그램에 대해서 알아보자","text":"Reference : https://aisolab.github.io/computer%20science/2018/08/09/CS_Object-oriented-programming/ [김보섭님 블로그] 1. 프로그래밍 패러다임프로그래밍 패러다임으로는 다음 3가지가 대표적이다. 절차 지향 프로그래밍(procedural programming) 객체 지향 프로그래밍(object-oriented programming) 함수형 프로그래밍(fuctional programming) 2. 절차 지향 프로그래밍절차를 의미하는 procedure는 서브 루틴, 메서드, 함수라고 불린다.함수는 입력을 받아 연산을 하고 출력을 내보낸다. 함수를 한 번 정의해 두면 다시 호출해서 쓸 수 있고 이름으로 어떤 일을 하는지 쉽게 알 수 있다.이처럼 함수를 사용해 프로그래밍 하는 것을 절차 지향 프로그래밍이라고 한다. 3. 절차 지향으로 학급 성적 평가 프로그램 만들기우리가 담임 선생님이 되었다고 가정하고 엑셀에 저장된 학생들의 점수를 이용해 평균과 표준편차를 구하고 전체의 평균과 비교하여 평가하는 프로그램을 만들어 보자. 3.1 openpyxl모듈 설치하기pip install openpyxl 을 입력한다. 3.2 openpyxl 모듈로 데이터 읽어 들이기exam.xlsx name score greg 95 john 25 yang 50 timothy 15 melisa 100 thor 10 elen 25 mark 80 steve 95 anna 20 function.py12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152from openpyxl import load_workbookfrom functools import reduceimport mathdef get_data_from_excel(filepath): wb = load_workbook(filename = filepath) ws = wb.active rows = ws.rows raw_data = {name_cell.value : score_cell.value for name_cell, score_cell in rows} scores = raw_data.values() return scoresdef get_average(scores): avrg = reduce(lambda score1, score2 : score1 + score2, scores) / len(scores) return avrgdef get_variance(scores, avrg): tmp = 0 for score in scores: tmp += (score - avrg)**2 else: var = tmp / len(scores) return vardef get_std_dev(var): std_dev = round(math.sqrt(var),1) return std_devdef evaluate_class(avrg, var, std_dev, total_avrg, total_std_dev): \"\"\" evaluate_class(avrg, var, std_dev, total_avrg, total_std_dev) -&gt; None Args: avrg : 반평균 var : 반분산 std_dev : 반표준편차 total_avrg : 학년평균 total_std_dev : 학년분산 \"\"\" print(\"평균:{}, 분산:{}, 표준편차:{}\".format(avrg, var, std_dev)) if avrg &lt; total_avrg and std_dev &gt; total_std_dev: print('성적이 너무 저조하고 학생들의 실력 차이가 너무 크다.') elif avrg &gt; total_avrg and std_dev &gt; total_std_dev: print('성적은 평균 이상이지만 학생들의 실력 차이가 크다. 주의 요망!') elif avrg &lt; total_avrg and std_dev &lt; total_std_dev: print('학생들의 실력 차이는 크지 않지만 성적이 너무 저조하다. 주의 요망!') elif avrg &gt; total_avrg and std_dev &lt; total_std_dev: print('성적도 평균 이상이고 학생들의 실력 차이도 크지 않다.') main.py123456789101112131415161718from functions import *import argparse parser = argparse.ArgumentParser(prog = '평가프로그램', description = '엑셀에 저장된 학생들의 점수를 가져와 평균과 표준편차를 구하고, 학년 전체 평균과 비교하는 프로그램')parser.add_argument('filepath', type = str, help = '엑셀파일 저장경로')parser.add_argument('total_avrg', type = float, help = '학년평균')parser.add_argument('total_std_dev', type = float, help = '학년표준편차')args = parser.parse_args()def main(): scores = get_data_from_excel(filepath = args.filepath) avrg = get_average(scores = scores) var = get_variance(scores = scores, avrg = avrg) std_dev = get_std_dev(var = var) evaluate_class(avrg, var, std_dev, args.total_avrg, args.total_std_dev)if __name__ == '__main__': main() 메인 함수에는 책과 다른점이 있다. argparse부분이다. argparse 라이브러리를 임포트해서함수에 argument들을 넣었다. argument를 가지고 좀 더 세밀한 부분을 다뤄볼 수 있게 되었다. 이처럼 함수를 이용하면, 코드가 심플해지고, 쉽게 다시 불러와 사용할 수 있다.프로그램이 무슨 일을 하는지 알 수 있고, 한눈에 프로그램의 실행 흐름을 파악할 수 있다.절차 지향의 특징과 장점이라고 할 수 있겠다. 4. 객체 지향 프로그래밍객체 지향은 ‘현실 세계에 존재하는 객체를 어떻게 모델링할 것인가?’에 대한 물음에서 시작한다.데이터 사이언티스트들에게 익숙한 표현이 아닌가 싶다. 4.1 캡슐화현실 세계의 객체를 나타내려면 변수와 함수만 있으면 된다. 객체가 지니는 특성 값에 해당하는 것이 변수이고,행동 혹은 기능은 함수로 표현할 수 있다. 이처럼 현실 세계를 모델링하거나 프로그램을 구현하는 데 변수와 함수를 가진 객체를 이용하는 패러다임을 객체 지향 프로그래밍이라고 하며, 변수와 함수를 하나의 단위로 묶는 것을 캡슐화라고 한다. 4.2 클래스를 사용해 객체 만들기객체와 함수에 대해서 사람들은 어떤 중요한 의미를 부여하게 된다. 하지만 컴퓨터의 입장에서는 어떨까?컴퓨터는 의미가 전달이 되지 않는다. 메모리의 한 단위로만 저장될 뿐이다. 객체라는 메모리 공간을 할당한 다음 객체 안에 묶인 변수를 초기화하고 함수를 호출하는 데 필요한 것이 클래스일 뿐이다. 클래스는 객체를 생성해내는 템플릿이고(그 유명한 붕어빵 틀) 객체는 클래스를 이용해 만들어진 변수와 함수를 가진 메모리 공간이다. 둘은 서로 다른 존재이고 메모리 공간도 다르다. 객체와 매우 유사한 개념으로 인스턴스가 있다. 객체와 인스턴스의 차이점은 객체는 객체 자체에 초점을 맞춘 용어이고(붕어빵) 인스턴스는 이객체가 어떤 클래스에서 만들어졌는지에 초점을 맞춘 용어이다.(어떤 붕어빵 틀에서 나왔니) 사람이라는 클래스를 만들어보면서 이해해보면 쉬울 것이다.구현 코드는 아래와 같다.1234567891011121314class Person: def __init__(self, name, money): self.name = name self.money = money def give_money(self, other, money): other.get_money(money) self.money -= money def get_money(self, money): self.money += money def __str__(self): return 'name : {}, money : {}'.format(self.name, self.money) 12greg = Person('greg', 5000)john = Person('john', 2000) 12345print(greg, john)name : greg, money : 5000 name : john, money : 2000greg.give_money(john, 2000)print(greg, john)name : greg, money : 3000 name : john, money : 4000 4.3 파이썬의 클래스4.2에서 구현한 클래스를 가져와서 살펴보자12345678type(Person.__init__)= &lt;class 'function'&gt;type(Person.give_momey)= &lt;class 'function'&gt;type(Person.get_money)= &lt;class 'function'&gt;type(Person.show)= &lt;class 'function'&gt; 모두 함수라는 충격적인 결과가 나온다. 이번에는 객체가 가진 메서드를 살펴보자123456type(g.give_money)= &lt;class 'method'&gt;type(g.get_meney)= &lt;class 'method'&gt;type(g.show)= &lt;class 'method'&gt; 객체 g의 메서드는 메서드인 것을 알 수 있다. 비슷한 것 같은데 둘의 차이는 무엇일까? 1234567dir(g.give_money)g.give_money.__func__g.give_money.__self__g.give_money.__self__ is g 위의 코드를 실행 시켜보면 차이를 확인해 볼 수 있다.g가 가진 메서드의 속성을 dir을 통해 확인해보면, __func__, __self__가 등장하는 것을 볼 수 있다. __self__를 확인해 보면 Person객체라고 나온다. __func__는 또한 Person클래스의 give_money()함수라는 것을 확인할 수 있고, __self__가 이 메소드를 가진 객체 자신을 참조하고 있다는 것도 알 수 있다. 객체에서 메서드를 호출할 때 self를 전달하지 않아도 되는 이유를 여기서 알 수 있게 된다. 메서드 내부에 함수와 객체의 참조를 가지고 있으므로, 함수에 직접 객체의 참조를 전달할 수 있기 때문이다. [혼자서하는 괴발개발 블로그]https://aisolab.github.io/computer%20science/2018/08/09/CS_Object-oriented-programming/classmethod와 staticmethod를 한눈에 정리가능한 코드가 있어서가져와봤다. 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Person: # 여기에 class variable (또는 class member) # instance 모두가 공유하는 동일한 값 # instance를 생성하지않고도, class만 선언한 상태에서 호출이 가능하다. # oop에서 global variable을 대체하기위하여 사용 __whole_population = 0 # name mangling technique 사용, 외부에서 ## Person.__whole_population으로 접근 불가 ## Person._Person__whole_population으로 접근 가능 # class method # oop에서 global에 선언된 function을 대체하기위해 사용 # 대체 생성자를 만들 때, 더 많이씀 (여긴 대체생성자 구현하지 않음) @classmethod def __birth(cls): cls.__whole_population += 1 @staticmethod def check_population(): return Person.__whole_population # instance method def __init__(self, name, money): # 생성자(constructor) Person.__birth() # instance variable (또는 instance member) # instance마다 값이 다른 변수, instance가 가지는 고유한 값 # 여기에서는 self.name, self.age self.name = name self.money = money def get_money(self, money): self.money += money def give_money(self, other, money): # message passing # 다른 인스턴스(객체)랑 상호작용을 할 때, 상대 인스턴스(객체)의 인스턴스 변수를 바꿔야한다면 other.get_money(money) # 이렇게하세요 # other.money += money 이렇게하지마세요 self.money -= money def __str__(self): return '{} : {}'.format(self.name, self.money) 주석처리도 너무 잘되어 있기 때문에 쭉 보고 따라 쳐보면서 이해하면 아주 좋을 것 같다. 클래스 메서드의 특징 중 하나는 인스턴스를 만들지 않고도 불러낼 수 있다는 것이다.12# 클래스 메소드는 인스턴스를 생성하지않고도 호출할 수 있다.print(Person.check_population()) 10 만들어놓은 클래스를 사용해보자.1234567891011121314151617# 클래스 변수는 인스턴스간에 모두 공유한다.# 인스턴스를 통해서도 클래스 변수나 클래스 메소드를 호출할 수 있다.mark = Person('mark', 5000)greg = Person('greg', 3000)steve = Person('steve', 2000)print(Person.check_population())print(Person._Person__whole_population)print(mark._Person__whole_population)print(greg._Person__whole_population)print(steve._Person__whole_population)steve._Person__birth()print(mark._Person__whole_population)print(greg._Person__whole_population)print(steve._Person__whole_population) 1234567833333444 마크와 그렉 스티브가 인스턴스로 만들어졌다. 만들어지자마자 클래스메서드의 __birth가 실행되어서인구가 총 3명이 된다.스티브 인스턴스를 통해 클래스 메서드로의 접근이 가능해서인구가 4가 되었고인스턴스로 접근해 전역변수 __whole_population을 요청하면 4가 나오게 된다. 4.4 객체 지향으로 은행 입출금 프로그램 만들기123456789101112131415161718192021222324252627282930313233343536class Account: __num_acnt = 0 @staticmethod def get_num_acnt(): return Account.__num_acnt def __init__(self, name, money): self._user = name self._balance = money Account.__num_acnt += 1 def deposit(self, money): assert money &gt; 0, '금액이 음수입니다.' self._balance += money def withdraw(self, money): assert money &gt; 0, '금액이 음수입니다.' if self._balance &gt;= money: self._balance -= money else: pass def transfer(self, other, money): assert money &gt; 0, '금액이 음수입니다.' self.withdraw(money) if self._balance &gt;= 0: other.deposit(money) return True else: return False def __str__(self): return 'user : {}, balance :{}'.format(self._user, self._balance) 4.5 정보 은닉결론부터 말하자면, 파이썬은 정보 은닉을 지원하지 않는다. 정보은닉은 캡슐화할때 사용된다. 캡슐화하는 과정에서 어떤 멤버와 메서드는 공개해서 유저 프로그래머가 사용할 수 있게 해야하고, 어떤 멤버와 메서드는 숨겨서, 접근하지 못하도록 해야한다. 캡슐화는 그래서 정보 은닉까지 포함하는 개념이다. 파이썬이 그나마 제공하는 방법은 두 가지이다. 숨기려는 멤버 앞에 언더바 두개 붙이기(name mangling) 프로퍼티 기법 첫번째 방법을 사용해보자123456789101112class Account: def __init__(self, name, money): self.__name = name self.__balance = money def get_balance(self): return self.__balance def set_balance(self, new_bal): if new_bal &lt; 0: return self.__balance = new_bal 12my_acnt = Account(name = 'hyubyy', money = 5000)print(my_acnt.__dict__) 1{'_Account__name': 'hyubyy', '_Account__balance': 5000} 내 계좌에 5000을 넣어놨다.12my_acnt.__balance = -5000print(my_acnt.get_balance()) 내 계좌에 직접 접근해서 -5000을 하는 코드이다. 그런데print를 하게되면 결과는 5000이 나오게된다.어? 정보 은닉이 된게 아닐까?1print(my_acnt.__dict__) 1{'_Account__name': 'hyubyy', '_Account__balance': 5000, '__balance': -5000} -5000은 __balance라는 형태로 저장되어 있다. 숨겨진 형태로 저장될 때_Account__balance로 원래의 5000이 따로 저장된다. 클래스 안에서 멤버 앞에 언더바를 두 개 붙이면 이 멤버는 객체가 만들어질 때 이름이 변한다. 하지만 __dict__로 확인이 가능해서, 언제든지 접근해서 변경할 수 있다.1my_acnt._Account__balance = 8888 1print(my_acnt.__dict__) 1{'_Account__name': 'hyubyy', '_Account__balance': 8888, '__balance': -5000} 다음은 프로퍼티 기법이다.1234567891011121314151617181920class Account: def __init__(self, name, money): self.__name = name self.balance = money @property def balance(self): # getter function return self.balance @balance.setter def balance(self, money): # setter function if money &lt; 0: return self._balance = money if __name__ == '__main__': my_acnt = Account('greg', 5000) my_acnt.balance = -3000 print(my_acnt.balance) 실행 결과는 5000이다. 놀랍게도 balance가 2000으로 나오지 않았다. 위의 코드에서 특이한 점이 있는데 @property와 @balance.setter라는 부분이다.@property를 붙여주면 이 함수는 getter 함수가 되며, @balance.setter는 setter함수로 사용된다.따라서, my_acnt 객체에는 balance라는 멤버가 없다. balance라는 이름의 getter와 setter밖에 존재 하지 않는다. my_acnt.balance = -3000은 값을 변경하는 것처럼 보이지만, 실제로는 setter가 실행되고 그 결과로 _balance값은 변경되지 않는다. 하지만 프로퍼티 기법 역시 유저가 접근하는 것을 막을 수는 없다.마찬가지로1my_acnt._balance = -3000 으로 바꿔버리면 그만이기 때문이다.이처럼 파이썬은 완벽한 정보 은닉을 제공하지 않는다. 5. 객체지향으로 다시 만드는 학급 성적 평가 프로그램이제 사용자 프로그램을 더 심플하게 작성할 수 있게 되었다.statistics.py1234567891011121314151617181920212223from functools import reduceimport mathclass Stat: def get_average(self, scores): avrg = reduce(lambda score1, score2 : score1 + score2, scores) / len(scores) return avrg def get_variance(self, scores, avrg): tmp = 0 for score in scores: tmp += (score - avrg)**2 else: var = tmp / len(scores) return var def get_std_dev(self, var): std_dev = round(math.sqrt(var),1) return std_dev datahandler.py12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758from openpyxl import load_workbookfrom statistics import Statclass DataHandler: evaluator = Stat() @classmethod def get_data_from_excel(cls, filepath): wb = load_workbook(filename = filepath) ws = wb.active rows = ws.rows raw_data = {name_cell.value : score_cell.value for name_cell, score_cell in rows} scores = raw_data.values() return scores def __init__(self, filepath): self.scores = DataHandler.get_data_from_excel(filepath = filepath) self.cache = {'scores' : self.scores} def get_average(self): if 'average' not in self.cache.keys(): self.cache.update({'average' : DataHandler.evaluator.get_average(self.cache.get('scores'))}) return self.cache.get('average') else: return self.cache.get('average') def get_variance(self): if 'variance' not in self.cache.keys(): self.cache.update({'variance' : DataHandler.evaluator.get_variance(self.cache.get('scores'), self.get_average())}) return self.cache.get('variance') else: return self.cache.get('variance') def get_std_dev(self): if 'std_dev' not in self.cache.keys(): self.cache.update({'std_dev' : DataHandler.evaluator.get_std_dev(self.get_variance())}) return self.cache.get('std_dev') else: return self.cache.get('std_dev') def evaluate_class(self, total_avrg, total_std_dev): avrg = self.get_average() var = self.get_variance() std_dev = self.get_std_dev() print(\"평균:{}, 분산:{}, 표준편차:{}\".format(avrg, var, std_dev)) if avrg &lt; total_avrg and std_dev &gt; total_std_dev: print('성적이 너무 저조하고 학생들의 실력 차이가 너무 크다.') elif avrg &gt; total_avrg and std_dev &gt; total_std_dev: print('성적은 평균 이상이지만 학생들의 실력 차이가 크다. 주의 요망!') elif avrg &lt; total_avrg and std_dev &lt; total_std_dev: print('학생들의 실력 차이는 크지 않지만 성적이 너무 저조하다. 주의 요망!') elif avrg &gt; total_avrg and std_dev &lt; total_std_dev: print('성적도 평균 이상이고 학생들의 실력 차이도 크지 않다.') main.py 123456789101112131415from datahandler import DataHandlerimport argparse parser = argparse.ArgumentParser(prog = '평가프로그램', description = '엑셀에 저장된 학생들의 점수를 가져와 평균과 표준편차를 구하고, 학년 전체 평균과 비교하는 프로그램')parser.add_argument('filepath', type = str, help = '엑셀파일 저장경로')parser.add_argument('total_avrg', type = float, help = '학년평균')parser.add_argument('total_std_dev', type = float, help = '학년표준편차')args = parser.parse_args()def main(): datahandler = DataHandler(filepath = args.filepath) datahandler.evaluate_class(total_avrg = args.total_avrg, total_std_dev = args.total_std_dev)if __name__ == '__main__': main()` 유저 프로그램인 main.py script를 실행시키면 아래와 같다.123456789101112$ python main.py --helpusage: 평가프로그램 [-h] filepath total_avrg total_std_dev엑셀에 저장된 학생들의 점수를 가져와 평균과 표준편차를 구하고, 학년 전체 평균과 비교하는 프로그램positional arguments: filepath 엑셀파일 저장경로 total_avrg 학년평균 total_std_dev 학년표준편차optional arguments: -h, --help show this help message and exit 1$ python main.py ./class_1.xlsx 50 25 12평균:51.5, 분산:1240.25, 표준편차:35.2성적은 평균 이상이지만 학생들의 실력 차이가 크다. 주의 요망!","link":"/2019/01/28/oop/"}],"tags":[{"name":"blog","slug":"blog","link":"/tags/blog/"},{"name":"Boosting","slug":"Boosting","link":"/tags/Boosting/"},{"name":"Gradient Boosting","slug":"Gradient-Boosting","link":"/tags/Gradient-Boosting/"},{"name":"Ada Boosting","slug":"Ada-Boosting","link":"/tags/Ada-Boosting/"},{"name":"elice","slug":"elice","link":"/tags/elice/"},{"name":"Information","slug":"Information","link":"/tags/Information/"},{"name":"Entropy","slug":"Entropy","link":"/tags/Entropy/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"code","slug":"code","link":"/tags/code/"},{"name":"programmers","slug":"programmers","link":"/tags/programmers/"},{"name":"Timeseries","slug":"Timeseries","link":"/tags/Timeseries/"},{"name":"Information Value","slug":"Information-Value","link":"/tags/Information-Value/"},{"name":"feature selection","slug":"feature-selection","link":"/tags/feature-selection/"},{"name":"debug","slug":"debug","link":"/tags/debug/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"sql","slug":"sql","link":"/tags/sql/"},{"name":"글또","slug":"글또","link":"/tags/글또/"},{"name":"float","slug":"float","link":"/tags/float/"},{"name":"Cross Entropy","slug":"Cross-Entropy","link":"/tags/Cross-Entropy/"},{"name":"KL Divergence","slug":"KL-Divergence","link":"/tags/KL-Divergence/"},{"name":"Ensemble","slug":"Ensemble","link":"/tags/Ensemble/"},{"name":"RandomForest","slug":"RandomForest","link":"/tags/RandomForest/"},{"name":"Metrics","slug":"Metrics","link":"/tags/Metrics/"},{"name":"Accuracy","slug":"Accuracy","link":"/tags/Accuracy/"},{"name":"PCA","slug":"PCA","link":"/tags/PCA/"},{"name":"Dimensional Reduction","slug":"Dimensional-Reduction","link":"/tags/Dimensional-Reduction/"},{"name":"A/B test","slug":"A-B-test","link":"/tags/A-B-test/"},{"name":"MAB","slug":"MAB","link":"/tags/MAB/"},{"name":"class","slug":"class","link":"/tags/class/"},{"name":"Supervised Learning","slug":"Supervised-Learning","link":"/tags/Supervised-Learning/"},{"name":"Linear Regression","slug":"Linear-Regression","link":"/tags/Linear-Regression/"},{"name":"Naive Bayes","slug":"Naive-Bayes","link":"/tags/Naive-Bayes/"},{"name":"oop","slug":"oop","link":"/tags/oop/"}],"categories":[{"name":"blog","slug":"blog","link":"/categories/blog/"},{"name":"ML","slug":"ML","link":"/categories/ML/"},{"name":"coding test","slug":"coding-test","link":"/categories/coding-test/"},{"name":"python","slug":"python","link":"/categories/python/"},{"name":"Statistics","slug":"ML/Statistics","link":"/categories/ML/Statistics/"},{"name":"Statistics","slug":"Statistics","link":"/categories/Statistics/"},{"name":"Algorithm","slug":"coding-test/Algorithm","link":"/categories/coding-test/Algorithm/"},{"name":"sql","slug":"sql","link":"/categories/sql/"},{"name":"Information Theory","slug":"ML/Information-Theory","link":"/categories/ML/Information-Theory/"},{"name":"cs","slug":"cs","link":"/categories/cs/"},{"name":"coding test","slug":"python/coding-test","link":"/categories/python/coding-test/"},{"name":"blog","slug":"coding-test/Algorithm/blog","link":"/categories/coding-test/Algorithm/blog/"},{"name":"debug","slug":"sql/debug","link":"/categories/sql/debug/"},{"name":"code","slug":"sql/code","link":"/categories/sql/code/"},{"name":"python","slug":"cs/python","link":"/categories/cs/python/"},{"name":"Algorithm","slug":"python/coding-test/Algorithm","link":"/categories/python/coding-test/Algorithm/"},{"name":"Statistics","slug":"ML/Information-Theory/Statistics","link":"/categories/ML/Information-Theory/Statistics/"},{"name":"삽질","slug":"sql/debug/삽질","link":"/categories/sql/debug/삽질/"},{"name":"Algorithm","slug":"Algorithm","link":"/categories/Algorithm/"},{"name":"book","slug":"book","link":"/categories/book/"},{"name":"Automation","slug":"Algorithm/Automation","link":"/categories/Algorithm/Automation/"},{"name":"ML","slug":"book/ML","link":"/categories/book/ML/"},{"name":"cs","slug":"python/cs","link":"/categories/python/cs/"}]}