<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>Zeppelin으로 Spark를 다뤄보자 01 - Unreasonable Effectiveness</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Unreasonable Effectiveness"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Unreasonable Effectiveness"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="pyspark로 데이터를 읽으려면 어떻게 해야할까?"><meta property="og:type" content="article"><meta property="og:title" content="Zeppelin으로 Spark를 다뤄보자 01"><meta property="og:url" content="http://tkdguq05.github.io/2020/01/06/spark-zeppelin/"><meta property="og:site_name" content="Unreasonable Effectiveness"><meta property="og:description" content="pyspark로 데이터를 읽으려면 어떻게 해야할까?"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://tkdguq05.github.io/images/spark-logo-trademark.png"><meta property="article:published_time" content="2020-01-06T12:44:53.000Z"><meta property="article:modified_time" content="2020-02-24T10:25:58.000Z"><meta property="article:author" content="SangHyub Lee, Jose"><meta property="article:tag" content="spark"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://tkdguq05.github.io/images/spark-logo-trademark.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://tkdguq05.github.io/2020/01/06/spark-zeppelin/"},"headline":"Zeppelin으로 Spark를 다뤄보자 01","image":["http://tkdguq05.github.io/images/spark-logo-trademark.png"],"datePublished":"2020-01-06T12:44:53.000Z","dateModified":"2020-02-24T10:25:58.000Z","author":{"@type":"Person","name":"SangHyub Lee, Jose"},"publisher":{"@type":"Organization","name":"Unreasonable Effectiveness","logo":{"@type":"ImageObject"}},"description":"pyspark로 데이터를 읽으려면 어떻게 해야할까?"}</script><link rel="canonical" href="http://tkdguq05.github.io/2020/01/06/spark-zeppelin/"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-1-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Unreasonable Effectiveness</a></div><div class="navbar-menu"><div class="navbar-end"></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-01-06T12:44:53.000Z" title="2020. 1. 6. 오후 9:44:53">2020-01-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-02-24T10:25:58.000Z" title="2020. 2. 24. 오후 7:25:58">2020-02-24</time></span><span class="level-item"><a class="link-muted" href="/categories/spark/">spark</a><span> / </span><a class="link-muted" href="/categories/spark/engineering/">engineering</a></span></div></div><h1 class="title is-3 is-size-4-mobile">Zeppelin으로 Spark를 다뤄보자 01</h1><div class="content"><p>pyspark로 데이터를 읽으려면 어떻게 해야할까?</p>
<span id="more"></span>
<h1 id="Zeppelin-이용해서-pyspark로-데이터-읽기-01"><a href="#Zeppelin-이용해서-pyspark로-데이터-읽기-01" class="headerlink" title="Zeppelin 이용해서 pyspark로 데이터 읽기 01"></a>Zeppelin 이용해서 pyspark로 데이터 읽기 01</h1><p>Spark는 고속 범용 분산 컴퓨팅 플랫폼으로 정의되곤 합니다. 대용량 데이터를 가져와 빠르게 분석해 낼 수 있다는 점에서 많은 기업들에서 도입을 검토하고 있고 실제로도 많이 사용되고 있습니다. 오늘은 이 유명한 Spark를 다운받고 Zeppelin으로 띄워서 pyspark를 이용해 데이터를 읽어보는 작업까지 해 보겠습니다.</p>
<p>먼저 Spark를 다운받아 줍니다. <a target="_blank" rel="noopener" href="https://spark.apache.org/downloads.html">Spark 설치</a></p>
<p><img src="/images/spark_down.png" alt="스파크 다운로드"><br>링크로 들어가면 다음과 같이 나오는데 다운받는 버전은 아무거나 받아도 상관 없지만 저는 AWS EMR로 Spark를 도입하기 전에 연습하는 용으로 사용하는 것이기 때문에 AWS EMR 버전과 같은 2.4.4버전을 다운받았습니다.</p>
<p>하둡 버전은 사진 그대로 2.7버전으로 진행 했습니다. </p>
<p>다운이 완료되면 폴더를 만들어서 그곳에 저장해주고 압축을 풀어줍니다.</p>
<p>tgz로 되어있는 파일은</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -xvf [filename]</span><br></pre></td></tr></table></figure>
<p>이렇게 풀어줍니다.</p>
<p>다음은 Zeppelin입니다. <a target="_blank" rel="noopener" href="https://zeppelin.apache.org/download.html">Zeppelin 설치</a></p>
<p><img src="/images/zeppelin_down.png" alt="제플린 다운로드"><br>제플린도 역시 두 가지 버전이 등장하는데, 저는 용량이 작은 버전으로 받았습니다. 큰 용량의 버전은 카산드라 등이 다 포함된 버전이기 때문에 굳이 받지 않았습니다.</p>
<p>제플린도 특정 폴더에 저장해주고 압축을 풀어줍니다.</p>
<h3 id="Spark-경로-지정"><a href="#Spark-경로-지정" class="headerlink" title="Spark 경로 지정"></a>Spark 경로 지정</h3><p>Spark의 경로를 잘 지정해줘야 Zeppelin이 실행되고 코드를 돌렸을 때 오류가 나지 않습니다.<br>먼저 쉘의 프로파일을 열어줍니다. 저는 zsh을 사용하기 때문에 zshrc를 열겠습니다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.zshrc</span><br></pre></td></tr></table></figure>

<p>그 다음 설정해야 할 것은 java home 경로입니다. jdk가 없다면 jdk 1.8이상 버전을 다운받아 설치합니다.<br>java home 경로는 </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="variable">$JAVA_HOME</span></span><br></pre></td></tr></table></figure>
<p>이 명령어로 알아낼 수 있습니다. java home의 경로를 알아냈다면 zshrc에 이 위치를 알려줘야합니다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=<span class="string">&quot;/Library/Java/JavaVirtualMachines/jdk1.8.0_181.jdk/Contents/Home&quot;</span></span><br></pre></td></tr></table></figure>
<p>저의 경우는 위치가 다음과 같아서 zsh의 아래쪽에 작성해 주었습니다.</p>
<p>그리고 설치된 Spark의 위치도 알려줘야 합니다. 아까 저장했던 폴더의 주소를 입력해 줍니다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> SPARK_HOME=/Users/sanghyub/spark-2.4.4-bin-hadoop2.7</span><br></pre></td></tr></table></figure>
<p>저의 경우는 이렇게 되어있습니다. 절대경로로 작성해 주시면 됩니다.</p>
<p>Spark 세팅은 일단 여기까지 하고 Zeppelin으로 넘어가겠습니다.</p>
<h3 id="Zeppelin-환경-설정"><a href="#Zeppelin-환경-설정" class="headerlink" title="Zeppelin 환경 설정"></a>Zeppelin 환경 설정</h3><p>Zeppelin이 저장된 폴더로 들어가서 conf로 들어가줍니다. conf에는 <code>ls</code>를 입력해보면 여러 파일들이 있는 것을 볼 수 있습니다. </p>
<p><img src="/images/zeppelin_conf.png" alt="Zeppelin conf files"><br>이 파일들 중에서 zeppelin-env.sh와 zeppelin-site.xml을 사용해야 하는데, .template으로 된 파일들이 보일 것 입니다. template를 <code>cp</code>를 이용해서 바꿔줍니다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> zeppelin-env.sh.template zeppelin-env.sh</span><br></pre></td></tr></table></figure>
<p><code>cp</code>는 복사하는 것도 있지만, 이렇게 이름을 바꿔주는데에도 사용됩니다.<br>zeppelin-env.sh와 zeppelin-site.xml을 얻었다면 vi를 이용해서 zeppelin-env.sh로 들어갑니다.<br>아까 작성한 자바 경로와 스파크 홈 경로를 그대로 갖고와서 작성해줍니다. zeppelin이 이 위치를 보고 Spark와 jdk를 이용할 수 있도록 적어두는 것 입니다.</p>
<p><img src="/images/zeppelin_sh.png" alt="zeppelin-env.sh 수정, 이렇게 적어주자"></p>
<p>zeppelin의 포트도 수정해 줍니다. 기본 포트는 8080포트인데 혹시 충돌될 수 있으니, 저는 안정적으로 9999포트로 변경하겠습니다.</p>
<p><img src="/images/zeppelin_xml.png" alt="zeppelin-site.xml 이렇게 작성!"></p>
<p>이제 기본적인 세팅은 끝났고 zeppelin을 실행시켜 봅니다.</p>
<h3 id="Zeppelin-실행"><a href="#Zeppelin-실행" class="headerlink" title="Zeppelin 실행"></a>Zeppelin 실행</h3><p>Zeppelin 실행은 jupyter notebook여는 것과는 조금 다릅니다. zeppelin을 입력해도 아무일도 일어나지 않습니다. Zeppelin을 열기 위해서는 zeppelin daemon을 실행시켜줘야 합니다.</p>
<p>zeppeliln daemon은 bin폴더에 있습니다. conf에서 빠져나와서 bin으로 들어가줍니다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ../bin</span><br></pre></td></tr></table></figure>

<p><code>ls</code>를 입력하면 찾았던 daemon이 보일 것 입니다. 너무 반갑지만 쉘이 익숙하지 않다면 실행하는 방법을 모를 것입니다. 저도 그랬고 같이 공부했던 사람들도 눈치만 봤었습니다. 백날 눈치를 보고 째려봐도 실행은 되지 않습니다. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./zeppelin-daemon.sh start</span><br></pre></td></tr></table></figure>
<p>이렇게 데몬을 실행시켜줍니다. 확인은 (<a href="https://localhost:9999)로">https://localhost:9999)로</a> 들어가서 해 보면 됩니다.</p>
<p><img src="/images/hello_zeppelin.png" alt="Hello Zeppelin"><br>짠! 제플린의 날개가 등장했습니다. 이제 노트를 만들고 데이터를 로드해보는 작업을 하겠습니다.</p>
</div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/spark/">spark</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/01/16/spark-in-action/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Spark에서 데이터 분석 시, RDD로 연산하면 안되는 이유</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/01/01/keras-trouble-shooting/"><span class="level-item">Failed to get convolution algorithm. This is probably because cuDNN failed to initialize 해결하기, feat. 케라스 창시자에게 배우는 딥러닝</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><!--!--><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Unreasonable Effectiveness</a><p class="is-size-7"><span>&copy; 2023 SangHyub Lee, Jose</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><!--!--><script src="/js/main.js" defer></script><!--!--></body></html>