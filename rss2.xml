<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Unreasonable Effectiveness</title>
    <link>http://tkdguq05.github.io/</link>
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description></description>
    <pubDate>Mon, 20 Jan 2020 05:46:09 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>Spark에서 데이터 분석 시, RDD로 연산하면 안되는 이유</title>
      <link>http://tkdguq05.github.io/2020/01/16/spark-in-action/</link>
      <guid>http://tkdguq05.github.io/2020/01/16/spark-in-action/</guid>
      <pubDate>Thu, 16 Jan 2020 08:49:47 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;데이터-분석하기-전-데이터부터-읽자&quot;&gt;&lt;a href=&quot;#데이터-분석하기-전-데이터부터-읽자&quot; class=&quot;headerlink&quot; title=&quot;데이터 분석하기 전, 데이터부터 읽자&quot;&gt;&lt;/a&gt;데이터 분석하기 전, 데이터부터 읽자&lt;/h1&gt;&lt;h3
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="데이터-분석하기-전-데이터부터-읽자"><a href="#데이터-분석하기-전-데이터부터-읽자" class="headerlink" title="데이터 분석하기 전, 데이터부터 읽자"></a>데이터 분석하기 전, 데이터부터 읽자</h1><h3 id="Spark-Session-conf-설정"><a href="#Spark-Session-conf-설정" class="headerlink" title="Spark Session, conf 설정"></a>Spark Session, conf 설정</h3><p>기존 python의 pandas를 이용해서 데이터를 읽으려면 pd.DataFrame(‘…….’)를 통해 파일을 읽으면 간단히 해결 되었다. 하지만 spark에서 데이터를 읽기 위해서는 조금 더 손을 거쳐야 한다. 물론 Zeppelin을 이용한다면 바로 파일을 읽어들일 수 있겠지만, pycharm을 이용해서 pyspark application을 만드는 작업을 할 것이기 때문에 직접 spark세팅을 해주어야 한다. </p><p>pycharm에서는 Spark Session을 설정해줘야 spark를 사용할 수 있다. 이 Spark Session에 대한 설정값으로 Spark Conf를 설정해주어야 한다.<br>먼저 필요한 라이브러리를 불러들이고 Spark conf와 session을 설정한다.<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> pyspark.conf <span class="hljs-keyword">import</span> SparkConf</span><br><span class="line"><span class="hljs-keyword">from</span> pyspark.sql <span class="hljs-keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">conf = SparkConf()</span><br><span class="line">conf.set(<span class="hljs-string">'spark.jars.packages'</span>, <span class="hljs-string">'org.mongodb.spark:mongo-spark-connector_2.11:2.3.1'</span>)</span><br><span class="line">spark = SparkSession.builder.appName(<span class="hljs-string">"spark test"</span>).config(conf=conf).getOrCreate()</span><br></pre></td></tr></table></figure></p><p>conf.set에는 mongoDB와의 연결을 위한 spark connector를 넣어줬다. 이렇게 하면 mongoDB에 있는 데이터를 바로 읽을 수 있을까? 아직 할 작업이 조금 남았다. data를 불러오기 전에 스키마 지정을 해줘야 하기 때문이다.</p><h3 id="스키마-지정"><a href="#스키마-지정" class="headerlink" title="스키마 지정"></a>스키마 지정</h3><p>스키마란 간단하게 말해서 데이터 구조와 제약 조건에 대한 명세(Specification) 기술한 것을 의미한다.<br>여기서 설정할 스키마는 이 데이터의 칼럼이 어떤타입으로 들어갈 것인지(string, integer, double …)를 주로 뜻하게 될 것이다.<br>mongoDB에서 사용자들이 거래한 내용 중 카트에 어떤 상품을 담았는지 알기 위해서 다음과 같이 코드를 작성했다.</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">cartSchema =  StructType([</span><br><span class="line">    StructField(<span class="hljs-string">"cartGoodsName"</span>, StringType(),<span class="hljs-keyword">True</span>),</span><br><span class="line">    StructField(<span class="hljs-string">"cartGoodsCode"</span>, StringType(),<span class="hljs-keyword">True</span>),</span><br><span class="line">    StructField(<span class="hljs-string">"cartGoodsAmount"</span>, IntegerType(),<span class="hljs-keyword">True</span>),</span><br><span class="line">    StructField(<span class="hljs-string">"cartGoodsCount"</span>, IntegerType(),<span class="hljs-keyword">True</span>),</span><br><span class="line">  ])</span><br><span class="line"></span><br><span class="line">userSchema = StructType([</span><br><span class="line">    StructField(<span class="hljs-string">"cookieId"</span>, StringType(),<span class="hljs-keyword">True</span>),</span><br><span class="line">    StructField(<span class="hljs-string">"currentTime"</span>, StringType(),<span class="hljs-keyword">True</span>),</span><br><span class="line">    StructField(<span class="hljs-string">"sessionSeq"</span>, StringType(),<span class="hljs-keyword">True</span>),</span><br><span class="line">    StructField(<span class="hljs-string">"userSeq"</span>, StringType(),<span class="hljs-keyword">True</span>),</span><br><span class="line">    StructField(<span class="hljs-string">"cart"</span>, ArrayType(cartSchema),<span class="hljs-keyword">True</span>)</span><br><span class="line">  ])</span><br></pre></td></tr></table></figure><p>이렇게 카트 데이터에 대한 스키마를 작성해서 유저스키마의 cart 부분에 넣어준 뒤 합쳐진 userSchema를 이용해 데이터를 읽었다.</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df = spark.read.schema(userSchema).format(<span class="hljs-string">"com.mongodb.spark.sql.DefaultSource"</span>) \</span><br><span class="line">    .option(<span class="hljs-string">"spark.mongodb.input.uri"</span>,</span><br><span class="line">            <span class="hljs-string">"mongodb://******/*****.userDataInfo.******"</span>) \</span><br><span class="line">    .option(<span class="hljs-string">"spark.mongodb.output.uri"</span>,</span><br><span class="line">            <span class="hljs-string">"mongodb://******/*****.userDataInfo.******"</span>) \</span><br><span class="line">    .load()</span><br></pre></td></tr></table></figure><p>읽은 결과는 따로 dataframe을 지정할 필요없이 바로 dataframe으로 떨어진다. 이제 바로 데이터에 대해서 작업을 수행할 수 있게 되었다.<br>카트에 담은 상품이 무엇인지 알고 싶어서 actionType이 viewCart인 부분을 가져왔다.</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">view_cart_df = df.filter(df.actionType ==<span class="hljs-string">'viewCart'</span>)</span><br></pre></td></tr></table></figure><p>가져오고 나서 전처리 작업을 하려고 했는데, 데이터프레임에 대한 이해가 적었었던 때라 어떻게 작업해야 할지 몰랐다. 그래서 먼저 RDD로 작업을 했고 뼈저리게 후회했다. 절대 발생하면 안되는 일이 일어났기 때문이다.</p><h1 id="RDD를-사용한-결과"><a href="#RDD를-사용한-결과" class="headerlink" title="RDD를 사용한 결과"></a>RDD를 사용한 결과</h1><p>RDD를 사용해서 전처리를 해보고 Cart에 담긴 Top N개의 상품을 가져와보기로 했다.<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_info</span><span class="hljs-params">(x)</span>:</span></span><br><span class="line">    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x:</span><br><span class="line">        <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> i:</span><br><span class="line">            test = Row(code=k[<span class="hljs-number">1</span>],cart_count=k[<span class="hljs-number">3</span>])</span><br><span class="line">    <span class="hljs-keyword">return</span> test</span><br></pre></td></tr></table></figure></p><p>RDD를 이용해 전처리를 할 때 쓸 함수를 지정해 놓고 작업을 하기로 했다. 함수는 다음과 같이 작성했고 상품의 코드와 그 상품이 얼마나 담겼는지를 Row로 생성했다.</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df = df.filter(df.cart.isNotNull()).withColumn(<span class="hljs-string">"currentTime"</span>, to_timestamp(<span class="hljs-string">"currentTime"</span>, <span class="hljs-string">"yyyy-MM-dd HH:mm:ss"</span>))</span><br><span class="line">view_cart_count = df.select(<span class="hljs-string">'cart'</span>).rdd.map(get_info).toDF()</span><br><span class="line"></span><br><span class="line">view_cart_count.groupBy(<span class="hljs-string">'code'</span>).count().show()</span><br></pre></td></tr></table></figure><p>이렇게 만든 함수를 df의 cart에서 rdd의 map을 이용해서 결과를 가져왔다. 그리고 상품코드 별로 그룹화 하고 sum을 해서 결과를 출력했다.</p><p><img src="/images/rdd_res.png" alt="RDD에 map한 결과"><br>그런데 뭔가 이상했다. sum을 했으면 결과값이 적어도 100은 넘어야 했는데, 100넘는 값이 너무 적었다. 그래서 특정 상품코드에 대해서 python으로 데이터 분석을 실시해서 결과를 매칭시켜 비교해보기로 했다.</p><p><img src="/images/python_res.png" alt="python을 통한 결과"><br>결과가 너무 차이가 났다. 이렇게 나온 결과로 아이템을 추천하게 되면 제대로 된 상품이 추천되지 않을  것이다. RDD에 함수를 map하는 것에 뭔가 문제가 있는 것이 분명했다. 방법을 찾다가 Dataframe으로 작업을 해보기로 했다.</p><h1 id="Dataframe을-사용한-결과"><a href="#Dataframe을-사용한-결과" class="headerlink" title="Dataframe을 사용한 결과"></a>Dataframe을 사용한 결과</h1><p>데이터 프레임으로 작업해야 결과값이 바뀌지 않는 다는 정보를 알게 되어 기존에 있던 df에 filter를 걸어 새 DF를 만들고 이걸 가지고 전처리 해보기로 했다.<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cartDF = df.filter(df.cart.isNotNull()).withColumn(<span class="hljs-string">"currentTime"</span>,</span><br><span class="line">                  to_timestamp(<span class="hljs-string">"currentTime"</span>, <span class="hljs-string">"yyyy-MM-dd HH:mm:ss"</span>)).select(<span class="hljs-string">"cart"</span>) \</span><br><span class="line">    .withColumn(<span class="hljs-string">"cart"</span>, explode(<span class="hljs-string">"cart"</span>))</span><br><span class="line"></span><br><span class="line">cart_all = cartDF.withColumn(<span class="hljs-string">"goodsCode"</span>, cartDF[<span class="hljs-string">"cart"</span>].getItem(<span class="hljs-string">"cartGoodsCode"</span>))\</span><br><span class="line">    .withColumn(<span class="hljs-string">"goodsCount"</span>, cartDF[<span class="hljs-string">"cart"</span>].getItem(<span class="hljs-string">"cartGoodsCount"</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">results_df = cart_all.groupby(<span class="hljs-string">'goodsCode'</span>).sum().orderBy(<span class="hljs-string">'sum(goodsCount)'</span>, ascending=<span class="hljs-keyword">False</span>)</span><br></pre></td></tr></table></figure></p><p>작업은 다음과 같이 실시했고 상품 갯수를 정렬하기 위해서 orderBy를 사용했다.<br>결과는 어떻게 나왔을까?</p><p><img src="/images/df_res.png" alt="Dataframe을 사용한 결과"></p><p>python을 사용한 결과와 똑같은 값이 등장했다. 성공했다!!!</p><h1 id="왜-값이-다를까"><a href="#왜-값이-다를까" class="headerlink" title="왜 값이 다를까?"></a>왜 값이 다를까?</h1><p>그렇다면 왜 RDD를 사용해서 함수를 적용할 때랑 Dataframe을 갖고 작업한 결과가 다른 것일까?<br>일단<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">view_cart_count = df.select(<span class="hljs-string">'cart'</span>).rdd.map(get_info)</span><br></pre></td></tr></table></figure></p><p>이 코드에서 rdd.map한 부분까지 가져와서 확인해보니 결과값이 많지 않았다. rdd에서 df로 바꿀때 데이터가 변하는 일은 없다는 것이다.<br>그렇다면 이 코드 전에 rdd.map(get_info)하는 부분에서 변형이 일어난 거라고 추측할 수 있다. 하지만 spark 이론에서 map을 적용할 때는<br>map 자체가 narrow transformation에 해당되기 때문에, shuffle이 일어나지 않는다고 나와있다. 결국 shuffle에 의한 데이터 변형의 가능성도 없다고 할 수 있는 것이다. 함수 자체에 이상이 있는 것일까? 그렇다고 보기엔 어렵다. 이 코드를 갖고 구매-할인율에 대한 것을 집계했을 때는 정확한 값이 나왔기 때문이다.</p><p>조금 더 공부해보고 왜 값이 다른지에 대해서는 추후에 계속 수정을 해 나가야겠다.</p><p>결국은 spark에서는 RDD를 사용할지 Dataframe을 사용할지, 그리고 Dataset을 사용할지 먼저 생각하고 작업하는 것이 중요하다.<br>이것에 관련해서는 Databricks에서 나온 <a href="https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html" target="_blank" rel="noopener">문서</a>가 있는데, 이것은 추후에 번역해서 업로드할 예정이다.</p>]]></content:encoded>
      
      <comments>http://tkdguq05.github.io/2020/01/16/spark-in-action/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Zeppelin으로 Spark를 다뤄보자 01</title>
      <link>http://tkdguq05.github.io/2020/01/06/spark-zeppelin/</link>
      <guid>http://tkdguq05.github.io/2020/01/06/spark-zeppelin/</guid>
      <pubDate>Mon, 06 Jan 2020 12:44:53 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Zeppelin-이용해서-pyspark로-데이터-읽기-01&quot;&gt;&lt;a href=&quot;#Zeppelin-이용해서-pyspark로-데이터-읽기-01&quot; class=&quot;headerlink&quot; title=&quot;Zeppelin 이용해서 pyspark로 데이터 읽
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Zeppelin-이용해서-pyspark로-데이터-읽기-01"><a href="#Zeppelin-이용해서-pyspark로-데이터-읽기-01" class="headerlink" title="Zeppelin 이용해서 pyspark로 데이터 읽기 01"></a>Zeppelin 이용해서 pyspark로 데이터 읽기 01</h1><p>Spark는 고속 범용 분산 컴퓨팅 플랫폼으로 정의되곤 합니다. 대용량 데이터를 가져와 빠르게 분석해 낼 수 있다는 점에서 많은 기업들에서 도입을 검토하고 있고 실제로도 많이 사용되고 있습니다. 오늘은 이 유명한 Spark를 다운받고 Zeppelin으로 띄워서 pyspark를 이용해 데이터를 읽어보는 작업까지 해 보겠습니다.</p><p>먼저 Spark를 다운받아 줍니다. <a href="https://spark.apache.org/downloads.html" target="_blank" rel="noopener">Spark 설치</a></p><p><img src="/images/spark_down.png" alt="스파크 다운로드"><br>링크로 들어가면 다음과 같이 나오는데 다운받는 버전은 아무거나 받아도 상관 없지만 저는 AWS EMR로 Spark를 도입하기 전에 연습하는 용으로 사용하는 것이기 때문에 AWS EMR 버전과 같은 2.4.4버전을 다운받았습니다.</p><p>하둡 버전은 사진 그대로 2.7버전으로 진행 했습니다. </p><p>다운이 완료되면 폴더를 만들어서 그곳에 저장해주고 압축을 풀어줍니다.</p><p>tgz로 되어있는 파일은<br><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -xvf [filename]</span><br></pre></td></tr></table></figure></p><p>이렇게 풀어줍니다.</p><p>다음은 Zeppelin입니다. <a href="https://zeppelin.apache.org/download.html" target="_blank" rel="noopener">Zeppelin 설치</a></p><p><img src="/images/zeppelin_down.png" alt="제플린 다운로드"><br>제플린도 역시 두 가지 버전이 등장하는데, 저는 용량이 작은 버전으로 받았습니다. 큰 용량의 버전은 카산드라 등이 다 포함된 버전이기 때문에 굳이 받지 않았습니다.</p><p>제플린도 특정 폴더에 저장해주고 압축을 풀어줍니다.</p><h3 id="Spark-경로-지정"><a href="#Spark-경로-지정" class="headerlink" title="Spark 경로 지정"></a>Spark 경로 지정</h3><p>Spark의 경로를 잘 지정해줘야 Zeppelin이 실행되고 코드를 돌렸을 때 오류가 나지 않습니다.<br>먼저 쉘의 프로파일을 열어줍니다. 저는 zsh을 사용하기 때문에 zshrc를 열겠습니다.<br><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.zshrc</span><br></pre></td></tr></table></figure></p><p>그 다음 설정해야 할 것은 java home 경로입니다. jdk가 없다면 jdk 1.8이상 버전을 다운받아 설치합니다.<br>java home 경로는<br><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-built_in">echo</span> <span class="hljs-variable">$JAVA_HOME</span></span><br></pre></td></tr></table></figure></p><p>이 명령어로 알아낼 수 있습니다. java home의 경로를 알아냈다면 zshrc에 이 위치를 알려줘야합니다.</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-built_in">export</span> JAVA_HOME=<span class="hljs-string">"/Library/Java/JavaVirtualMachines/jdk1.8.0_181.jdk/Contents/Home"</span></span><br></pre></td></tr></table></figure><p>저의 경우는 위치가 다음과 같아서 zsh의 아래쪽에 작성해 주었습니다.</p><p>그리고 설치된 Spark의 위치도 알려줘야 합니다. 아까 저장했던 폴더의 주소를 입력해 줍니다.<br><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-built_in">export</span> SPARK_HOME=/Users/sanghyub/spark-2.4.4-bin-hadoop2.7</span><br></pre></td></tr></table></figure></p><p>저의 경우는 이렇게 되어있습니다. 절대경로로 작성해 주시면 됩니다.</p><p>Spark 세팅은 일단 여기까지 하고 Zeppelin으로 넘어가겠습니다.</p><h3 id="Zeppelin-환경-설정"><a href="#Zeppelin-환경-설정" class="headerlink" title="Zeppelin 환경 설정"></a>Zeppelin 환경 설정</h3><p>Zeppelin이 저장된 폴더로 들어가서 conf로 들어가줍니다. conf에는 <code>ls</code>를 입력해보면 여러 파일들이 있는 것을 볼 수 있습니다. </p><p><img src="/images/zeppelin_conf.png" alt="Zeppelin conf files"><br>이 파일들 중에서 zeppelin-env.sh와 zeppelin-site.xml을 사용해야 하는데, .template으로 된 파일들이 보일 것 입니다. template를 <code>cp</code>를 이용해서 바꿔줍니다.</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp zeppelin-env.sh.template zeppelin-env.sh</span><br></pre></td></tr></table></figure><p><code>cp</code>는 복사하는 것도 있지만, 이렇게 이름을 바꿔주는데에도 사용됩니다.<br>zeppelin-env.sh와 zeppelin-site.xml을 얻었다면 vi를 이용해서 zeppelin-env.sh로 들어갑니다.<br>아까 작성한 자바 경로와 스파크 홈 경로를 그대로 갖고와서 작성해줍니다. zeppelin이 이 위치를 보고 Spark와 jdk를 이용할 수 있도록 적어두는 것 입니다.</p><p><img src="/images/zeppelin_sh.png" alt="zeppelin-env.sh 수정, 이렇게 적어주자"></p><p>zeppelin의 포트도 수정해 줍니다. 기본 포트는 8080포트인데 혹시 충돌될 수 있으니, 저는 안정적으로 9999포트로 변경하겠습니다.</p><p><img src="/images/zeppelin_xml.png" alt="zeppelin-site.xml 이렇게 작성!"></p><p>이제 기본적인 세팅은 끝났고 zeppelin을 실행시켜 봅니다.</p><h3 id="Zeppelin-실행"><a href="#Zeppelin-실행" class="headerlink" title="Zeppelin 실행"></a>Zeppelin 실행</h3><p>Zeppelin 실행은 jupyter notebook여는 것과는 조금 다릅니다. zeppelin을 입력해도 아무일도 일어나지 않습니다. Zeppelin을 열기 위해서는 zeppelin daemon을 실행시켜줘야 합니다.</p><p>zeppeliln daemon은 bin폴더에 있습니다. conf에서 빠져나와서 bin으로 들어가줍니다.<br><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-built_in">cd</span> ../bin</span><br></pre></td></tr></table></figure></p><p><code>ls</code>를 입력하면 찾았던 daemon이 보일 것 입니다. 너무 반갑지만 쉘이 익숙하지 않다면 실행하는 방법을 모를 것입니다. 저도 그랬고 같이 공부했던 사람들도 눈치만 봤었습니다. 백날 눈치를 보고 째려봐도 실행은 되지 않습니다. </p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./zeppelin-daemon.sh start</span><br></pre></td></tr></table></figure><p>이렇게 데몬을 실행시켜줍니다. 확인은 (<a href="https://localhost:9999)로" target="_blank" rel="noopener">https://localhost:9999)로</a> 들어가서 해 보면 됩니다.</p><p><img src="/images/hello_zeppelin.png" alt="Hello Zeppelin"><br>짠! 제플린의 날개가 등장했습니다. 이제 노트를 만들고 데이터를 로드해보는 작업을 하겠습니다.</p>]]></content:encoded>
      
      <comments>http://tkdguq05.github.io/2020/01/06/spark-zeppelin/#disqus_thread</comments>
    </item>
    
    <item>
      <title>케라스 창시자에게 배우는 딥러닝에서의 Failed to get convolution algorithm. This is probably because cuDNN failed to initialize 해결하기</title>
      <link>http://tkdguq05.github.io/2020/01/01/keras-trouble-shooting/</link>
      <guid>http://tkdguq05.github.io/2020/01/01/keras-trouble-shooting/</guid>
      <pubDate>Wed, 01 Jan 2020 07:13:44 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Failed-to-get-convolution-algorithm-This-is-probably-because-cuDNN-failed-to-initialize&quot;&gt;&lt;a href=&quot;#Failed-to-get-convolution-algorit
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Failed-to-get-convolution-algorithm-This-is-probably-because-cuDNN-failed-to-initialize"><a href="#Failed-to-get-convolution-algorithm-This-is-probably-because-cuDNN-failed-to-initialize" class="headerlink" title="Failed to get convolution algorithm. This is probably because cuDNN failed to initialize"></a>Failed to get convolution algorithm. This is probably because cuDNN failed to initialize</h1><p>케라스 창시자에게 배우는 딥러닝 책 진도를 쭉쭉 나가는 중이었다. 챕터5의 CNN코드를 돌리던 중 다음과 같은 에러가 등장했다.</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(<span class="hljs-number">0</span>) Unknown: Failed to get convolution algorithm. </span><br><span class="line">This <span class="hljs-keyword">is</span> probably because cuDNN failed to initialize, so <span class="hljs-keyword">try</span> looking to see <span class="hljs-keyword">if</span> a warning log message was printed above. </span><br><span class="line">[[&#123;&#123;node conv2d_1/convolution&#125;&#125;]] [[metrics/acc/Mean/_99]]</span><br></pre></td></tr></table></figure><p>황금같은 쉬는 날에 cudnn과 CUDA의 꼬임으로 인한 에러인 줄 알고 굉장히 낙담했다. 실제로 저 에러를 복사해다가 구글에 붙여넣어서 답을 찾아보니 다시 설치하라는 의견이 많았다. </p><p>하지만 정말 귀찮아서 내 설치 환경을 다시 살펴보고 이상이 있으면 수정하기로 했다.</p><p>일단 내가 설치한 CUDA와 CuDnn 환경은 저번 글들에 나와 있다.</p><p><a href="https://tkdguq05.github.io/2019/11/10/ubuntu/">ubuntu 딥러닝 서버 구축기 01</a><br><a href="https://tkdguq05.github.io/2019/11/22/ununtu2/">ubuntu 딥러닝 서버 구축기 02</a><br><a href="https://tkdguq05.github.io/2019/12/08/ubuntu3/">ubuntu 딥러닝 서버 구축기 03</a></p><p>CUDA와 CuDNN의 호환성은 문제가 없었다. 그렇다면 뭐가 문제였을까? 하던 중에 Python의 버젼을 살펴봤다.<br>콘다 가상환경에 올리고 쓰고 있었는데 python버전을 확인해보니 python 3.7버전이었다.</p><p>여러 글들을 보다보니 python 3.6버전이 keras와 궁합이 잘 맞는다는 것을 알게되었다. </p><p>그래서 바로</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n [환경 이름] python=3.6</span><br></pre></td></tr></table></figure><p>가상환경을 만들어주고 만든 가상환경을 jupyter kernelspec에 넣어주었다.<br><a href="https://medium.com/@5eo1ab/jupyter-notebook%EC%97%90-%EA%B0%80%EC%83%81%ED%99%98%EA%B2%BD-kernel-%EC%B6%94%EA%B0%80%ED%95%98%EA%B8%B0-ed5261a7e0e6" target="_blank" rel="noopener">jupyter kernelspec 추가하기</a></p><p>python 3.6으로 갈아끼워 준 뒤에<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Conv2D(<span class="hljs-number">32</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">'relu'</span>, input_shape=(<span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>)))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="hljs-number">64</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="hljs-number">64</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">'relu'</span>))</span><br></pre></td></tr></table></figure></p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="hljs-number">64</span>, activation=<span class="hljs-string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="hljs-number">10</span>, activation=<span class="hljs-string">'softmax'</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> keras.datasets <span class="hljs-keyword">import</span> mnist</span><br><span class="line"><span class="hljs-keyword">from</span> keras.utils <span class="hljs-keyword">import</span> to_categorical</span><br><span class="line"></span><br><span class="line">(train_images, train_labels), (test_images, test_labels) = mnist.load_data()</span><br><span class="line"><span class="hljs-comment"># train_images = train_images.reshape((60000, 28, 28, 1))</span></span><br><span class="line"></span><br><span class="line">train_images = train_images.reshape((<span class="hljs-number">60000</span>, <span class="hljs-number">28</span>,<span class="hljs-number">28</span>, <span class="hljs-number">1</span>))</span><br><span class="line">train_images = train_images.astype(<span class="hljs-string">'float32'</span>)/<span class="hljs-number">255</span></span><br><span class="line"></span><br><span class="line">test_images = test_images.reshape((<span class="hljs-number">10000</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>))</span><br><span class="line">test_images = test_images.astype(<span class="hljs-string">'float32'</span>)/<span class="hljs-number">255</span></span><br><span class="line"></span><br><span class="line">train_labels = to_categorical(train_labels)</span><br><span class="line">test_labels = to_categorical(test_labels)</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="hljs-string">'rmsprop'</span>,</span><br><span class="line">             loss=<span class="hljs-string">'categorical_crossentropy'</span>,</span><br><span class="line">             metrics=[<span class="hljs-string">'accuracy'</span>])</span><br><span class="line">model.fit(train_images, train_labels,</span><br><span class="line">         epochs=<span class="hljs-number">5</span>, batch_size=<span class="hljs-number">64</span>)</span><br></pre></td></tr></table></figure><p>코드를 돌렸더니 잘 돌아간다!!!</p>]]></content:encoded>
      
      <comments>http://tkdguq05.github.io/2020/01/01/keras-trouble-shooting/#disqus_thread</comments>
    </item>
    
    <item>
      <title>2019년도 회고, 2020년을 맞이하며</title>
      <link>http://tkdguq05.github.io/2019/12/22/adios-2019/</link>
      <guid>http://tkdguq05.github.io/2019/12/22/adios-2019/</guid>
      <pubDate>Sun, 22 Dec 2019 11:10:22 GMT</pubDate>
      <description>
      
        
        
          &lt;h2 id=&quot;2019-회고&quot;&gt;&lt;a href=&quot;#2019-회고&quot; class=&quot;headerlink&quot; title=&quot;2019 회고.&quot;&gt;&lt;/a&gt;2019 회고.&lt;/h2&gt;&lt;p&gt;2019년은 감사할 일이 많았었던 해, 많은 변화가 있었고, 사람들을 제대로 챙기지 못
        
      
      </description>
      
      <content:encoded><![CDATA[<h2 id="2019-회고"><a href="#2019-회고" class="headerlink" title="2019 회고."></a>2019 회고.</h2><p>2019년은 감사할 일이 많았었던 해, 많은 변화가 있었고, 사람들을 제대로 챙기지 못했었던 해.</p><h3 id="상반기-예상치-못한-취준"><a href="#상반기-예상치-못한-취준" class="headerlink" title="상반기 - 예상치 못한 취준"></a>상반기 - 예상치 못한 취준</h3><p>상반기는 한 단어로 요약할 수 있을 것 같다. ‘취준. 1월부터 6월까지 패스트 캠퍼스 데이터 사이언스 익스텐션 2학기 조교생활을 하면서 동시에 취업준비를 했다. 사실 1월 2월에는 취업을 당장 준비하지 않을 계획이었다. 강의 들은 것과 프로젝트 진행했었던 내용들을 차분히 정리하고 하반기부터 본격적으로 취업에 도전하려고 했었다. 하지만 상반기 서류 지원이 시작되었고, 한번 넣어보자는 생각으로 데이터 분석 관련해서 인턴 몇개랑 정규직 원서를 제출했다. 인턴이라도 될 줄 알았었는데, 다 떨어져버렸다. 말그대로 광탈. 그래도 교수님께 첨삭받은 지원서들이었는데 어안이 벙벙했다. 그렇게 취업시장의 높은 벽을 느껴버리고는 바로 취업 준비를 시작했다. 패캠 강사분에게도 조언을 구하면서 6월까지 원서를 고치고 제출하고, 시험을 보고 면접만 봤었다. 몇 번을 쓴물을 삼키다가 마지막 남은 회사의 면접에서 ‘여기 안되면 다시 준비해서 내년에 도전해야겠다’라는 생각으로 마음 놓고 들어갔다. 지금까지 했었던 데이터 프로젝트를 차분히 설명하고, 2차 면접까지 진행한 후에 최종 합격 통보가 내게 전달되었고 7월 1일 첫 출근 하게 되었다.</p><h3 id="하반기-회사에서-혼자-살아남기"><a href="#하반기-회사에서-혼자-살아남기" class="headerlink" title="하반기 - 회사에서 혼자 살아남기"></a>하반기 - 회사에서 혼자 살아남기</h3><h4 id="입사"><a href="#입사" class="headerlink" title="입사"></a>입사</h4><p>7월부터 지금까지 정신없이 살아오고 있는 것 같다.(글또를 시작한 것도 7월!!!!) 입사한 회사는 이제 데이터 프로젝트를 진행하려는 회사였다. 데이터 사이언스 프로젝트를 위한 준비가 잘 되어있는 회사는 아니었기 때문에, 데이터를 분석하고 모델만 만드는 일은 할 수 없었다. 물론 처음에는 아무것도 몰랐다. OJT를 1주동안 받고 2주차부터 A/B 테스트 자동화 프로젝트를 맡게 되었다. 데이터 조직에 관련된 사람이 나 혼자 뿐이었기 때문에 혼자 리서치하고 코딩하고 결과를 분석했다. 리서치하는 일은 좋았다. 논문이나 글들을 정리해서 방향을 설정하는 것이었기 때문이었다.(물론 수식을 이해하는 부분은 어려웠다) 코딩을 하다 막히면 정말 도와줄 사람이 아무도 없었기 때문에 그 때는 정말 답답해서 자주 옥상으로 올라가 바람을 쐬었다. <del>처음으로 담배를 필까 고민을 했다.</del> </p><p>여차저차 모델을 만들고 정말 싫어하는 Flask를 이용해서 API를 만드는 작업을 했다. 백엔드 쪽은 공부를 얉게 했기 때문에 어떻게 데이터를 전달받고 결과를 출력해서 줘야하는지 이해하는 데 시간이 많이 들었지만, 개발팀의 도움으로 회사 서비스와 이어 붙이는 데 성공했다.(정말 이어 붙이는 데에만…) 이 작업을 진행하면서 어떻게 회사 제품이 서비스 되고 있는지 깊이 알 수 있게 되었고 백엔드와 데이터 엔지니어링에 흥미가 가기 시작했다. 이전에는 무슨 말인지 이해가 하나도 안되어서 해야되는 건 알았지만 하기가 싫었다…</p><h4 id="10월-이후"><a href="#10월-이후" class="headerlink" title="10월 이후"></a>10월 이후</h4><p>10월쯤에 되어서야 혼자있는 데이터팀에 대리님이 오시게 되었고 둘이서 열심히 A/B 테스트 베타 서비스한 결과를 가지고 수정에 수정을 거쳐 드디어 서비스할 수 있는 정도의 제품이 나오게 되었고 화면기획만 되면 내년 초에 오픈할 수 있게 되었다. 동시에 추천 시스템 개발을 10월부터 시작해서 12월 말까지 돌릴 수 있는 알고리즘을 선별해 놓았고 아키텍쳐를 짜는 중이다. A/B 테스트 자동화에 시간을 많이 써서 추천 쪽에 시간을 못 써서 아쉽긴 하지만 데이터 파이프라인을 붙이는 쪽에 신경을 많이 써볼 생각이다. 데이터 엔지니어링…데이터 엔지니어링…잘하고 싶다…</p><h3 id="여가-및-개인-공부"><a href="#여가-및-개인-공부" class="headerlink" title="여가 및 개인 공부"></a>여가 및 개인 공부</h3><p>취미생활은 따로 나가서 하는 건 없는 것 같다. 일주일에 한번 정도 하는 풋살? 그 외에는 집 앞 헬스장에서 살기 위해서 하는 운동과 축구를 잘하기 위해서 운동을 한다. 축구 잘하려고 운동은 정말 가끔했었는데, 입사하고 삼개월 정도 되었을 때 3키로 넘게 쪄버려서 꾸준히 운동을 해야겠다고 마음 먹었다. 운동하는 걸 제외하면 영화보고 음악듣는 게 내 취미생활의 전부인데 뭔가 새로운 걸 해보고 싶은 마음이 있다. 회사에서 마카롱 만드는 걸 배워서 직접 만든 걸 먹어본 적이 있었는데 굉장히 맛있어서 클래스를 한번 들어볼까? 생각해봤다. 생각만했다… 향수를 만들어 보거나 목공예를 하고 싶기도 한데 시간은 없고ㅠㅜㅜㅠㅠㅠ</p><p>입사한 첫 달을 제외하면 개인 공부 시간이 많이 줄었다. 처음에야 할 일도 많지 않고, 엄청난 열정을 갖고 시작했기 때문에 출근하는 버스에서도 관련 논문도 챙겨보고 했었지만, 5개월차에 벌써 피곤에 쩔어 버스만 타면 졸게 되어 버려서 기껏해야 동영상으로 설명해주는 영상 몇개 보는 정도에 그치고 있다. 그러다 딥러닝 공부를 제대로 해보고 싶기도 했고, 일해서 번 돈으로 딥러닝 서버를 집에 하나 두고 싶었던 작은 소망이 있어서 거금 200만원을 투자해서 딥러닝용 PC를 사들였다. <code>sanghyub machine</code>이라는 특징없는 이름을 갖고 있지만 아주 애착이 간다. 딥러닝 모델을 돌리기 위해서 세팅은 다 끝났고, 케라스 창시자에게 배우는 딥러닝을 읽으면서 모델을 한번 돌려보고 있다. 기존 노트북에서 하루종일 돌아가던게 쌩쌩 돌아간다. 역시 돈이 최고인 것 같다. </p><p>하지만, 진짜 하고 싶었던 건 12월까지 <code>sanghyub machine</code>과 함께 캐글 대회에 참가해보는 것이었다. 이것저것 세팅도 하고 회사일도 조금 바빴기에 미뤄두다가 연말이 되어버렸다. 내년에는 꼭 대회에 참가해서 좋은 결과를 만들어 내고 싶다.</p><h2 id="2020"><a href="#2020" class="headerlink" title="2020"></a>2020</h2><p>2020년에는 하고싶은? 목표라고 생각할 만한 것들이 몇개 고정되어 있다. 일적인 부분도 있고 내 개인 생활과 관련된 목표도 있다. 2019년은 닥치는 대로 살다보니 계획적으로 살지 못한 것 같아 아쉬운 것이 있어서, 할 걸 제대로 설정해서 똑바로 살아봐야겠다.(하지만 글또 3기를 한 건 2019년의 큰 계획 중에 하나였다. ‘글을 꾸준히 써보자’, 아주 성공적이진 않지만, 나름 한달에 글은 부끄럽지만 2개는 꾸준히 썼다!)</p><h4 id="2020년에-나는"><a href="#2020년에-나는" class="headerlink" title="2020년에 나는"></a>2020년에 나는</h4><ul><li>추천 시스템이나 다른 서비스를 위한 데이터 파이프라인 구성을 성공적으로 한다.</li><li>퇴근 후 개인 공부시간을 매일 30분 이상 갖는다.</li><li>캐글 대회에 도전한다.</li><li>캐글 대회에서 동메달 이상의 성과를 낸다.</li><li>일주일에 3일 이상 운동한다.</li><li>3대 운동 300에 도전한다.</li><li>돈을 모아서 피렌체에 간다.</li><li>꾸준히 글을 쓴다.</li><li>책을 꾸준히 읽자.</li><li>일을 즐겁게 한다.</li><li>소중한 사람들을 잘 챙기자.</li></ul><p>더 구체적인 목표를 더 쓰고 싶은데, 글로 적으려니 제대로 써지지가 않는다. 아직 2020년까지 8일 더 남았으니까 그 전까지 하고싶은 리스트를 더 늘리고, 더 구체적으로 작성해봐야겠다. 2019년 재밌게 살았다. 이번해와는 또 다르게 2020년을 계획하고 기록해서, 2020년 말에는 꽉 찬 느낌이 드는 해로 만들어 봐야겠다. 그리고 글또 3기가 끝나면 4기에 다시 도전해보고 싶다. 처음에 목표했었던 것은 10만원 deposit을 온전히 연말에 돌려받는 것이었는데, 리뷰하는 것을 까먹어서 10만원 돌려받기는 글러버렸다… 리뷰도 꼼꼼히 하고 지금 글쓰는 것과는 조금 다르게 글 구성에 신결을 써서 작성해보고 싶다. </p>]]></content:encoded>
      
      <comments>http://tkdguq05.github.io/2019/12/22/adios-2019/#disqus_thread</comments>
    </item>
    
    <item>
      <title>ubuntu를 이용한 딥러닝 Server 설치하기 3</title>
      <link>http://tkdguq05.github.io/2019/12/08/ubuntu3/</link>
      <guid>http://tkdguq05.github.io/2019/12/08/ubuntu3/</guid>
      <pubDate>Sun, 08 Dec 2019 06:57:40 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Installation-of-Ubuntu-18-04-LTS-for-Deep-Learning-Computer-2&quot;&gt;&lt;a href=&quot;#Installation-of-Ubuntu-18-04-LTS-for-Deep-Learning-Computer
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Installation-of-Ubuntu-18-04-LTS-for-Deep-Learning-Computer-2"><a href="#Installation-of-Ubuntu-18-04-LTS-for-Deep-Learning-Computer-2" class="headerlink" title="Installation of Ubuntu 18.04 LTS for Deep Learning Computer -2"></a>Installation of Ubuntu 18.04 LTS for Deep Learning Computer -2</h1><h2 id="Ubuntu-with-mac-원격-접속-연결하기"><a href="#Ubuntu-with-mac-원격-접속-연결하기" class="headerlink" title="Ubuntu with mac, 원격 접속 연결하기"></a>Ubuntu with mac, 원격 접속 연결하기</h2><p>저번 글에서는 공유기를 이용한 고정ip설정과 포트포워딩, 원격 접속, 원격 파일 전송에 대해서 알아봤습니다. 이번 글에서는 본격적으로 딥러닝을 하기 위한 Cuda와 CuDnn, tensorflow, keras 설치에 이어 jupyter notebook 연결까지 해보겠습니다.</p><p>설치하는 순서는 다음과 같습니다.</p><ul><li>nvidia 그래픽 드라이버 설치</li><li>Cuda 설치</li><li>CuDnn 설치</li><li>tensorflow, keras 설치</li><li>jupyter notebook 연결</li></ul><h2 id="1-nvidia-그래픽-드라이버-설치"><a href="#1-nvidia-그래픽-드라이버-설치" class="headerlink" title="1. nvidia 그래픽 드라이버 설치"></a>1. nvidia 그래픽 드라이버 설치</h2><p>그래픽 드라이버 설치는 겜돌이들에게는 너무나 익숙한 일입니다. 예전엔가 카트를 하고 싶었는데 화면이 까맣게 나와서 네이버 지식인에 물어봤더니 드라이버 설치를 하라고 했던 기억이 나네요. 그래픽 드라이버 회사의 사이트로 들어가서 그래픽 드라이버를 받아서 설치하면 끝입니다. 같은 방식으로 Ubuntu 서버에도 그래픽 드라이버 종류를 알아본 뒤에, 이에 맞는 드라이버를 받아서 설치해주면 됩니다. 하지만 설치를 잘못하게 되면 검은화면에서 뚝뚝뚝 에러메서지만 흘러나오며 엔터키도 먹지 않는 악몽을 경험하게 될 것입니다. </p><p>자신의 그래픽 카드가 뭔지는 컴퓨터를 사신 분이 잘 아실 것입니다. 그 정보를 가지고 <a href="http://www.nvidia.com/Download/Find.aspx?lang=en-us" target="_blank" rel="noopener">http://www.nvidia.com/Download/Find.aspx?lang=en-us</a> nvidia 홈페이지에 접속한 후에 그래픽 카드 정보를 입력하고 알맞은 그래픽 드라이버의 Version을 확인 합니다.</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ apt-cache search nvidia</span><br></pre></td></tr></table></figure><p>서버로 돌아와 다음 명령어를 이용해 설치가능한 드라이버를 확인해 보고 본격적으로 설치해봅니다.</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install nvidia-xxx</span><br></pre></td></tr></table></figure><p>이제 xxx에 들어갈 적절한 드라이버 Version을 입력하고 설치를 해주면 됩니다. 보통은 정상적으로 설치가 되는데, </p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Errors were encountered while processing:</span><br><span class="line"> nvidia-xxx</span><br><span class="line"> libcuda1-xxx</span><br><span class="line"> nvidia-opencl-icd-xxx</span><br><span class="line">E: Sub-process /usr/bin/dpkg returned an error code (1)</span><br></pre></td></tr></table></figure><p>이런 식의 에러가 날 수 있습니다. 이런 경우에는<br><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo mkdir /usr/lib/nvidia</span><br><span class="line">$ sudo apt-get install nvidia-xxx</span><br></pre></td></tr></table></figure></p><p>를 이용해서 nvidia 폴더를 만들어주고 설치를 진행하면 됩니다.</p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install dkms nvidia-modprobe</span><br></pre></td></tr></table></figure><p>그리고 드라이버 종류에 상관없이 위의 패키지를 설치해주고 그래픽 드라이버가 로드 될 수 있도록 reboot 시켜줍니다.</p><p><a href="https://hiseon.me/linux/ubuntu/install_nvidia_driver/" target="_blank" rel="noopener">설치 가이드 출처</a></p><h3 id="Trouble-shooting"><a href="#Trouble-shooting" class="headerlink" title="Trouble shooting"></a>Trouble shooting</h3><p>설치 후에 뿌듯 뿌듯한 마음으로 reboot 명령어를 내리고 화면을 천천히 지켜보고 있다 보면, 심상치 않은 메세지가 뚝뚝뚝 나오고 엔터키도 듣지 않는 것처럼 보일 때가 있습니다. 저 또한 멘탈이 깨져버려서 10붕동안은 멍하니 쳐다보고만 있었습니다. </p><p>이유는 여러가지가 있겠습니다만, 저의 경우에는 설치된 드라이버 버전이 서버와 맞지 않아서 생기는 문제였습니다. 이럴 경우에는 설치된 드라이버를 삭제하고 다시 설치하는 방법을 생각해 볼 수 있겠습니다.</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt purge nvidia*</span><br></pre></td></tr></table></figure><p>위의 명령어로 nvidia관련 드라이버를 싹 날려주고 reboot하여 맞는 드라이버를 설치해 줍니다. </p><h2 id="2-Cuda-CuDnn-설치"><a href="#2-Cuda-CuDnn-설치" class="headerlink" title="2.Cuda, CuDnn 설치"></a>2.Cuda, CuDnn 설치</h2><p>이제 CUDA 10.0과 cuDNN 7.5 설치를 진행해봅니다. Cuda는 다음의 명령어로 설치해 줍니다.<br><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install cuda-10-0</span><br></pre></td></tr></table></figure></p><p>설치가 되는데 시간이 좀 걸릴 수 있습니다. 설치가 끝나면 제대로 설치가 되었는지를 확인하기 위해서</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc --version</span><br></pre></td></tr></table></figure><p>위의 명령어를 이용해 Cuda Compiler정보를 확인합니다. nvcc정보가 잘 나오면 설치가 잘 된 것입니다.</p><p>이제 CuDnn을 설치해야 하는데, CuDnn은 Nvidia에서 공개적으로 다운받을 수 있게 해놓지 않았습니다. Nvidia에 회원으로 등록을 해야 CuDnn을 다운 받을 수 있게 해줍니다. 따라서 <a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener">https://developer.nvidia.com/cudnn</a> 이 사이트로 들어가 회원가입을 해주고 우리는 Cuda 10.0을 설치해줬으니까 10.0에 맞는 Cudnn 7.5를 다운로드 해줍니다. 다운이 되었으면 저의 경우는 Mac을 이용해서 받았기 때문에, <a href="https://tkdguq05.github.io/2019/11/22/ununtu2/">이전 글</a>에서 다루었던 <code>sftp</code>를 이용해서 파일을 전송했습니다.</p><p>파일을 이동시킨 후에 tar로 말려져 있는 파일을 풀어줍니다.<br><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf cudnn-10.0-linux-x64-v7.5.x.x.tgz</span><br></pre></td></tr></table></figure></p><p>7.5뒤의 버전은 다를 수 있으니 잘 확인하시고 수정해 넣으시면 됩니다. 이제 압축을 푼 파일을 cuda폴더에 복사해 넣어줍니다.</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo cp -P cuda/lib64/libcudnn* /usr/<span class="hljs-built_in">local</span>/cuda-10.0/lib64/</span><br><span class="line"></span><br><span class="line">sudo cp  cuda/include/cudnn.h /usr/<span class="hljs-built_in">local</span>/cuda-10.0/include/</span><br></pre></td></tr></table></figure><p>마지막으로 이동시킨 파일들에 대한 권한을 부여해주면 됩니다.<br><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo chmod a+r /usr/<span class="hljs-built_in">local</span>/cuda-10.0/include/cudnn.h /usr/<span class="hljs-built_in">local</span>/cuda-10.0/lib64/libcudnn*</span><br></pre></td></tr></table></figure></p><p>*추가<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#Nvidia에서 필요한 파일이라고 하네요</span><br><span class="line">sudo apt-get install libcupti-dev</span><br></pre></td></tr></table></figure></p><p>bashrc에 환경변수를 추가해주는 글을 많이 봤는데, 저의 경우에는 굳이 입력을 안해도 잘 인식하는 걸 봐서, 넣지 않았습니다. 제대로 불러오지 못한다면<br><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi ~/.bashrc</span><br></pre></td></tr></table></figure></p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export PATH=/usr/local/cuda-10.0/bin$&#123;PATH:+:$&#123;PATH&#125;&#125;</span><br><span class="line"></span><br><span class="line">export LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64\$&#123;LD_LIBRARY_PATH:+:$&#123;LD_LIBRARY_PATH&#125;&#125;</span><br></pre></td></tr></table></figure><p>를 추가해 주세요</p><h2 id="3-Tensorflow-Keras-설치"><a href="#3-Tensorflow-Keras-설치" class="headerlink" title="3. Tensorflow, Keras 설치"></a>3. Tensorflow, Keras 설치</h2><p>Keras 설치에 앞서, 백엔드로 사용하는 Tensorflow를 설치해 줍니다. 이제 설치는 정말 간단합니다.</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install --upgrade tensorflow-gpu</span><br></pre></td></tr></table></figure><p>python3버전의 tensorflow를 설치해줍니다. cpu 버전을 설치하고 싶다면 -gpu를 빼주면 됩니다.</p><p>conda 가상환경을 만들었다면, 실행시킨 후에 필요 라이브러리를 설치하고 Keras를 최종적으로 설치하면 끝입니다!</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conda activate your_name</span><br><span class="line">(your_name) conda install h5py</span><br><span class="line">(your_name) conda install graphviz</span><br><span class="line">(your_name) conda install pydot</span><br><span class="line">(your_name) conda install keras</span><br></pre></td></tr></table></figure><h2 id="4-Jupyter-Notebook-설치"><a href="#4-Jupyter-Notebook-설치" class="headerlink" title="4. Jupyter Notebook 설치"></a>4. Jupyter Notebook 설치</h2><p>먼저 가상환경으로 들어가주고 pip를 이용해 jupyter notebook을 설치해 줍니다.<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda activate your_name</span><br><span class="line">pip install jupyter notebook</span><br></pre></td></tr></table></figure></p><p>설치가 되었지만, 외부에서 접속을 해서 jupyter notebook을 사용하려면 아직 몇가지 설정이 더 남았습니다.<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter notebook --generate-config</span><br></pre></td></tr></table></figure></p><p>를 이용해서 jupyter 설정파일을 만들어 준 후에</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ipython <span class="hljs-comment">#입력 후 In[1]이 나오면,</span></span><br><span class="line">from notebook.auth import passwd</span><br><span class="line">Enter password:  <span class="hljs-comment">#원하는 비밀번호 입력</span></span><br><span class="line">Verify password: </span><br><span class="line">Out[2]: <span class="hljs-string">'sha1:f24baff49ac5:863dd2ae747212ede58125302d227f0ca7b12bb3'</span></span><br></pre></td></tr></table></figure><p>이렇게 하고 나면 shai로 시작하는 암호문 같은 게 있습니다. 이걸 복사해서 잘 적어두시고, <code>jupyter_notebook_config.py</code>를 열어서<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># The IP address the notebook server will listen on. </span><br><span class="line">c.NotebookApp.ip = &apos;0.0.0.0&apos; </span><br><span class="line">c.NotebookApp.port_retries = 50 </span><br><span class="line">c.NotebookApp.port_retries = 8888</span><br><span class="line">c.NotebookApp.open_browser = False</span><br></pre></td></tr></table></figure></p><p>위와 같이 수정해 주고 <code>jupyter notebook --ip=0.0.0.0</code>으로 실행해주면 jupyter notebook이 짠 하고 등장할 것입니다.</p>]]></content:encoded>
      
      <comments>http://tkdguq05.github.io/2019/12/08/ubuntu3/#disqus_thread</comments>
    </item>
    
    <item>
      <title>ubuntu를 이용한 딥러닝 Server 설치하기 2</title>
      <link>http://tkdguq05.github.io/2019/11/22/ununtu2/</link>
      <guid>http://tkdguq05.github.io/2019/11/22/ununtu2/</guid>
      <pubDate>Fri, 22 Nov 2019 08:18:37 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Installation-of-Ubuntu-18-04-LTS-for-Deep-Learning-Computer-2&quot;&gt;&lt;a href=&quot;#Installation-of-Ubuntu-18-04-LTS-for-Deep-Learning-Computer
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Installation-of-Ubuntu-18-04-LTS-for-Deep-Learning-Computer-2"><a href="#Installation-of-Ubuntu-18-04-LTS-for-Deep-Learning-Computer-2" class="headerlink" title="Installation of Ubuntu 18.04 LTS for Deep Learning Computer -2"></a>Installation of Ubuntu 18.04 LTS for Deep Learning Computer -2</h1><h2 id="Ubuntu-with-mac-원격-접속-연결하기"><a href="#Ubuntu-with-mac-원격-접속-연결하기" class="headerlink" title="Ubuntu with mac, 원격 접속 연결하기"></a>Ubuntu with mac, 원격 접속 연결하기</h2><p>간밤에 평안하셨습니까? 지난번까지는 ubuntu설치를 열심히 했고, 원격 접속은 쉽게 해결할 것이라고 생각하며 가볍게 노트북을 열어서 신나게 원격접속 연결을 시도했습니다. 퇴근 후에 저녁을 먹고 여유롭게 9시부터 만지기 시작했는데, 어느새 11시가 넘어가고 새벽 1시가 넘어가곤 했습니다. 그렇게 며칠을 지내고서야 맥북으로 ubuntu서버에 접속을 할 수 있었습니다. </p><p>이번 글을 쓰기 까지 간밤에 한 일들은 다음과 같습니다.</p><ul><li>ubuntu 인터넷 연결 </li><li>KT 공유기 고정 아이피 설정</li><li>포트 포워딩</li><li>원격 접속 </li><li>원격 파일 전송 </li><li>nvidia 그래픽 드라이버 설치</li><li>Cuda 설치</li><li>CuDnn 설치</li><li>tensorflow, keras 설치</li><li>jupyter notebook 연결</li></ul><p>각 단계에서 다음 단계로 넘어가기 까지 우여곡절이 많았는데, 해결할때마다 은근 쾌감이 있어서 기분 좋았습니다. 리눅스, 그러니까 검은 화면만 보면 겁을 실컷 먹었었는데, 그 두려움을 극복해가는 스스로가 대견스럽다고 생각을 해봅니다. </p><p>이번 글은 ubuntu 인터넷 연결부터 원격 파일 전송까지가 되겠습니다. 가장 힘들었던 부분은 네트워크를 이해하지 못해서 삽질을 여러번해서 애먹었던 부분입니다. 이 부분은 KT 공유기 고정 아이피 설정에서 민낯을 샅샅이 밝힐 예정입니다.</p><h2 id="1-ubuntu-인터넷-연결"><a href="#1-ubuntu-인터넷-연결" class="headerlink" title="1. ubuntu 인터넷 연결"></a>1. ubuntu 인터넷 연결</h2><p>저는 공유기에 있는 랜선을 서버용 컴퓨터에 끼워주면 알아서 인터넷 연결이 될 줄 알았지만 그렇지 않았습니다. 그런 것은 검은 화면이 아닌 곳에서나 가능하다는 것을 왜 그때는 제대로 깨닫지 못했을까요? </p><p>ubuntu 서버 화면으로 넘어가서 vi 편집기를 이용해 다음 명령어를 날려줍니다.<br><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/network/interfaces</span><br></pre></td></tr></table></figure></p><p>그러면 무언가 입력할 것이 있는 창이 하나 나와 있을 것 입니다.<br><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># This file describes the network interfaces available on your system</span></span><br><span class="line"><span class="hljs-comment"># and how to activate them. For more information, see interfaces(5).</span></span><br><span class="line"><span class="hljs-comment"># The loopback network interface</span></span><br><span class="line">auto lo</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># The primary network interface</span></span><br><span class="line">auto eth0</span><br></pre></td></tr></table></figure></p><p>저의 경우에는 이렇게 들어있는 내용이 얼마 없었던 걸로 기억합니다.(당시에 경황이 없어서 화면 사진을 하나도 찍지 못했네요ㅜㅜ)<br><code>ifconfig</code>명령어를 이용해 현재 이더넷의 주소를 알아내야합니다. 저의 경우에는 enpxxxx이었습니다. 이 값을 기억해두고 다시 interface로 들어가서</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># This file describes the network interfaces available on your system</span></span><br><span class="line"><span class="hljs-comment"># and how to activate them. For more information, see interfaces(5).</span></span><br><span class="line"><span class="hljs-comment"># The loopback network interface</span></span><br><span class="line">auto lo</span><br><span class="line">iface lo inet loopback</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># The primary network interface</span></span><br><span class="line">auto enpxxxx</span><br><span class="line">iface enpxxxx inet dhcp</span><br></pre></td></tr></table></figure><p>이런식으로 입력해 줍니다. 이 방식은 유동 ip일때 사용하는 방식이기는 하지만, 일단 인터넷 연결이 되어야 ubuntu 라이브러리를 받을 수 있기 때문에 설정해 줍니다.</p><p>설정이 다 되었다면<br><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service networking restart</span><br></pre></td></tr></table></figure></p><p>를 이용해서 network를 재시작해 반영시켜줍니다.</p><h2 id="2-KT-공유기-고정-ip-설정"><a href="#2-KT-공유기-고정-ip-설정" class="headerlink" title="2. KT 공유기 고정 ip 설정"></a>2. KT 공유기 고정 ip 설정</h2><p>이제 KT공유기의 ip를 고정시켜줄 차례입니다. 고정 아이피를 잡아주는 이유는 간단합니다. 외부 통신을 통해(예를 들어 맥북을 통해) 서버로 접속한다고 했을 때, 고정 ip가 잡혀있지 않다면, 동적 아이피로 인해 서버의 ip 주소는 계속 바뀔 것이고 결국 접속이 안될 것입니다. </p><p>정말 간단하게 설정할 수 있기 때문에 제가 보고 설정한 링크를 첨부해 놓겠습니다.<br><a href="https://extrememanual.net/12155#%EC%95%84%EC%9D%B4%ED%94%BC_%EC%88%98%EB%8F%99_%EC%84%A4%EC%A0%95" target="_blank" rel="noopener">KT 공유기 고정IP 설정</a></p><p>이렇게 고정 ip를 잡아주고 난 뒤에 서버 컴퓨터로 와서 ifconfig 명령어를 쳐서 ip를 확인하고 설정한 ip대로 나온다면 성공입니다.</p><p>이제 아까 dhcp설정을 static으로 고쳐줄 차례입니다.<br><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/network/interfaces</span><br></pre></td></tr></table></figure></p><p>명령어를 통해 수정할 부분으로 가서<br><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># The primary network interface</span></span><br><span class="line">auto enpxxxx</span><br><span class="line">iface enpxxxx inet static</span><br></pre></td></tr></table></figure></p><p>이렇게 고쳐줍니다.</p><h2 id="3-포트포워딩"><a href="#3-포트포워딩" class="headerlink" title="3. 포트포워딩"></a>3. 포트포워딩</h2><p>포트포워딩을 하는 이유는 외부에서 접속을 하게 될 때 공유기로 인해 내가 접속하고 싶은 컴퓨터를 제대로 연결을 못 해주게 됩니다. 공유기가 많은 컴퓨터에 대해서 ip를 뿌려주고 있기 때문입니다. 그래서 어떤 포트로 접속을 해줘야 내가 원하는 컴퓨터에 연결이 되는지를 알려줘야 제대로 연결을 할 수 있게 됩니다. 따라서 포트포워딩은 특정 컴퓨터에게 특정 포트로 연결해 주는 작업을 말하는 것입니다. 포트가 일종의 이정표 역할을 하게 되겠습니다. </p><p>다시 KT 홈허브 관리페이지로 가서 장치 설정에 트래픽 관리로 가면 바로 포트포워딩을 볼 수 있습니다. 포트 포워딩 설정에서 다른 건 건드리지 않고 외부/내부 포트, 내부 ip 주소만 작성해줍니다. 외부/내부 포트에는 내가 열고 싶은 포트 번호를 입력해주고, 내부 ip에서는 고정 ip를 넣어줍니다. 일단 8888포트를 열어줍니다.(jupyter notebook이 켜지는 포트가 주로 8888이니까 이렇게 설정을 했습니다)<br><img src="/images/portforwarding.jpg" alt="포트포워딩 화면"><br><a href="https://m.blog.naver.com/PostView.nhn?blogId=hiho33&amp;logNo=40206570339&amp;proxyReferer=https%3A%2F%2Fwww.google.com%2F" target="_blank" rel="noopener">사진출처</a></p><h2 id="4-원격접속"><a href="#4-원격접속" class="headerlink" title="4. 원격접속"></a>4. 원격접속</h2><p>원격접속을 위해서 우리가 연결할 포트가 필요합니다. ssh접속은 22번 포트를 사용하고, 보통 처음 산 컴퓨터에는 이런 설정이 제대로 되어있지 않은 경우가 많습니다. 그렇기 때문에 직접 포트를 열어주도록 하겠습니다.</p><p>서버컴퓨터로 돌아와서<br><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/ssh/sshd_config</span><br><span class="line">``` </span><br><span class="line">명령어를 입력해 줍니다. 여기서 sshd_config가 없다면, </span><br><span class="line"></span><br><span class="line">```bash</span><br><span class="line">apt-get install openssh-server</span><br><span class="line">``` </span><br><span class="line">를 통해 ssh를 설치해주면 됩니다.</span><br><span class="line"></span><br><span class="line">sshd_config를 보면 Port라고 써있는 부분이 있습니다. 해당 라인이 <span class="hljs-comment">#로 주석 처리 되어 있거나, 포트 넘버가 적혀있지 않은 경우에는, i를 눌러 insert모드로 바꾸고 port에 22를 넣어줍니다. 그리고 esc를 누르고 :wq(저장 후 종료)로 빠져나옵니다. 그러면 원격접속을 위한 준비는 끝났습니다.</span></span><br><span class="line"></span><br><span class="line">이제 맥북으로 돌아와 터미널을 열어줍니다. </span><br><span class="line">```bash</span><br><span class="line">ssh -p 22 [servername]@[ip address]</span><br></pre></td></tr></table></figure></p><p>이 명령어를 입력해주면 연결이 됩니다. ssh로 22번 포트에 접속해 준다는 것이고, 설정한 서버이름과 서버가 사용하는 ip주소를 입력해주고 설정한 비밀번호를 입력해주면<br><img src="/images/connect_server.png" alt="연결 성공!!"><br>연결에 성공하게 됩니다.<br>(*주의, 혹시 집에서 노트북도 같은 아이피를 쓰고 있는 상태에서 연결을 시도하게 되면 100% 연결 성공했다고 나오게 된다. 공유기를 통해 내부적으로 연결이 되어 있기 때문이다. 정확한 확인을 위해서 잠시 노트북의 wifi를 끄고 테더링을 걸어서 다시 확인해보자, 이렇게 해서 연결이 된다면 진짜 된 것이다.)</p><h2 id="5-원격-파일-전송"><a href="#5-원격-파일-전송" class="headerlink" title="5. 원격 파일 전송"></a>5. 원격 파일 전송</h2><p>원격 파일 전송은 로컬에 있는 파일을 서버에 보내고 싶을 때 혹은 서버에 있는 파일을 로컬로 가져오고 싶을 때 사용할 수 있습니다. 특히 Nvidia 그래픽 드라이버를 서버에 보내서 설치하고 싶을 때 아주 유용하게 사용할 수 있습니다.</p><p>scp를 사용해도 되고, sftp를 사용해도 된다.</p><p>개인적으로 sftp를 더 선호하기 때문에 sftp로 파일 전송하는 법을 간략히 설명해보면,<br>아까 원격접속을 했던 것과 마찬가지로<br><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sftp [servername]@[ip_address]</span><br></pre></td></tr></table></figure></p><p>앞에만 sftp로 바꿔주고 나머지는 똑같이 입력한다. 그러면 패스워드를 입력하라고 나오고 정상적으로 패스워드를 입력했다면 sftp&gt; 로 시작하는 간단한 화면이 등장한다. sftp는 쉘을 오픈한 폴더 위치에서 시작하게 되므로 파일이 있는 위치로 이동한 다음 쉘을 여는 것을 권장한다. </p><p>여기서 <code>put</code>명령어를 입력하고 보낼 파일이름을 끝까지 적으면, 서버에 파일이 전달되는 것을 확인할 수 있다.</p><hr><p>이제 진짜 딥러닝 PC를 만들기 위한 기본 세팅이 끝났다. 퇴근 하고 집에와서 잠도 적게 자면서 연결했는데 생각보다 금방 끝나서, 그리고 회사에서도 연결이 되어서 뿌듯했었다. 이제 간밤에 악몽을 꾸게 만든 Nvidia 그래픽 드라이버 설치, CUDA 설치 그리고 CuDNN 설치가 남았다. </p>]]></content:encoded>
      
      <comments>http://tkdguq05.github.io/2019/11/22/ununtu2/#disqus_thread</comments>
    </item>
    
    <item>
      <title>ubuntu를 이용한 딥러닝 Server 설치하기 1</title>
      <link>http://tkdguq05.github.io/2019/11/10/ubuntu/</link>
      <guid>http://tkdguq05.github.io/2019/11/10/ubuntu/</guid>
      <pubDate>Sun, 10 Nov 2019 11:35:14 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Installation-of-Ubuntu-18-04-LTS-for-Deep-Learning-Computer-1&quot;&gt;&lt;a href=&quot;#Installation-of-Ubuntu-18-04-LTS-for-Deep-Learning-Computer
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Installation-of-Ubuntu-18-04-LTS-for-Deep-Learning-Computer-1"><a href="#Installation-of-Ubuntu-18-04-LTS-for-Deep-Learning-Computer-1" class="headerlink" title="Installation of Ubuntu 18.04 LTS for Deep Learning Computer -1"></a>Installation of Ubuntu 18.04 LTS for Deep Learning Computer -1</h1><h2 id="Ubuntu-Installation-The-Trouble-Shooting"><a href="#Ubuntu-Installation-The-Trouble-Shooting" class="headerlink" title="Ubuntu Installation - The Trouble Shooting"></a>Ubuntu Installation - The Trouble Shooting</h2><p>평소에 캐글 대회에 관심이 있었고, 제대로 대회에 참여해봐야지 하는 생각이 있었습니다. 그러다가 IEEE 대회에 참여해 봤습니다. 결과는 노메달!, 동메달이라도 따보고 싶었는데 아쉽게 메달을 놓치게 되었습니다. 그때 정말로 캐글 대회에서 메달을 따보고 싶다는 생각이 들었고, 올해가 되기 전에 대회에 한번 더 참여하는 것과, 내년 초까지 Competition으로 Expert를 따보자는 계획을 하게 되었습니다.</p><p>계획을 위해서는 딥러닝용 사양 좋은 PC가 필수라는 생각이 들었고, 시원하게 2백만원 정도의 사양의 컴퓨터를 맞추게 되었습니다.</p><p><img src="/images/spec.jpeg" alt="PC의 사양"></p><p>딥러닝용 PC서버를 만들기 위해서 OS를 정해야 했는데, 캐글 고수분들께서 Ubuntu로 세팅을 많이 하시는 걸 보고 바로 usb에 부팅용 iso를 받아서 시동 디스크를 만들었습니다.</p><p>제가 주로 보고 따라한 블로그 주소는 다음과 같습니다. <a href="https://simonjisu.github.io/datascience/2018/06/02/gpuserver.html" target="_blank" rel="noopener">장지수님 블로그, 개인 딥러닝용 서버 설치 과정기</a></p><p>이 과정을 보고 쭉 따라했고, usb를 넣고 부팅을 시켰더니,<br><img src="/images/error.jpeg" alt="에러에러에러!!!!"></p><h3 id="Ubuntu-18-04-USB-설치-error-Mac-OS-이용"><a href="#Ubuntu-18-04-USB-설치-error-Mac-OS-이용" class="headerlink" title="Ubuntu 18.04 USB 설치 error (Mac OS 이용)"></a>Ubuntu 18.04 USB 설치 error (Mac OS 이용)</h3><p>쉽게 될 줄 알았더니 똭!! 에러가 떠버렸습니다. Google신을 답을 알고 계시겠죠? 하지만 답을 쉽게 주지는 않으시는 것 같습니다. 3시간의 서칭 끝에 ‘<code>nouveau</code> unknown chipset’, 누보(새 시작 이라는 말이라고 합니다)에 대한 해결법을 찾았습니다. 부팅 디스크를 넣고, ubuntu Grub화면까지 간 다음(grub 화면이 안나올 경우 shift를 누르면 된다고 하네요), e를 눌러서 텍스트 편집기로 갑니다. 이후 나타나는 화면에서 <code>quiet splash</code> 혹은 <code>quiet ---</code>로 표시된 부분으로 갑니다. <code>quiet splash nomodeset</code> 또는 <code>quiet splash nomodeset</code>을 입력 후 F10을 눌러 저장하고 리부팅 합니다.</p><p>보통 이렇게 하면 문제없이 ubuntu화면으로 넘어가서 설치가 될 것입니다. 하지만 신은 저에게 편한 삶을 허락하지 않는 것 같습니다. 일요일에 좀 쉬고싶었는데 눈치없이 등장하는 에러들… <code>couldn&#39;t get size 0x80000000000e</code>와 <code>MODSIGN: Couldn&#39;t get UEFI db list</code> 그리고 <code>line 7: can&#39;t open /dev/sdc: No medium found</code>. 또 다시 Google 신에게 달려가서 2시간 동안 서칭하고 실패하고를 반복했습니다. 그러다가 사막의 오아시스 같은 솔루션을 발견했습니다.</p><p><a href="https://askubuntu.com/questions/47076/usb-boot-problems" target="_blank" rel="noopener">line 7 no medium found 솔루션</a></p><p>3 보트업 받은 솔루션을 보면 약간의 야매 방법이 등장합니다. 아까 nouveau 메시지에 대한 해결을 하기 위해 <code>nomodeset</code>을 사용했는데 그것 대신 <code>break debug</code>를 입력하는 것 입니다. 이렇게 하면 debug 메시지가 쭈우욱 등장하고 엔터를 눌렀을 때 입력할 수 있는 터미널이 나오게 됩니다. 여기서</p><ol><li>부팅 디스크인 USB를 빼고</li><li>다시 USB를 넣은 후에</li><li>exit을 입력하고 엔터를 누릅니다.</li></ol><p>이렇게 되면 화면이 후루룩 쭉죽 지나가면서 된다 된다…라는 희망에 빠지게 됩니다.</p><p><img src="/images/success.jpeg" alt="성공이다ㅠㅠㅠㅠㅜㅠㅜㅜㅠ"><br>성공입니다. ubuntu 설치 화면으로 정상적으로 이동하였습니다. 여기서부터 세팅은 안내에 따라서 착착 맞춰서 하면 되고, 쭉 진행 하면 성공적으로 username과 서버명이 등록된 ubuntu 화면을 볼 수 있게 됩니다.</p><p>잠시 달콤한 성공을 맛봤으니 원격 부팅 세팅을 해보아야겠습니다. 블로그 설명에 따라</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/ssh/sshd_config</span><br></pre></td></tr></table></figure><p>를 쳐봅니다. </p><p>?????</p><p>그런건 없습니다. ssd_config를 오타냈나 싶어서 쳐보고 확인해보지만 블로그 설명과는 다른 값이 나옵니다. 찾아보니 </p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install openssh -server</span><br></pre></td></tr></table></figure><p>을 해야 만들어진다고 합니다. 자 그럼 sudo apt-get install openssh -server를 입력해봅니다. <code>Unable to fetch ~~</code>가 나올 것입니다. 이것은 현재 ubuntu 라이브러리를 받는 서버가 맛이 갔거나, 현재 인터넷 연결이 안되어 있다는 말입니다. 또 다시 문제에 봉착했습니다.</p><h3 id="인터넷-연결이-안되어있습니다-Ubuntu에서는-인터넷-연결을-어떻게-하는-것일까요"><a href="#인터넷-연결이-안되어있습니다-Ubuntu에서는-인터넷-연결을-어떻게-하는-것일까요" class="headerlink" title="인터넷 연결이 안되어있습니다. Ubuntu에서는 인터넷 연결을 어떻게 하는 것일까요?"></a>인터넷 연결이 안되어있습니다. Ubuntu에서는 인터넷 연결을 어떻게 하는 것일까요?</h3><p>또 다시 서칭을 시작했습니다. 인생은 깁니다. 주말은 짧습니다. 일단 떡볶이를 먹고 제정신을 차린 후 다시 시도해보았습니다. 여러 솔루션들이 나왔지만 고정 ip를 이용하는 글이 대부분이었고 제가 원하는 답은 없는 것 같았습니다. </p><p>먼저 </p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/network/interfaces</span><br></pre></td></tr></table></figure><p>명령어를 통해서 네트워크 설정이 어떻게 되어있는지 확인했습니다. 보통의 경우라면</p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># This file describes the network interfaces available on your system</span></span><br><span class="line"><span class="hljs-comment"># and how to activate them. For more information, see interfaces(5).</span></span><br><span class="line"><span class="hljs-comment"># The loopback network interface</span></span><br><span class="line">auto lo</span><br><span class="line">iface lo inet loopback</span><br><span class="line"><span class="hljs-comment"># The primary network interface</span></span><br><span class="line">auto eth0</span><br><span class="line">iface eth0 inet dhcp</span><br></pre></td></tr></table></figure><p>이렇게 나와있는 게 정상이고 default 값이라는 얘기가 많아서 똑같이 설정을 해주었습니다. 하지만 리부트해도 여전히 인터넷 연결은 되지 않았습니다. </p><p>하지만 스스로 답을 구하는 자에게는 복이 주어집니다. fresh ubuntu installation을 한 사람이 인터넷 연결이 안된다는 글을 올린 것을 보았고 솔루션 내용은 다음과 같았습니다. </p><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo ifconfig eth0 up   </span><br><span class="line">sudo dhclient eth0</span><br></pre></td></tr></table></figure><p>물론 바로 되지는 않습니다. 세상에는 쉬운일이 없습니다. 항상 자신의 상황에 맞는지 확인하고 문제에 쏙 맞게 다듬을 필요가 있습니다. 문제는 eth0 부분이었습니다. eth0에 해당하는, 자신의 값을 알아야 했습니다.</p><p><code>ifconfig -a</code>를 이용하면 logical name을 알 수 있습니다. 저의 경우에는 enp34s0였습니다. </p><p>이 값을 다시 넣어서 엔터를 눌러주고<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ping www.google.com</span><br></pre></td></tr></table></figure></p><p>로 테스트를 해주면, 이제 구글에 ping을 날릴 수 있는 것을 확인할 수 있습니다.</p><p>일요일을 다 날렸지만, 이제 나름대로 세팅할 수 있는 환경을 만들어 놔서 뿌듯합니다. 월요일에 퇴근하고 이제 원격 부팅 접속을 만져봐야겠습니다.</p>]]></content:encoded>
      
      <comments>http://tkdguq05.github.io/2019/11/10/ubuntu/#disqus_thread</comments>
    </item>
    
    <item>
      <title>2019 GDG DEVFEST SEOUL 행사를 다녀오다</title>
      <link>http://tkdguq05.github.io/2019/10/20/GDG-DEV-FEST/</link>
      <guid>http://tkdguq05.github.io/2019/10/20/GDG-DEV-FEST/</guid>
      <pubDate>Sun, 20 Oct 2019 08:30:50 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;2019-GDG-DEVFEST-SEOUL&quot;&gt;&lt;a href=&quot;#2019-GDG-DEVFEST-SEOUL&quot; class=&quot;headerlink&quot; title=&quot;2019 GDG DEVFEST SEOUL&quot;&gt;&lt;/a&gt;2019 GDG DEVFEST SEO
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="2019-GDG-DEVFEST-SEOUL"><a href="#2019-GDG-DEVFEST-SEOUL" class="headerlink" title="2019 GDG DEVFEST SEOUL"></a>2019 GDG DEVFEST SEOUL</h1><p>2019 GDG DEVFEST SEOUL 행사가 세종대학교 광개토관 지하 2층 컨벤션홀에서 열렸습니다. 2주 전에 행사 소식을 접했는데 타임 테이블을 보니 ML/AI관련 세션이 많이 준비되어 있고 관심있는 내용이 있어서 바로 티켓을 구매했습니다. 특히 캐글 코리아에서 활동하시는 이유한 님의 BERT in Kaggle, 분자대회에서 BERT를 이용해서 어떻게 금메달을 획득했는지가 궁금해서 질러버렸습니다.(캐글 코리아 짱짱)</p><p><img src="/images/NAVERcloud/timetable.png" alt="GDG 시간표"><br>타임테이블은 다음과 같았습니다.</p><h2 id="쉽게-따라할-수-있는-한국어-임베딩-구축-by-이기창님"><a href="#쉽게-따라할-수-있는-한국어-임베딩-구축-by-이기창님" class="headerlink" title="쉽게 따라할 수 있는 한국어 임베딩 구축 by 이기창님"></a>쉽게 따라할 수 있는 한국어 임베딩 구축 by 이기창님</h2><p>맨 첫 번째로 Google Cloud Korea 양승도님께서 키노트 발표를 해주셨고 30분간의 쉬는시간을 가졌습니다. 그리고 제가 첫번째로 들으려고 했던 세션은 Naver 이기창님의 <strong>쉽게 따라할 수 있는 한국어 임베딩 구축</strong> 이었습니다.<br><img src="/images/NAVERcloud/Gichang.jpeg" alt="이기창님의 세션"> 쉬는시간에 밥을 빨리 먹으려고 하는데, 식사가 너무 늦게나오는 바람에 세션의 앞부분은 놓쳤습니다(ㅠㅠㅠㅠㅜㅠ). 아쉬운 부분이 있었지만, 핵심은 기존의 워드 기반의 임베딩보다 최근에는 문장 수준의 임베딩이 잘 된다는 것이었습니다. 문장 수준의 임베딩이 나온 이후로는 워드 기반의 임베딩에 관한 페이퍼가 거의 등장하지 않는다고 하셨습니다. 그 만큼 문장 수준의 임베딩의 결과가 훌륭하다는 것이겠습니다. 실제로 ELMo가 등장한 이후에 리서치 트렌드가 아예 문장 수준의 임베딩으로 바뀐것이 관찰되었습니다. 문장 수준의 임베딩에는 대표적으로 두 가지 알고리즘이 있는데 바로 앞서 말씀드린 ELMo와 그 유명한 BERT입니다. BERT는 transformer network이며 attention 기반으로 만들어진 것입니다. BERT는 기존의 일방향성의 문맥 흐름에서 양방향성의 문맥을 읽어냄으로써 동음이의어 분간을 가능하게 만들었습니다. BERT는 pretrain하고 fine tuning 하는 작업이 필요한데, pretrain하는 작업은 추천하지 않는다고 하였습니다. 그 이유는 이 모델을 훈련시키는데 GPU 8개로 2주의 시간이 필요하기 때문입니다. GPU리소스가 충분하다면야 가능하겠지만, 그 보다 공개된 BERT를 사용하면 좋겠습니다. 공개된 BERT 성능이 나쁘지 않기 때문입니다. 그리고 세션에서 마지막으로 강조한 부분은 임베딩 하고 그 위에 무엇을 올릴까에 관한 것이었습니다. 보통 Bi-Direction만 사용하곤 하는데, 그 위에 활용하는 부분은 자유롭게 바꿔보면서, 실험해보며 다양한 모델들을 만들어 볼 수 있다는 것으로 세션이 종료되었습니다.</p><h2 id="Clean-Code-for-ML-AI-by-한성민님"><a href="#Clean-Code-for-ML-AI-by-한성민님" class="headerlink" title="Clean Code for ML/AI by 한성민님"></a>Clean Code for ML/AI by 한성민님</h2><p>15분의 휴식시간이 끝나고 두 번째 세션에 들어갔습니다. 두 번째로 들은 것은 Naver 한성민님의 <strong>Clean Code for ML/AI</strong> 였습니다.<br><img src="/images/NAVERcloud/cleancode.jpeg" alt="한성민님의 클린코드">클린 코드에 대한 중요성을 말하기전에 설명해주신 개념은 깨진 유리창 이론에 관한 것이었습니다. 품질이 떨어지는 코드를 쌓아올리는 시작하는 순간 부터 다른 협업자의 코드 품질도 떨어지기 시작합니다. 그렇기 때문에 보이 스카웃 규칙대로 코딩을 하는 것이 중요합니다. 그 규칙은 간단합니다.</p><ul><li>떠날 때는 찾을 때보다 캠프장을 더욱 깨끗이 할 것</li><li>손을 거치게 된 코드는 원래 상태보다 더 낫게 만들고 떠나라</li></ul><p>훌륭한 도입부와 더불어 기존에 제가 짠 코드가 더럽다고 계속 생각을 했었고, Clean Code에 대해서 중요성을 항상 들어왔기 때문에 더 집중하게 되었습니다. ML/AI 관련 코드를 짤 때면 If else구문을 자주 활용했었고, indentation이 복잡해져 가독성이 많이 떨어지는 일이 빈번했습니다. 역시 한성민님이 지적한 부분도 같았습니다.<br><img src="/images/NAVERcloud/code_smell.jpeg" alt="코드 악취"><br>일명 <code>코드 악취</code>라고 불리는 더러운 코드들을 소개해주셨고, 깨끗하게 정리된 코드들을 보여주셨습니다.<br><img src="/images/NAVERcloud/cleaned_code.jpeg" alt="정리된 모습"><br>보면서 느끼는 것이 너무 많았고, 회사에 있는 코드를 빨리 정리하고 싶다는 생각이 들었습니다. 최근에 한 프로젝트의 코드들이 눈앞에 지나가면서 다시보기 싫었던 그 느낌이 생각났습니다. 이 외에도 다양한 코드 악취 Case들을 보여주시고 정리한 내용들을 보여주셨습니다. 대표적으로 너무 많은 분기는 좋지 않으므로, return이나 continue를 이용해 가드 클로져 구문을 사용하는 것을 추천해 주셨고, 주ㅜ석 남용도 코드 악취에 해당하기 때문에 함수로 정의하는 것이 좋다고 말씀해 주셨습니다. 한 함수에는 너무 많은 기능을 담지 않고, 50줄 안으로 쓰는 것이 적정하며, 동일한 작동을 너무 많이 반복하는 것을 지양해야 함을 알려주셨습니다. 그 외에 연구자와 개발자끼리 코드 컨벤션이 맞지 않는 문제, IDE로 사용하지 않는 변수들 제거, 수정이 빈번한 변수들은 전역 변수로 추출, 복잡성이 높은 로직에 대해서 함수 추출해 optimizer과 hyperparameter로 뽑아내기 등을 설명해 주셨고<br>google/gin-gonfig나 Lint와 Quality Gate와 같은 클린코드 툴을 알려주셨습니다. 개인적으로 느끼기에는 바로 써먹을 수 있고, 코드의 퀄러티가 높아질 수 있기에 너무 좋은 세션이었습니다. 클린 코드에 대해서 제대로 느끼게 만든 훌륭한 강의였습니다. </p><h2 id="BERT-in-Kaggle-by-이영수님-송원호님-이유한님"><a href="#BERT-in-Kaggle-by-이영수님-송원호님-이유한님" class="headerlink" title="BERT in Kaggle by 이영수님, 송원호님, 이유한님"></a>BERT in Kaggle by 이영수님, 송원호님, 이유한님</h2><p>세번째 세션은 듣고싶었던 캐글 세션이었습니다.<br><img src="/images/NAVERcloud/bert_in.jpeg" alt="Kaggle Korea의 갓갓갓"><br>먼저 이영수님께서 BERT의 개념에 대해서 간략하게 설명해 주셨습니다. 맨 처음에 들었던 세션인, 이기창님의 세션에서 이해가 잘 안되었던 부분이 이영수님의 세션을 통해 어느정도 해결이 되었습니다.<br><img src="/images/NAVERcloud/bert_transformer.jpeg" alt="이영수님이 설명해주시는 BERT"><br>설명이 어느정도 끝나고 다음 바통을 잡은 분은 송원호님이었습니다. 송원호님은 Toxic 대회를 진행하면서 BERT를 통해 스코어를 올렸었던 경험에 대해서 설명해 주셨습니다. Toxic대회는 2017년에 한번 진행했었던 대회인데, 어떤 코멘트에 대해서 이 코멘트가 정상인지 악성인지 분류하는 문제입니다. 2019년에 다시 열리기 된 것은 바로 Unintended Bias가 추가되었기 때문입니다. 특정 키워드가 들어가게 되면 악성으로 분류되어버리는 문제 때문에, 이것을 더 정밀하게 분류해 내는 모델이 필요했고, 더 정밀해진 Metric을 만족시켜야 하는 대회였습니다. 그렇기 때문에 Metric에 대한 설명이 쭉 진행되었고 Metric에 맞는, 기존 loss와 다른 loss function을 재 정의했어야 했던 점을 설명해 주셨습니다. 결구 새로 열린 이 대회에서 중요했던 것은 <code>문맥</code>이었습니다. 문맥을 잘 살려서 코멘트를 분류해야 했었기 때문에 BERT로 접근을 했고 그 결과가 Baseline을 사용할 때에 비해서 좋아질 수 있었습니다. Leaderboard 상으로는 10등으로 in-money권에 있었지만 결과는 26등이었습니다. 쉐이크업으로 인해 등수가 떨어지게 되었는데, 캐글의 discussion에서 그 이유가 등장했습니다. 원호님과 비슷하게 접근을 했지만 높은 등수를 기록했던 분과의 차이점은 모델에서 BERT large, small, medium을 다 사용했고 GPT 2 small도 활용하며, XLNet까지 사용했다는 점이었습니다. 크고 다양한 언어 모델을 사용했고 속도 문제에 있어서는 Sequence Bucketing을 통해 해결한 점이 큰 차이점이었습니다. 결론은 다음과 같았습니다. </p><ul><li>NLP 에서 좋은 머신은 꼭 필요하다.</li><li>작은모델 큰 모델 다 중요하다.</li><li>Evaluation에 맞는 loss를 잘 정의해야한다.</li><li>파이프라인을 일찍 구성하고 실험을 많이 해봐야 한다.</li><li>제한된 시간하에 높은 점수를 위해 속도 줄이기 위한 여러 기술이 필요하다.</li></ul><p>그 다음으로는 생일을 맞으신 이유한님이 발표해주셨습니다.<br><img src="/images/NAVERcloud/birthday.jpeg" alt="발표자이자 생일자 이유한님"><br>이유한님게서는 분자대회에서 BERT를 사용한 경험에 대해서 전달해주셨습니다. 먼저 과학에서 머신러닝이 어떻게 사용되는지에 대해 간략히 설명해 주셨고 과학과 머신러닝의 유사점에 대해서 정리해주셨습니다. 본격적으로 분자대회에 대해서 설명을 해주셨는데, 정확하게는 이해하지 못했고 아무튼 양자 계산으로 너무 힘든 분자에 관한 어떤 예측 문제를 딥러닝을 이용해서 풀어보는 대회였습니다. 보통 분자는 그래프 네트워크와 유사한 부분이 있습니다. 그래서 유한님도 처음에 GNN을 통해 접근을 했었다고 합니다. 하지만 분자를 sentence로 풀어서 BERT에 넣어봤더니 성적이 갑자기 뛰기 시작했습니다. 그래프 네트워크보다 오히려 더 좋은 성적이 나오기 시작한 것입니다. 분자의 정보를 문장화 시켰고, 각 정보를 임베딩하고 벡터화했습니다. 그리고 데이터에 기반해 자발적으로 학습된 임베딩을 뽑아냈습니다. 결국 임베딩도 학습된 것이고 임베딩된 결과도 학습되었습니다. end to end 모델로 구성한 것이고 결국 딥러닝 모델이 알아서 다 하게 되는 모델을 만들어 낸 것입니다. 여기에 Auxiliary targets을 이용해서 5개의 타겟으로 학습시켰고, 세밀한 정보가 도출되어 이것을 이용해서 점수를 끌어내었다고 설명해 주셨습니다. 여기까지 대회에 대해서 정리해 주셨고, 캐글 코리아 운영자답게 캐글 대회에서 높은 점수를 받는 방법에 대해서 알려주셨습니다. </p><h4 id="캐글에서-높은-점수를-얻으려면"><a href="#캐글에서-높은-점수를-얻으려면" class="headerlink" title="캐글에서 높은 점수를 얻으려면?"></a>캐글에서 높은 점수를 얻으려면?</h4><pre><code>- Diversity를 살려서 Ensemble하자- 다양한 모델의 사용- 다양한 시드, 아키텍쳐 같아도 시드가 다르면 다른 모델- Pseudo Labeling, 예측한 값을 타겟으로 한 테스트 셋으로 새로 학습을 진행한다.(대회니까 가능함)- 뭘 쓸까 항상 생각해야 한다. 학습 방식을 선택해야 하는데, EDA를 통해서 특성을 파악하고 모델을 선택해야 한다.- Loss functionn을 잘 찾아야 함,    - BCE, MAE, MSE, CORAL, DICE 등, 다 해보고 좋은 것을 선택한다- 학습이 잘 될 수 있는 학습 스케쥴링</code></pre><h2 id="구글-번역이-크라우드소스로-어떻게-언어를-배워요-by-Anh-Tuan-Nguyen"><a href="#구글-번역이-크라우드소스로-어떻게-언어를-배워요-by-Anh-Tuan-Nguyen" class="headerlink" title="구글 번역이 크라우드소스로 어떻게 언어를 배워요? by Anh Tuan Nguyen"></a>구글 번역이 크라우드소스로 어떻게 언어를 배워요? by Anh Tuan Nguyen</h2><p>마지막으로는 구글 브레인의 안 투앙님의 발표였습니다. 프랑스분이셨는데, 한국어로 발표해주신 점이 인상깊었습니다.<br><img src="/images/NAVERcloud/crowd.jpeg" alt="Crowd소스이다, Cloud가 아니다"><br>발표는 간단했습니다. 머신러닝에 대해서 설명하고, 학습과 추론에 대해서 짚었습니다. 지도학습에 대해서만 말씀해주셨고 이 모델을 활용하는 것에서는 Google의 photo에서 텍스트를 감지하는 것, 그리고 동물 감지, 예를 들어 강아지를 포토에서 검색하면 찍은 사진중에 강아지가 감지된 사진이 선택되는 것을 말씀해 주셨습니다. 그리고 번역에 대해서 말씀을 하기 시작하셨는데, 가끔 번역이 잘 안되는 내용이 있다고 하셨습니다.<br><img src="/images/NAVERcloud/gee.jpeg" alt="번역이 잘 안되는 한국말"><br><img src="/images/NAVERcloud/jmt.jpeg" alt="JMT"></p><p>위의 사진들이 그 예를 찍은 것입니다. 고치는 방법은 여러가지가 있겠습니다만, 많은 데이터를 통해서 해결해 나갈 수 있습니다. Google Crowdsource라는 앱을 통해서 가능하다는 것입니다. 일종의 게임을 만들어서 사용자가 해석에 대한 맞는 라벨을 골라주는 것입니다. 이 게임을 통해서 뱃지를 얻을 수 있고 레벨을 올릴 수 있다고 설명해 주셨습니다. 발표시간이 조금 남아서 질문 답변 시간을 길게 가졌고 이 마지막 세션을 끝으로 GDG DEVFEST행사가 종료되었습니다. </p><p>처음 가본 GDG행사였는데, 알고 싶었던 BERT모듈에 대해서 일부 알게 되었고, Kaggle에 대한 경험담과 피와 살이 될 것 같은 Clean code에 대해서 제대로 알 수 있게 되어 좋았습니다. 일찍 예매해서 만원정도에 티켓을 구매할 수 있었는데, 값이 아깝지 않았습니다.(물론 GDG에 참여한 회사들의 굿즈들을 많이 받고 간식도 많이 먹긴 했습니다.) 다음에 또 이런 행사가 있으면, 꼭 참여하고 싶다는 생각이 들었고 언젠가는 저기서 발표하고 싶다는 작은 목표를 기록해두면서 글을 마무리합니다.</p>]]></content:encoded>
      
      <comments>http://tkdguq05.github.io/2019/10/20/GDG-DEV-FEST/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Time Seires, 시계열 분석 세번째</title>
      <link>http://tkdguq05.github.io/2019/09/20/Time-Series-03/</link>
      <guid>http://tkdguq05.github.io/2019/09/20/Time-Series-03/</guid>
      <pubDate>Fri, 20 Sep 2019 02:08:36 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Dive-into-시계열-데이터-분석&quot;&gt;&lt;a href=&quot;#Dive-into-시계열-데이터-분석&quot; class=&quot;headerlink&quot; title=&quot;Dive into 시계열 데이터 분석&quot;&gt;&lt;/a&gt;Dive into 시계열 데이터 분석&lt;/h1&gt;&lt;
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Dive-into-시계열-데이터-분석"><a href="#Dive-into-시계열-데이터-분석" class="headerlink" title="Dive into 시계열 데이터 분석"></a>Dive into 시계열 데이터 분석</h1><h2 id="시계열-데이터-분석에-대해서-공부해보자-03"><a href="#시계열-데이터-분석에-대해서-공부해보자-03" class="headerlink" title="시계열 데이터 분석에 대해서 공부해보자 03"></a>시계열 데이터 분석에 대해서 공부해보자 03</h2><p>시계열 데이터 분석과 기계학습의 차이점에 대해서 본격적으로 들어가보도록 하겠습니다. 시계열 알고리즘에는 기계학습과는 다른, 2가지 차별화 방향이 있습니다.</p><p>첫번째는 ‘과거데이터로 미래 데이터 뽑아낼 수 있는가’ 로 시간 축 기반의 예측이 가능하다는 것이고, 두번째는 시계열 알고리즘은 점추정이 아닌 구간추정 알고리즘으로 설명력 효과에 뿌리를 두었다는 것입니다. 대부분의 기계학습 모델은 통계분포에 기반하지 않끼 때문에 점추정 알고리즘이고, 시계열 알고리즘은 구간추정을 하기 때문에 점추정 보다 더 다양한 해석이 가능합니다.</p><h4 id="특별한-모델들"><a href="#특별한-모델들" class="headerlink" title="(특별한 모델들)"></a>(특별한 모델들)</h4><ul><li>Dynamic Modeling : y가 여러개인 모델입니다. y에 대한 영향을 비교하고 싶다면 y를 두 개로 둬서 모델을 두개 만들고 실험하는 것을 생각해 볼 수 있습니다.</li><li>XAI, LIME : 최근에 등장한 개념으로, 설명가능한 Aritificial Intelligence, 설명가능한 딥러닝에 대한 것입니다. Random Forest의 feature importance와 비슷하게 측정이 가능하다고 합니다.</li></ul><h3 id="시계열-데이터-분석-준비"><a href="#시계열-데이터-분석-준비" class="headerlink" title="시계열 데이터 분석 준비"></a>시계열 데이터 분석 준비</h3><p>데이터 분석 준비는 기존 머신러닝 데이터를 준비하는 것과 비슷하지만, 시계열 데이터만의 특징이 있기 때문에, 머신러닝 데이터 준비와 다른 몇 가지 특징들이 존재합니다.<br><img src="/images/cv_step.png" alt="1step and 2step"></p><ul><li>가장 옛날 것을 훈련데이터로 사용하고, 그 다음 것을 Validation 데이터, 가장 최근 것을 test데이터로 사용합니다.</li><li>기간을 두고 훈련셋을 만듭니다. 시간축을 잘 보존해야합니다.</li><li>훈련세트에서 하나 건너서 Validation set을 만들면 ⇒ 1스텝 교차검사</li><li>훈련세트에서 두 개 건너서 Validation set을 만들면 ⇒ 2스텝 교차검사</li><li>모델이 월 마다의 예측력이 다를 수 있기 때문에, 월별 모델을 만들기도 한다. (실제로 이렇게 모델을 만드는 경우가 많음)</li></ul><h3 id="검증지표와-잔차진단"><a href="#검증지표와-잔차진단" class="headerlink" title="검증지표와 잔차진단"></a>검증지표와 잔차진단</h3><p>분석하고 예측만 잘하면 될까요? 큰 착각일 수 있습니다. 중요한 것은 예측이 잘 되었는지 평가하는 것 그리고 데이터의 시간패턴이 잘 추출되었는지 확인하는 작업입니다.</p><p>검증지표는 예측값과 실제값이 얼마나 유사한지 측정하는 것이고, 잔차진단은 데이터의 시간패턴을 잘 뽑아내었는지 알아보는 작업입니다. </p><p><strong>검증지표</strong> 에는 흔히 사용되고 눈에도 익숙한 MSE가 대표적입니다. 그 외에 MAE, MAPE, MAPE, MPE(y가 %로 나올 때) 등 다양한 검증지표가 사용되며, 왠만하면 다 사용해보고 수치가 안정될 때까지 모델을 만드는 것이 좋습니다. 또한 기존의 검증지표가 맘에 들지 않는다면, 분석가나 데이터 사이언티스트가 직접 고안해서 검증지표를 사용해도 됩니다.</p><p>훌륭한 데이터 사이언티스트라면 검증지표를 직접 만들어서 사용해야하는 경우가 많을 것입니다. 왜냐하면 검증지표만 가지고 사용하면 결과에 대한 해석을 다르게 할 수 있기 때문입니다. 예를들어 MSE의 경우는 오차에 대한 가중치를 확 올려버리는 검증지표입니다. 오차에 대해서 제곱을 하기 때문에 가중치가 급격하게 증가하게 됩니다. 분석가가 보기에 이 가중치가 너무 과하다고 생각되면 절대값을 사용할 수 있습니다. 이렇게 되면 MAE를 사용하는 것이 되겠습니다.<br>$$MSE = {1\over n}\sum(y-\hat{y})^2$$<br>$$MAE = {1\over n}\sum|y - \hat{y}|$$</p><p><strong>잔차진단</strong> 는 말 그대로 잔차, $$y-f(x)$$ 에 대한 값을 보고 진단하는 것을 말합니다. 회귀분석을 해보신 분들을 아시겠지만, 잔차는 정의가 존재합니다.</p><h3 id="잔차의-정의"><a href="#잔차의-정의" class="headerlink" title="잔차의 정의"></a>잔차의 정의</h3><ol><li>잔차들은 정규분포이고, 평균 0과 일정한 분산을 가져야 한다.</li><li>잔차들이 시간의 흐름에 따라 상관성이 없어야 한다.<ul><li>자기상관 함수를 통해 Autocorrelation이 0인지 확인</li><li>공분산</li><li>자기상관함수</li><li>편자기상관함수</li></ul></li></ol><p>자기상관 정도를 확인하기 위해서는 일반적으로 랜덤으로 epsilon을 두 개 뽑아서 자기상관성이 있는지 확인합니다. 자기상관성 뿐 아니라, 잔차가 잘 뽑혔는지 확인하기 위해서는 시각화를 통해서 확인하고, 자기상관성이나 평균, 분산과 같이 통계량을 계산해서 확인하는, 두 가지 방법을 모두 사용해야 합니다.</p><p>잔차를 보고 더 뽑아내야 할 것이 있는지, 분석이 잘되고 있는지 안되고 있는지를 확인해 나가야 합니다. </p><p><img src="/images/autocor.png" alt="White Noise"><br>예를 하나 들어서 보겠습니다. 여기에 다양한 모델들이 있네요. Autocorrelation에 대해서 가정을 설정했고, 가정에 대한 결과표가 나왔습니다. 대중 주장은 모델의 잔차가 White Noise라는 것이고, 내 주장은 모델의 잔차가 White Noise가 아니라는 것입니다. 모델을 쭉 보니, SARIMA 모델은 p-value값이 굉장히 높고 나머지는 0에 가깝습니다. 이것을 어떻게 해석하면 될까요? p-value가 크다는 것은 대중 주장이 맞다는 것입니다. 대중 주장이 맞으니까 SARIMA의 잔차는 White Noise이고 모델이 잘 만들어졌다고 추측해 볼 수 있습니다. 나머지 모델들은 영 꽝이네요. 이런 식으로 모델에 대한 잔차를 검증해 나가면 됩니다.</p><h2 id="시간영역-선택하기"><a href="#시간영역-선택하기" class="headerlink" title="시간영역 선택하기"></a>시간영역 선택하기</h2><p>시계열 분석이 머신러닝 분석 방법과 다른 것은 <code>시간 축</code>입니다. 이 시간 축을 어떻게 두느냐에 따라 분석 결과가 급격하게 달라집니다. 따라서 시계열이 분석효과에 도움이 될 시간영역(해상도)를 선택해야 합니다. 일종의 window size를 정한다고 생각하면 이해가 잘 되실 겁니다. 시간축을 년 단위로 할지, 월로 할지, 일주일로 할지는 사실 다 해보는 수 밖에 없습니다. 알 수가 없기 때문입니다. 그래서 다 해보고 잘되는 시간 영역을 선택해야 합니다. 물론 선택하는 기준은 있습니다. 바로 통계량과 잔차를 기준으로 잘 나오는 시간축을 선택하는 것입니다. 분석은 항상 이 방법으로 진행이 됩니다. <strong>통계량과 잔차!</strong></p><h2 id="회귀분석-요약-시계열-분석-요약"><a href="#회귀분석-요약-시계열-분석-요약" class="headerlink" title="회귀분석 요약 / 시계열 분석 요약"></a>회귀분석 요약 / 시계열 분석 요약</h2><p>계수 추정 방법은 두 가지 방법이 있습니다. 수학자(수식)방법과 통계학자(확률)의 방법입니다. 수학자의 방식은 결정론적 모형입니다. 잔차벡터를 구하고, 잔차 제곱합을 구한 후, 그레디언트를 계산합니다. 그 이후에 미분을 하여 최적점을 구하고 추정된 계수를 얻는 방법입니다. 이 때, $X^T X$ 행렬은 역행렬이 존재해야 합니다. $X$ 가 full rank가 아니면 계산이 되지 않겠습니다. 결국 $X^TX$ 행렬은 Positive Definite이 아니면 계산 되지 않습니다.</p><p>확률론적 모형은 다음과 같습니다. Main Equation에서 $X$ 가 있을 때의 $Y$ 의 기대값과 분산을 구합니다. 이를 통해 분포를 추정할 수 있게됩니다. 구한 평균과 분산을 가지고, $Y$ 값 각각의 확률을 구합니다. 그 이후에는 $Y$ 의 발생가능성에 대해서 Likelihood를 구합니다. Maximum Likelihood Estimation을 하려는 것입니다.<br><img src="/images/likelihood.png" alt="Maximum Likelihood Estimation"><br>Log를 취해 계산을 편리하도록 만들어주고 미분으로 0값이 되는 지점을 구합니다. 통계학자의 방식은 이렇게 분포에 대한 계산을 해놓는 다는 점입니다. 이런 식으로 계산이 되면 구간추정도 가능해지게 됩니다. $beta$ (coefficient)값에 대한 분산은 $Covariance$ 를 통해서 구합니다.</p><p>역행렬이 없을 수록 에러값이 증가하게 되고 이것은 구간이 넓어지는 것을 의미하게 됩니다. 결국 넓어진 구간을 좁히는 것이 목표가 되겠습니다. beta값의 분포에 대해서는  $t$ 분포 따르는 게 증명이 되었기 때문에 $t$를 사용하면 됩니다. $beta$ 가 $t$ 에서 나온다는 성질은 가설검정을 할 때 이용됩니다. 추가로 딥러닝에 대해서 덧붙이자면, Neural Network는 신뢰구간의 범위가 너무 넓습니다. 이론적 근거가 없기 때문입니다. 검증을 할 때는 P-value를 보고 값이 높은 것은 coefficient가 몇이든 다 0으로 보면 됩니다. $R^2$ 값이랑은 별개의 문제입니다.</p><hr><p>시계열 데이터 분석은 분석하고 검증하고 모델링하는 것도 중요하지만, 데이터에 따라 높은 정확도나 높은 에러를 가지게 됩니다. 시계열 분석은 단기적인 상황에서는 성능이 좋지만 중 장기 예측에 대해서는 잘 맞지 않는 다는 단점이 존재합니다. 물론 변화가 별로 없고 일반적인 패턴을 지닌다면 잘 맞추겠지만 변화가 굉장히 극심하다면 잘 맞추기 못 하게 됩니다. 애초에 데이터를 정렬할때도 시간축을 잘 살려서 정제를 해야하니 데이터 정렬 자체, 데이터 준비하기도 굉장히 어려운 작업이라고 할 수 있겠습니다.</p>]]></content:encoded>
      
      <comments>http://tkdguq05.github.io/2019/09/20/Time-Series-03/#disqus_thread</comments>
    </item>
    
    <item>
      <title>시계열 분석 시리즈 두 번째</title>
      <link>http://tkdguq05.github.io/2019/09/08/Time-Series02/</link>
      <guid>http://tkdguq05.github.io/2019/09/08/Time-Series02/</guid>
      <pubDate>Sun, 08 Sep 2019 10:57:22 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Dive-into-시계열-데이터-분석&quot;&gt;&lt;a href=&quot;#Dive-into-시계열-데이터-분석&quot; class=&quot;headerlink&quot; title=&quot;Dive into 시계열 데이터 분석&quot;&gt;&lt;/a&gt;Dive into 시계열 데이터 분석&lt;/h1&gt;&lt;
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Dive-into-시계열-데이터-분석"><a href="#Dive-into-시계열-데이터-분석" class="headerlink" title="Dive into 시계열 데이터 분석"></a>Dive into 시계열 데이터 분석</h1><h2 id="시계열-데이터-분석에-대해서-공부해보자-02"><a href="#시계열-데이터-분석에-대해서-공부해보자-02" class="headerlink" title="시계열 데이터 분석에 대해서 공부해보자 02"></a>시계열 데이터 분석에 대해서 공부해보자 02</h2><p>시계열 데이터도 그렇고 데이터 분석 자체도 그렇습니다만, 내가 어떤 문제를 풀어야 하는지 알게 되면, 문제에 대한 기획/접근/해결 방향은 단순해집니다. </p><ul><li><p>문제가 무엇일까?</p></li><li><p>내가 사용가능한 알고리즘은?</p></li><li><p>알고리즘의 입력과 형식은?</p></li><li><p>알고리즘의 출력은?</p></li></ul><p>보통 이런 4단계를 거치게 되겠습니다. 항상 알고리즘을 사용하기 전에 위의 4가지 물음에 대해서 고민해 보는 게 좋을 것 같습니다. 학습하는 방향에 따라서 알고리즘은 달라집니다. 대표적인 알고리즘 유형은 다음과 같습니다.</p><h3 id="Supervised-Learning"><a href="#Supervised-Learning" class="headerlink" title="Supervised Learning"></a>Supervised Learning</h3><ul><li>Regression</li><li>Instance Based</li><li>Regularization</li><li>Tree</li><li>Bayesian</li><li>ANN</li></ul><h3 id="Unsupervised-Learning"><a href="#Unsupervised-Learning" class="headerlink" title="Unsupervised Learning"></a>Unsupervised Learning</h3><ul><li>Clustering</li><li>Association Rule</li><li>Dimensionality Reduction</li><li>Ensemble</li><li>Deep Learning</li></ul><p>머신러닝에 대해서는 어느정도 알고 있습니다. 그렇다면 머신러닝과 시계열 분석의 차이는 무엇일까요? 큰 차이점은 바로 <code>시간축</code>을 고려하는가? 아닌가?에 관한 것입니다. 시계열 분석은 시간축에 대해서 고려를 해야하고, 학습데이터와 테스트 데이터를 나눌때도 시간축을 신경 써서 나누어야 합니다.</p><h2 id="시계열-데이터의-독자적인-성분들-7종"><a href="#시계열-데이터의-독자적인-성분들-7종" class="headerlink" title="시계열 데이터의 독자적인 성분들 7종"></a>시계열 데이터의 독자적인 성분들 7종</h2><p>시계열 데이터를 다루다 보면 시계열 데이터만의 독특한 성분들이 발견됩니다. 대표적인 7종을 알아보겠습니다. </p><ol><li><p>빈도<br>빈도는 말 그대로 frequency를 나타내는 말입니다. 하지만 조금 다른게 있다면, 계절성 패턴이 나타나기 전까지의 데이터 갯수로 사람이 정해야 한다는 점입니다. 일 단위, 월 단위, 연 단위로 나누어서 빈도를 측정합니다. 나누는 기준은 따로 없지만, 비즈니스 사이클이 복잡할수록 작은 시간축, 단순하다면 크게 월로 해도 어느정도 맞아들어갑니다. 혹시 작업을 하다가 시간축이 안맞아 Null이 발생할 수 있는데, 파이썬의 여러 메서드를 사용한다면 금방 채울 수 있습니다. <code>bfill</code>(Backward fill)이나 <code>ffill</code>(Forward fill)등을 이용하면 됩니다.</p></li><li><p>추세<br>추세는 트렌드를 말합니다. 시계열이 시간에 따라 증가, 감소 또는 일정 수준을 유지하는 경우를 말하며, 아마존의 주식 챠트를 보면 우상향하는 그래프를 볼 수 있는데, 그런 경향을 바로 트렌드라고 합니다. 확률과정(Yt)이 추정이 가능한 결정론적 추세함수 f(t)와 정상확률과정(Yt)의 합으로 나타내어집니다.<br>$$Y_t = f(t) + Y_t(Seasonal)$$<br>추세를 제거하게 되면 추세를 제외한 함수로 예측하는 것이 일반적이고 상한, 하한을 만들어 놓습니다. X에 대해서는 일/월/년 인지 모르기 때문에 frequency 세팅을 꼭 해주어야 합니다.</p></li></ol><ol start="3"><li><p>계절성<br>계절성은 일정한 빈도로 주기적으로 반복되는 패턴(m), 특정한 달/요일에 따라 기대값이 달라지는 것을 말합니다. 주기적 패턴이 12개월마다 반복된다면 m=12로 설정합니다. $Sin$함수나 $Cos$함수를 그려보면 이해가 빠를 것 같습니다.<br><img src="/images/seasoanlity.png" alt="계절성이란?"></p></li><li><p>주기<br>주기는 계절성과 많이 헷갈릴 수 있습니다. 주기는 일정하지 않은 빈도로 발생하는 패턴을 말합니다. 계절성과는 일정한 빈도라는 부분에서 차이가 납니다. 빈도가 1일 때도 발생가능하며, 쉽게말해 Variance가 비슷하면 계절성이고, 다르면 주기(Cycle)이라고 볼 수 있습니다.<br><img src="/images/cycle.png" alt="Cycle이란?"></p></li><li><p>더미변수<br>더미변수는 이진수의 형태로 변수를 생성하는 것으로 휴일, 이벤트, 캠페인, Outlier 등을 생성할 수 있습니다. 범주형 변수의 기준값을 미리 결정해야 하며, 기준 값을 제외한 채 더미변수를 생성합니다.(N개의 변수라면 하나는 빼주어야 합니다.) 각 더미변수의 값을 0 또는 1로 채우며 1은 각 더미변수의 정의와 같음을 의미합니다. 물론 더미변수는 N-1개를 만들어야 하지만, 더미변수는 해석에 자신이 있을때의 경우이고 자신이 없다면 N개 만들어도 됩니다.</p></li><li><p>지연값(Lag)<br>Lag는 변수의 지연된 값을 독립변수로 반영합니다. 과거의 X를 현재에 반영하고 싶을 때 사용하고 python의 shift를 이용해서 간단하게 Lag를 만들 수 있습니다. shift(1) 바로 이전의 것, shift(2) 두 단계 전의 값. ARIMA, VAR, NNAR 등이 활용합니다.<br><img src="/images/shift.png" alt="Lag란?"></p></li><li><p>시간변수<br>시간 변수를 미시/거시적으로 분리하거나 통합하여 생성된 변수를 말합니다.</p></li></ol><p>시계열 구성요소는 각 변수의 시간패턴을 알아내는 데 중요합니다. Feature Engineering을 통해 생성된 변수의 input형태로 모델 선택을 하는 데 필요합니다. 생성된 변수의 패턴이 이전 모델에서 발견되지 않은 패턴이라면 모델의 성능을 높일 수 있습니다. 또한, 예측 성능 뿐 아니라, 결과를 해석하고 해당 속성을 분석하며 가능한 원인 식별에 도움이 됩니다.</p><p>기본적으로 시계열 데이터 분석은 Numpy와 Pandas를 가지고 분석을 하게 됩니다. statsmodels라는 패키지의(sm)<br><code>sm.tsa.seasonal_decompose</code>를 통해 분석을 하게 됩니다. 여기서 parameter를 살펴보면, <code>additive</code>와 <code>multiplicative</code>모델을 고르는 부분이 있습니다. 뭘 선택해야 할지 고민을 할 수 있습니다. 일반적으로 additive모델을 주로 사용합니다. multiplicative모델은 언제 사용하느냐 하면, y가 %, 즉 비율로 표현되어 있을 때 사용하면 됩니다.<br><code>sm.tsa.seasonal_decompose</code>를 통해서 개략적으로 파악하고, 잔차까지 확인합니다.</p><p><img src="/images/analysis.png" alt="sm.tsa.seanoal_decompose를 사용하자"></p><p>Residual을 확인하면서 추출해 나가야합니다. Residual을 봤는데, Y = T + S + Residual이므로<br>Residual은 Y-T-S가 됩니다. </p><p>이런식으로 잔차를 확인하고, 잔차에 트렌드가 있으면 트렌드를 잘못 추출한 것이고 잔차에 계절성이 있으면 계절성을 잘못 추출한 것이라고 판단하면서 분석의 방향을 잡아나아가면 됩니다. </p>]]></content:encoded>
      
      <comments>http://tkdguq05.github.io/2019/09/08/Time-Series02/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Time Series Analysis Begins</title>
      <link>http://tkdguq05.github.io/2019/08/25/Time-Series-Begins/</link>
      <guid>http://tkdguq05.github.io/2019/08/25/Time-Series-Begins/</guid>
      <pubDate>Sun, 25 Aug 2019 03:30:03 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Dive-into-시계열-데이터-분석&quot;&gt;&lt;a href=&quot;#Dive-into-시계열-데이터-분석&quot; class=&quot;headerlink&quot; title=&quot;Dive into 시계열 데이터 분석&quot;&gt;&lt;/a&gt;Dive into 시계열 데이터 분석&lt;/h1&gt;&lt;
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Dive-into-시계열-데이터-분석"><a href="#Dive-into-시계열-데이터-분석" class="headerlink" title="Dive into 시계열 데이터 분석"></a>Dive into 시계열 데이터 분석</h1><h2 id="시계열-데이터-분석에-대해서-공부해보자"><a href="#시계열-데이터-분석에-대해서-공부해보자" class="headerlink" title="시계열 데이터 분석에 대해서 공부해보자!"></a>시계열 데이터 분석에 대해서 공부해보자!</h2><p>저번 주부터 고대하던 시계열 분석에 대해서 본격적으로 공부해보게 되었습니다. 공부한 내용에 대해서 차근차근 정리를 해보는 시간을 갖겠습니다.</p><h3 id="분석적-사고의-필요성"><a href="#분석적-사고의-필요성" class="headerlink" title="분석적 사고의 필요성"></a>분석적 사고의 필요성</h3><p>시계열 분석에 앞서 강조하는 부분이 있었습니다.  데이터 분석에는 6가지 사이클이 있습니다.</p><ol start="0"><li>문제정의</li><li>데이터 수집</li><li>데이터 전처리</li><li>데이터 정리</li><li>데이터 분석</li><li>결과 정리</li></ol><p>그 중 가장 중요한 것은, 데이터 분석이 아니라 분석적 사고의 필요성입니다. 특히 데이터 사이언티스트에게 중요한 덕목으로서 강사님께서 강조해 주셨는데요, 결국은 문제 정의를 잘하는 것이 중요하다는 것이었습니다. 문제가 잘 정의되면 데이터를 어디서 갖고 올지 어떤 알고리즘을 사용할지 등이 정리가 될 수 있습니다. 사실 <code>캐글 = 데이터사이언스</code>로 보는 사람들이 많은데, 엄밀히 따지면 캐글은 알고리즘을 공부할 수 있는 대회일 수 있습니다. 이미 사전에 문제정의가 끝나고 데이터를 잘 모으고 정리되어서 캐글쪽에 전달되기 때문에 정말 필요한 능력인 문제정의 능력을 키우기는 힘들 수 있습니다.(개인적으로 가장 신선한 충격을 받았던 설명이었습니다)</p><p>문제 정의 후에는 이것을 고객들이나 관리자에게 잘 전달해주어야 합니다. 그래서 중요한 것은 설득 및 설명 능력입니다. 사실, 데이터분석 관련지식(이론), 프로그래밍 활용능력(실습) 등은 금방 늘어날 수 있는 능력이지만, 잘 설득하고 이해하기 쉽도록 설명하는 능력은 정말 키우기 어렵습니다. 어쩌면 데이터 사이언티스트에게 커뮤니케이션 능력은 잘 키울 수 없기에 더 중요하지 않을까 생각되기도 합니다.</p><h3 id="정확한-문제-정의의-중요성"><a href="#정확한-문제-정의의-중요성" class="headerlink" title="정확한 문제 정의의 중요성"></a>정확한 문제 정의의 중요성</h3><p>앞서 말씀 드린 것처럼, 정확하게 문제를 정의하고 분석을 시작해야 합니다. 이를 위해서는 가설을 설정하고 검정하는 것이 필요하게 됩니다. 가설 설정의 세가지 조건은 다음과 같습니다.</p><h4 id="가설-설정-세가지-조건"><a href="#가설-설정-세가지-조건" class="headerlink" title="가설 설정 세가지 조건"></a>가설 설정 세가지 조건</h4><ol><li>상호배반적</li><li>증명가능성</li><li>구체성 </li></ol><p>상호배반성은 나의 주장과 대립 주장이 모호함이 없어야 한다는 것으로, 서로 겹치는 영역이 없어야 된다는 것을 말합니다. 증명가능성은 성급화 일반화에 빠지지 않기 위해서는 증명 가능한 것이나, 범위로 내세워야 한다는 것을 말합니다. 마지막으로 구체성은 충분히 구별되고 실현가능한 표현으로 정의되어야 한다는 것입니다. </p><h3 id="검정"><a href="#검정" class="headerlink" title="검정"></a>검정</h3><p>가설을 세웠으면, 이제 그 가설이 맞는지 검정을 해야 합니다. 주의해야할 점은 모집단에 대한 것입니다. 모집단은 논란이 있을 수 있지만, 관찰이 불가능한 것입니다. 이상적인 샘플 집단이기 때문입니다. 그렇기 때문에 우리는 항상 샘플을 갖고 분석을 할 수 밖에 없습니다. 샘플에 Bias가 있다면, Bias를 제거하고 사용합니다. </p><p>귀무가설과 대립가설은 통계에서 정말 자주 등장하는 개념입니다. 하지만 익숙하지 않은 단어들이기 때문에 항상 헷갈리는에요, 귀무가설은 기존의 주장(대립 주장), 대립가설은 내 주장 이라고 생각하면 사고하기 편리합니다. </p><p>귀무가설과 대립가설을 세웠다면, 이제 통계량을 보고 어떤 가설이 맞는지 확인해야 합니다. 이때 우리가 확인하는 통계량을 검정 통계량이라고 합니다. 대립가설과 귀무가설을 비교하기 위한 검증지표값으로 흔히 ‘점추정’이라고 부릅니다. </p><p>검정통계량이 발생가능한 구간에 대해서도 용어가 정리되어 있는데, 이것을 신뢰 구간이라고 부릅니다. 또 귀무가설이 참일 때 검정통계량으로 대립가설이 발생활 확률을 말하는 p-value가 있습니다. 일반적으로 p-value 기준으로 0.05보다 크면 대립가설을 기각하고, 0.05보다 작으면 대립가설을 채택합니다. </p><h3 id="통계량"><a href="#통계량" class="headerlink" title="통계량"></a>통계량</h3><p>분석 단계별 의사결정을 위해서는 수학/통계적 언어를 이해하는 것이 필요합니다. 변동/산포 특성, 지표의 변동성을 나타내는 통계량에는 분산과 표준편차가 있습니다. 분산은 편차제곱의 합을 데이터의 수로 나눈 값이고, 표준편차는 분산에 루트를 씌운 값입니다. (참고로 편차는 관측값과 평균의 차이입니다)</p><p>분포의 형태 특성을 나타내는 것으로는 대표적으로 Skewness와 Kurtosis가 있습니다. 왜도와 첨도라고 부를 수 있습니다. 왜도는 평균을 중심으로 데이터가 좌우로 편향되어 있는 정도를 말하고, 첨도는 뾰족한 정도로, 사실 더 중요한 것은 tail의 fat함을 보는 데 사용될 수 있습니다. fat-tail하다면 정규성 가정이 깨지게 되므로(정규성 가정 중 하나 : 분포의 tail은 슬림하다, kurtosis값은 0에 가까울 수록 좋다) 만든 모델이 제대로 작동하지 않을 가능성이 높습니다.</p><p><img src="/images/skewkurt.png" alt="skewness kurtosis"></p><h3 id="시계열-데이터와-횡단면-데이터"><a href="#시계열-데이터와-횡단면-데이터" class="headerlink" title="시계열 데이터와 횡단면 데이터"></a>시계열 데이터와 횡단면 데이터</h3><p>이제 데이터에 대한 얘기를 시작하겠습니다. 횡단면 자료(Cross-Sectional data)는 일정시점에서 하나 이상의 변수에 대해 수집된 자료를 말합니다. (예: 2016년 전국 16개 시도의 GRDP와 최종소비)</p><p>시계열 데이터는 일별, 주별, 월별, 분기별, 연도별 등 시간에 걸쳐 수집한 자료로 거시경제변수를 측정한 자료에서 많이 발생하는 데이터 입니다. 시계열 데이터는 보통의 데이터에 비해서 레코드(또는 로우)에 타임스탬프 또는 각 시간구간에 따른 집계 레벨(분별, 시간대별, 일별, 주별, 월별, 분기별, 년도별)에 대한 순서가 있는 시간값을 함께 가지고 있습니다. 시계열 데이터는 횡단면 데이터에 비해 고려해야 할 <code>시간축</code>이 하나 더 있는 것이 문제이며 시간축이 선후관계를 가지는 것, 그리고 시간축에 대한 것을 드릴다운하거나 다시 롤업(roll-up)해서 집계 응집도를 높여야 할 수 있습니다.<br><a href="http://intothedata.com/02.scholar_category/timeseries_analysis/" target="_blank" rel="noopener">http://intothedata.com/02.scholar_category/timeseries_analysis/</a></p><hr><p>시계열 데이터 분석을 위한 준비는 이것으로 어느정도 마무리 된 것 같습니다. 이외에도 Anaconda 설정이나, Numpy, Pandas를 다루는 부분이 있지만 블로그 글에서는 생략하겠습니다. </p><p>다음 포스팅 부터는 본격적인 시계열 데이터의 계절성이나 주기의 차이점, Residual을 주의깊게 관찰해야 하는 이유 등에 대해서 다뤄보겠습니다.</p>]]></content:encoded>
      
      <comments>http://tkdguq05.github.io/2019/08/25/Time-Series-Begins/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Multi Armed Bandit 알고리즘?</title>
      <link>http://tkdguq05.github.io/2019/07/18/Bandit/</link>
      <guid>http://tkdguq05.github.io/2019/07/18/Bandit/</guid>
      <pubDate>Thu, 18 Jul 2019 01:13:21 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;이 글의 주 소스 링크를 먼저 밝힙니다. 원작자에게 먼저 허락을 구하고 글을 작성했습니다.&lt;br&gt;&lt;a href=&quot;https://www.kaggle.com/ruslankl/how-to-deal-with-multi-armed-bandit-proble
        
      
      </description>
      
      <content:encoded><![CDATA[<p>이 글의 주 소스 링크를 먼저 밝힙니다. 원작자에게 먼저 허락을 구하고 글을 작성했습니다.<br><a href="https://www.kaggle.com/ruslankl/how-to-deal-with-multi-armed-bandit-problem" target="_blank" rel="noopener">https://www.kaggle.com/ruslankl/how-to-deal-with-multi-armed-bandit-problem</a></p><h1 id="Multi-Armed-Bandit-MAB-란"><a href="#Multi-Armed-Bandit-MAB-란" class="headerlink" title="Multi Armed Bandit(MAB) 란?"></a>Multi Armed Bandit(MAB) 란?</h1><p>마케팅이든 아니면 의학적인 실험에서든 사용자에게 어떤 게 가장 좋은 것 인지 확인하는 방법은 무엇일까요?<br>바로 Multi Armed Bandit Algorithm입니다. 특히 Thompson Sampling이라는 기법과 같이 사용된다면 굉장히 효과적으로 가장 좋은 선택이 무엇인지 알아낼 수 있습니다.(실제로 추천 알고리즘의 Cold Start 문제 등에 효과적으로 적용되고 있는 알고리즘 중 하나입니다.)</p><p>마케팅 캠페인을 한다고 합시다. 마케팅 캠페인에서는 보통 CTR(Click Through Rate)을 이용해서 광고가 효과적인지 판단하곤 합니다.(물론 마케팅 회사마다 케이스 바이 케이스이긴 합니다만, 일단 CTR이라고 가정하고 넘어가 봅시다)</p><ul><li>CTR 예시, 어떤 광고가 100번 노출되고 유저가 10번 클릭을 한다면, 이 광고의 CTR은 10/100으로 0.1입니다.</li></ul><p>이야기가 나온김에 Regret도 같이 설명하자면, Regret은 가능한 CTR중 최고의 CTR과 지금 있는 CTR을 빼준 값입니다. 광고 A의 CTR이 0.1이고 B가 0.3이라고 할 때, A를 보여줬을 때 Regret은 $0.3 - 0.1 = 0.2$가 됩니다.</p><p>이제 광고에 대한 여러 안들이 있고, 어떤 광고가 가장 효과적인지 확인하려고 합니다. 하지만 광고에 대해서 어떤 사전 정보도 없다면 어떨까요?, 어떻게 여러 대안중에 효과적인 광고를 골라낼 수 있을까요? 이럴 때는 보통 사용하는 방법이 A/B test입니다. A/B 테스트는 말 그대로 A안과 B안을 노출시켜서(노출 비율은 정할 수 있다) 두 집단의 각각 다른 효과를 확인하기 위해서 사용되는 방법입니다. (wiki 설명 : A/B 테스트는 변수 A에 비해 대상이 변수 B에 대해 보이는 응답을 테스트하고, 두 변수 중 어떤 것이 더 효과적인지를 판단함으로써 단일 변수에 대한 두 가지 버전을 비교하는 방법이다, <a href="https://ko.wikipedia.org/wiki/A/B_%ED%85%8C%EC%8A%A4%ED%8A%B8" target="_blank" rel="noopener">https://ko.wikipedia.org/wiki/A/B_%ED%85%8C%EC%8A%A4%ED%8A%B8</a>) </p><p>‘아 그럼 A/B 테스트 하고 좋은 거 그냥 뽑으면 되겠네!’라고 생각할 수 있겠지만, 회사에서 이 테스팅을 진행한다고 생각해 봅시다. 주의할 점이 있습니다. A안을 기존에 하던 광고라고 하고 B를 실험하는 광고라고 해봅시다. A안 광고를 통해서는 꾸준히 매출을 기록하고 있고, B안은 아직 확실하지 않습니다. B가 아마 효과적이라고 하는데 아직 의심스럽습니다. 만약 테스팅을 하는데 B의 효과가 너무 떨어진다면 어떨까요?</p><ul><li>기존 광고 효과의 목표치에 도달하지 못한다.</li><li>매출이 떨어진다.</li><li>고객이 실망하고 이탈한다.</li></ul><p>이런 상황이 가능하지 않을까요? 그래서 MAB에서 중요한 것은, <code>Exploration</code>과 <code>Exploitaion</code>입니다. 한국어로 쉽게 말하면, 탐색하기와 뽑아먹기 입니다. 쉽게 탐색과 이용이라고 하겠습니다.</p><h4 id="Exploration은-탐색하는-것입니다-새로운-안에-대해서-계속-테스트하고-실험해-보는-것입니다"><a href="#Exploration은-탐색하는-것입니다-새로운-안에-대해서-계속-테스트하고-실험해-보는-것입니다" class="headerlink" title="Exploration은 탐색하는 것입니다. 새로운 안에 대해서 계속 테스트하고 실험해 보는 것입니다."></a>Exploration은 탐색하는 것입니다. 새로운 안에 대해서 계속 테스트하고 실험해 보는 것입니다.</h4><h4 id="Exploitation은-이용하는-것입니다-즉-기존에-효과적이었던-광고를-계속-하는-것입니다"><a href="#Exploitation은-이용하는-것입니다-즉-기존에-효과적이었던-광고를-계속-하는-것입니다" class="headerlink" title="Exploitation은 이용하는 것입니다. 즉, 기존에 효과적이었던 광고를 계속 하는 것입니다."></a>Exploitation은 이용하는 것입니다. 즉, 기존에 효과적이었던 광고를 계속 하는 것입니다.</h4><p>결국 A/B테스트이든, MAB이든 중요한 것은, 이 비율을 적절하게 맞춰서 탐색을 간결하게 하고 최대한 효과적으로 이용할 수 있는 대안을 선정하는 것입니다.</p><p>MAB, 즉 Multi Armed Bandit 알고리즘은 여러 대안들(슬롯머신의 Arm에서 이름을 따왔습니다)을 자동으로 실험하고 최적의 광고를 탐색과 이용사이에서 균형을 잡으면서 빠르게 찾는데 좋은 알고리즘입니다. Multi Armed Bandit 알고리즘들은 몇 가지 종류가 있습니다만 거의 모든 알고리즘은 위에서 소개한 Regret을 줄이는 것을 목표로 하고 있습니다.</p><p>주요 알고리즘들은 다음과 같습니다.</p><ul><li>Random Selection</li><li>Epsilon Greedy</li><li>Thompson Sampling</li><li>Upper Confidence Bound (UCB1)</li></ul><p>이 알고리즘들을 가지고 실험을 하기 전에 CTR을 사전에 설정해 둘 필요가 있습니다. 설정해둔 CTR로 광고가 주어졌을 때 클릭에 대한 시뮬레이션을 진행할 수 있습니다.</p><p>먼저 CTR을 비현실적이지만 0.45와 0.65로 설정하겠습니다.</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ACTUAL_CTR = [<span class="hljs-number">.45</span>, <span class="hljs-number">.65</span>]</span><br></pre></td></tr></table></figure><h2 id="1-Random-Selection"><a href="#1-Random-Selection" class="headerlink" title="1. Random Selection"></a>1. Random Selection</h2><p>Random Selection은 말그대로 탐색을 하지 않고 동전 튕기기를 이용해서 앞면이면 광고0, 뒷면이면 광고1을 보여주는 알고리즘입니다. 정말 간단합니다!</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">n=<span class="hljs-number">1000</span></span><br><span class="line"></span><br><span class="line">regret = <span class="hljs-number">0</span></span><br><span class="line">total_reward = <span class="hljs-number">0</span></span><br><span class="line">regret_list = []</span><br><span class="line">ctr = &#123;<span class="hljs-number">0</span>: [], <span class="hljs-number">1</span>:[]&#125; <span class="hljs-comment">#lists for collecting the calculated CTR</span></span><br><span class="line">index_list = [] <span class="hljs-comment"># lists for collecting the number of randomly choosen Ad</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-comment">#initial values for impressons and clicks</span></span><br><span class="line">impressions = [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]</span><br><span class="line">clicks = [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(n):</span><br><span class="line">    random_index = np.random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>] <span class="hljs-comment"># randomly choose the value between [0,1]</span></span><br><span class="line">    index_list.append(random_index)</span><br><span class="line">    impressions[random_index] += <span class="hljs-number">1</span></span><br><span class="line">    did_click = bernoulli.rvs(actual_ctr[random_index])</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-keyword">if</span> did_click:</span><br><span class="line">        clicks[random_index] += did_click</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-keyword">if</span> impressions[<span class="hljs-number">0</span>] == <span class="hljs-number">0</span> :</span><br><span class="line">        ctr_0 = <span class="hljs-number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="hljs-keyword">else</span> :</span><br><span class="line">         ctr_0 = clicks[<span class="hljs-number">0</span>]/impressions[<span class="hljs-number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-keyword">if</span> impressions[<span class="hljs-number">1</span>] == <span class="hljs-number">0</span>:</span><br><span class="line">        ctr_1 = <span class="hljs-number">0</span></span><br><span class="line">    <span class="hljs-keyword">else</span> :</span><br><span class="line">        ctr_1 = clicks[<span class="hljs-number">1</span>]/impressions[<span class="hljs-number">1</span>]</span><br><span class="line">    </span><br><span class="line">    ctr[<span class="hljs-number">0</span>].append(ctr_0)</span><br><span class="line">    ctr[<span class="hljs-number">1</span>].append(ctr_1)</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment">## calculate the regret and reward</span></span><br><span class="line">    regret += max(actual_ctr) - actual_ctr[random_index]</span><br><span class="line">    regret_list.append(regret)</span><br><span class="line">    total_reward += did_click</span><br></pre></td></tr></table></figure><p><img src="/images/newplot.png" height="100%" width="100%"></p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Ad #0 has been shown 48.4 % of the time.</span><br><span class="line">Ad #1 has been shown 51.6 % of the time.</span><br><span class="line">Total Reward (Number of Clicks): 546</span><br></pre></td></tr></table></figure><p>CTR이야 0.65, 0.45를 잘 찾아간다지만, 중요한 것은 Regret입니다. Regret함수를 보면 함수값이 거의 100대에 육박하는 것을 볼 수 있습니다. 좀 더 좋은 알고리즘을 통해서 Regret을 낮출 필요가 있겠습니다. 마케팅 예산이 무한대라면 그냥 마구잡이로 보여주고 CTR을 측정해서, 높은 CTR을 보이는 광고안을 선정하면 그만입니다. 하지만 일개 사원인 우리들은 예산을 최대한 아껴서 좋은 효율적인 광고를 통해 매출을 극대화 해야하는 사람들입니다. 그렇다면 좀 더 좋은 알고리즘을 살펴보겠습니다.</p><h2 id="2-Epsilon-Greedy"><a href="#2-Epsilon-Greedy" class="headerlink" title="2. Epsilon Greedy"></a>2. Epsilon Greedy</h2><p>Epsilon Greedy 알고리즘은 Random Selection에서 한 단계 업그레이드 된 모델입니다.<br>이 알고리즘은 탐색과 이용의 비율을 어느정도 조정한다는 것이 큰 특징입니다.</p><ul><li>~15%까지는 Exploration</li><li>~85%까지 Exploitation</li></ul><p>로직은 다음과 같습니다.</p><ol><li>초기 몇번 까지는 Exploration(초기 값이 중요!)</li><li>각 Exploration마다 최고 점수를 받는 variant 고르기</li><li>Epsilon 설정</li><li>(1-E)%의 winning variant를 고르고 다른 옵션에는 E%를 설정한다.</li></ol><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">e = <span class="hljs-number">0.05</span></span><br><span class="line">n_init = <span class="hljs-number">100</span></span><br><span class="line">impressions = [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]</span><br><span class="line">clicks = [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(n_init):</span><br><span class="line">    random_index = np.random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>]</span><br><span class="line">    </span><br><span class="line">    impressions[random_index] += <span class="hljs-number">1</span></span><br><span class="line">    did_click = bernoulli.rvs(actual_ctr[random_index])</span><br><span class="line">    <span class="hljs-keyword">if</span> did_click:</span><br><span class="line">        clicks[random_index] += did_click</span><br><span class="line">    </span><br><span class="line">ctr_0 = clicks[<span class="hljs-number">0</span>] / impressions[<span class="hljs-number">0</span>]</span><br><span class="line">ctr_1 = clicks[<span class="hljs-number">1</span>] / impressions[<span class="hljs-number">1</span>]</span><br><span class="line">win_index = np.argmax([ctr_0, ctr_1])</span><br><span class="line"></span><br><span class="line">print(<span class="hljs-string">'After'</span>, n_init, <span class="hljs-string">'initial trials Ad #'</span>, \</span><br><span class="line">      win_index, <span class="hljs-string">'got the highest CTR'</span>, round(np.max([ctr_0, ctr_1]),<span class="hljs-number">2</span>),</span><br><span class="line">     <span class="hljs-string">'(Real CTR value is'</span>, actual_ctr[win_index], <span class="hljs-string">')'</span></span><br></pre></td></tr></table></figure><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">regret = <span class="hljs-number">0</span></span><br><span class="line">total_reward = <span class="hljs-number">0</span></span><br><span class="line">regret_list = []</span><br><span class="line">ctr = &#123;<span class="hljs-number">0</span> : [], <span class="hljs-number">1</span>: []&#125;</span><br><span class="line">index_list = []</span><br><span class="line">impressions = [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]</span><br><span class="line">clicks = [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(n):</span><br><span class="line">    epsilon_index = random.choices([win_index, <span class="hljs-number">1</span>-win_index],</span><br><span class="line">                                  [<span class="hljs-number">1</span>-e, e])[<span class="hljs-number">0</span>]</span><br><span class="line">    index_list.append(epsilon_index)</span><br><span class="line">    </span><br><span class="line">    impressions[epsilon_index] +=<span class="hljs-number">1</span></span><br><span class="line">    did_click = bernoulli.rvs(actual_ctr[epsilon_index])</span><br><span class="line">    <span class="hljs-keyword">if</span> did_click :</span><br><span class="line">        clicks[epsilon_index] += did_click</span><br><span class="line">        </span><br><span class="line">    <span class="hljs-keyword">if</span> impressions[<span class="hljs-number">0</span>] == <span class="hljs-number">0</span> :</span><br><span class="line">        ctr_0 = <span class="hljs-number">0</span></span><br><span class="line">    <span class="hljs-keyword">else</span> :</span><br><span class="line">        ctr_0 = clicks[<span class="hljs-number">0</span>]/impressions[<span class="hljs-number">0</span>]</span><br><span class="line">        </span><br><span class="line">    <span class="hljs-keyword">if</span> impressions[<span class="hljs-number">1</span>] ==<span class="hljs-number">0</span> :</span><br><span class="line">        ctr_1 = <span class="hljs-number">0</span></span><br><span class="line">    <span class="hljs-keyword">else</span> :</span><br><span class="line">        ctr_1 = clicks[<span class="hljs-number">1</span>]/impressions[<span class="hljs-number">1</span>]</span><br><span class="line">        </span><br><span class="line">    ctr[<span class="hljs-number">0</span>].append(ctr_0)</span><br><span class="line">    ctr[<span class="hljs-number">1</span>].append(ctr_1)</span><br><span class="line">    </span><br><span class="line">    regret += max(actual_ctr) - actual_ctr[epsilon_index]</span><br><span class="line">    regret_list.append(regret)</span><br><span class="line">    total_reward += did_click</span><br></pre></td></tr></table></figure><p><img src="/images/newplot (1).png" height="100%" width="100%"></p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Ad #0 has been shown 6.2 % of the time.</span><br><span class="line">Ad #1 has been shown 93.8 % of the time.</span><br><span class="line">Total Reward (Number of Clicks): 642</span><br></pre></td></tr></table></figure><p>Random Selection model보다는 훨씬 괜찮은 결과가 나왔습니다. 간단한데 결과는 훨씬 좋아지네요. 하지만 탐색시의 winning variant는 최적의 variant가 아닐 수 있습니다. 사실 suboptimal variant로 탐색 한 것입니다. 이것은 regret을 올리고 보상을 감소시킬 수 밖에 없습니다. 큰 수의 법칙에 따르면, 초기 시도를 많이 할수록, winning variant를 찾을 가능성이 커집니다. 하지만 마케팅에서는 큰 수의 법칙에 결코 따를 수가 없을 겁니다. <del>우리는 일개 사원…</del></p><p>이 알고리즘의 좋은 점은 어떤 비율을 설정할 수 있다는 것입니다. 각기 다른 epsilon값을 선택함으로써 얼마나 자주 winning ad를 보여줄 수 있는지 조정할 수 있는 것입니다.</p><p>좀 더 좋은 알고리즘을 살펴볼까요?</p><h2 id="3-Thompson-Samling"><a href="#3-Thompson-Samling" class="headerlink" title="3. Thompson Samling"></a>3. Thompson Samling</h2><ul><li>50% Exploration</li><li><p>50% Exploitation<br>Thompson Sampling의 탐색 부분은 Epsilon-greedy알고리즘보다 복잡합니다. 이 알고리즘은 단순히 epsilon을 정하는 것이 아니라, Beta distribution을 이용하기 때문입니다. 왜냐하면 광고를 클릭하는 것은 베르누의 과정에 속하기 때문입니다.(클릭했다, 안했다는 1,0으로 표현 가능합니다) 하지만 톰슨 샘플링은 일반적으로 어떤 분포, 어떤 파라미터에서든지 샘플링이 가능하다. 이게 가장 큰 장점 중 하나라고 생각합니다.</p></li><li><p>참고로 Beta 분포는 alpha와 beta 파라미터로 분포의 모양을 조절한다.(prior 조정 가능)</p></li></ul><p>로직은 다음과 같습니다.</p><ol><li>alpha와 beta를 고른다.</li><li>$\alpha=prior+hits$, $\beta=prior+misses$로 계산한다. 우리의 경우는 hits는 클릭 수를 말하고, misses는 클릭없이 impression된 경우를 말합니다(클릭 없는 노출). prior는 CTR에 대한 prior정보가 있으면 유용합니다. 우리는 갖고 있지 않으므로 1.0을 사용할 것 입니다..</li><li>CTR을 추정합니다. 실제 CTR을 베타 분포에서 샘플링하고 $B(\alpha_i,\beta_i)$에서, 추정 CTR이 가장 높은 것을 선택한다.</li><li>2-3을 반복한다.</li></ol><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">regret = <span class="hljs-number">0</span></span><br><span class="line">total_reward = <span class="hljs-number">0</span></span><br><span class="line">regret_list = []</span><br><span class="line">ctr = &#123;<span class="hljs-number">0</span> : [], <span class="hljs-number">1</span>: []&#125;</span><br><span class="line">index_list = []</span><br><span class="line">impressions = [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]</span><br><span class="line">clicks = [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]</span><br><span class="line">priors = (<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)</span><br><span class="line"><span class="hljs-comment">#randomly choose the first shown ad</span></span><br><span class="line">win_index = np.random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>] </span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(n):</span><br><span class="line">    impressions[win_index] += <span class="hljs-number">1</span></span><br><span class="line">    did_click = bernoulli.rvs(actual_ctr[win_index])</span><br><span class="line">    <span class="hljs-keyword">if</span> did_click :</span><br><span class="line">        clicks[win_index] += did_click</span><br><span class="line">    </span><br><span class="line">    ctr_0 = random.betavariate(priors[<span class="hljs-number">0</span>] + clicks[<span class="hljs-number">0</span>], priors[<span class="hljs-number">1</span>] + impressions[<span class="hljs-number">0</span>] - clicks[<span class="hljs-number">0</span>])</span><br><span class="line">    ctr_1 = random.betavariate(priors[<span class="hljs-number">1</span>] + clicks[<span class="hljs-number">1</span>], priors[<span class="hljs-number">1</span>] + impressions[<span class="hljs-number">1</span>] - clicks[<span class="hljs-number">1</span>])</span><br><span class="line">    </span><br><span class="line">    win_index = np.argmax([ctr_0, ctr_1])</span><br><span class="line">    index_list.append(win_index)</span><br><span class="line">    </span><br><span class="line">    ctr[<span class="hljs-number">0</span>].append(ctr_0)</span><br><span class="line">    ctr[<span class="hljs-number">1</span>].append(ctr_1)</span><br><span class="line">    </span><br><span class="line">    regret += max(actual_ctr) - actual_ctr[win_index]</span><br><span class="line">    regret_list.append(regret)</span><br><span class="line">    total_reward += did_click</span><br></pre></td></tr></table></figure><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">x = np.arange (<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0.01</span>)</span><br><span class="line">y = beta.pdf(x, priors[<span class="hljs-number">0</span>]+clicks[<span class="hljs-number">0</span>], priors[<span class="hljs-number">1</span>] + impressions[<span class="hljs-number">0</span>] - clicks[<span class="hljs-number">0</span>])</span><br><span class="line">y /= y.max() <span class="hljs-comment">## normalize</span></span><br><span class="line"></span><br><span class="line">data1 = go.Scatter(x=x,</span><br><span class="line">                   y=y,</span><br><span class="line">                   name=<span class="hljs-string">'(Ad #0)'</span>,</span><br><span class="line">                   marker = dict(color=(<span class="hljs-string">'rgba(10, 108, 94, 1)'</span>)),</span><br><span class="line">                   fill=<span class="hljs-string">'tozeroy'</span>,</span><br><span class="line">                   fillcolor = <span class="hljs-string">'rgba(10, 108, 94, .7)'</span>)</span><br><span class="line"></span><br><span class="line">data2 = go.Scatter(x = [actual_ctr[<span class="hljs-number">0</span>]] * <span class="hljs-number">2</span>,</span><br><span class="line">                   y = [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>],</span><br><span class="line">                   name = <span class="hljs-string">'Actual CTR #0 Value'</span>,</span><br><span class="line">                   mode=<span class="hljs-string">'lines'</span>,</span><br><span class="line">                   line = dict(</span><br><span class="line">                       color = (<span class="hljs-string">'rgb(205, 12, 24)'</span>),</span><br><span class="line">                       width = <span class="hljs-number">2</span>,</span><br><span class="line">                       dash = <span class="hljs-string">'dash'</span>))</span><br><span class="line"></span><br><span class="line">y = beta.pdf(x, priors[<span class="hljs-number">0</span>]+clicks[<span class="hljs-number">1</span>], priors[<span class="hljs-number">1</span>] + impressions[<span class="hljs-number">1</span>] - clicks[<span class="hljs-number">1</span>])</span><br><span class="line">y /= y.max()</span><br><span class="line"></span><br><span class="line">data3 = go.Scatter(x=x,</span><br><span class="line">                   y=y,</span><br><span class="line">                   name=<span class="hljs-string">'(Ad #1)'</span>,</span><br><span class="line">                   marker = dict(color=(<span class="hljs-string">'rgba(187, 121, 24, 1)'</span>)),</span><br><span class="line">                   fill=<span class="hljs-string">'tozeroy'</span>,</span><br><span class="line">                   fillcolor = <span class="hljs-string">'rgba(187, 121, 24, .7)'</span>)</span><br><span class="line"></span><br><span class="line">data4 = go.Scatter(x = [actual_ctr[<span class="hljs-number">1</span>]] * <span class="hljs-number">2</span>,</span><br><span class="line">                   y = [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>],</span><br><span class="line">                   name = <span class="hljs-string">'Actual CTR #1 Value'</span>,</span><br><span class="line">                   mode=<span class="hljs-string">'lines'</span>,</span><br><span class="line">                   line = dict(</span><br><span class="line">                       color = (<span class="hljs-string">'rgb(205, 12, 24)'</span>),</span><br><span class="line">                       width = <span class="hljs-number">2</span>,</span><br><span class="line">                       dash = <span class="hljs-string">'dash'</span>))</span><br><span class="line"></span><br><span class="line">layout = go.Layout(title=<span class="hljs-string">'Beta Distributions for both Ads'</span>,</span><br><span class="line">                   xaxis=&#123;<span class="hljs-string">'title'</span>: <span class="hljs-string">'Possible CTR values'</span>&#125;,</span><br><span class="line">                   yaxis=&#123;<span class="hljs-string">'title'</span>: <span class="hljs-string">'Probability Density'</span>&#125;)</span><br><span class="line"></span><br><span class="line">fig = go.Figure(data=[data1, data2, data3, data4], layout=layout)</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># fig = tools.make_subplots(rows=1, cols=2, print_grid=False, shared_xaxes=False,</span></span><br><span class="line"><span class="hljs-comment">#                           subplot_titles=('Beta Distribution (Ad #0)','Beta Distribution (Ad #1)'))</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># fig.append_trace(data1, 1, 1)</span></span><br><span class="line"><span class="hljs-comment"># fig.append_trace(data2, 1, 1)</span></span><br><span class="line"><span class="hljs-comment"># fig.append_trace(data3, 1, 2)</span></span><br><span class="line"><span class="hljs-comment"># fig.append_trace(data4, 1, 2)</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># fig['layout'].update(showlegend=False)</span></span><br><span class="line"></span><br><span class="line">iplot(fig, show_link=<span class="hljs-keyword">False</span>)</span><br></pre></td></tr></table></figure><p><img src="/images/newplot (3).png" height="100%" width="100%"></p><p><img src="/images/newplot (2).png" height="100%" width="100%"></p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Ad #0 has been shown 4.2 % of the time.</span><br><span class="line">Ad #1 has been shown 95.8 % of the time.</span><br><span class="line">Total Reward (Number of Clicks): 647</span><br></pre></td></tr></table></figure><p>지금까지 본 regret중 가장 낮은 regret을 확인할 수 있습니다. </p><p>이 알고리즘은 지속적으로 탐색합니다. 자연스럽게 Beta distribution을 이용해 가장 가치가 높은 샘플을 가져와서 이용할 수 있습니다. Beta distribution Ad#1은 더 높고 좁은 분포를 갖고 있습니다. 이것은 샘플된 값들이 항상 Ad#0보다 높을 것이라는 것을 의미합니다. 결국 Ad#1이 우리가 원하는 광고임을 빠르게 파악할 수 있습니다.</p><h2 id="UCB-Upper-Confidence-Bound"><a href="#UCB-Upper-Confidence-Bound" class="headerlink" title="UCB (Upper Confidence Bound)"></a>UCB (Upper Confidence Bound)</h2><ul><li>50% Exploration</li><li>50% Exploitation<br>Thompson Sampling과 달리 UCB는 불확실성에 더 초점을 맞춥니다. 한 variant에 대해 더 불확실 할 수록, 더 탐색을 해야만 하는 알고리즘입니다.</li></ul><p>알고리즘은 가장 높은 UCB가 나오는 variant를 선택합니다. UCB를 통해 가장 높은 보상이 나올 것이라고 생각되는 variant를 고르는 것입니다.</p><p>$$UCB = \bar x_i + \sqrt{\frac{2 \cdot \log{t}}{n}}$$<br>이 수식을 따르며 뒤에 term에 따라 UCB의 파생 알고리즘들이 등장하게 됩니다.</p><p>$\bar x_i$ CTR이 i번째 단계일 때,<br>$t$ - 모든 variant에 대해 impression을 다 더한 숫자이다.<br>$n$ - 선택된 variant에 대해 impression을 다 더한 숫자이다.</p><p>로직은 직관적입니다.</p><ol><li>UCB를 모든 변량들에 대해 구합니다.</li><li>가장 높은 UCB를 가진 변량을 선택합니다.</li><li>1번으로 다시 돌아갑니다.</li></ol><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">regret = <span class="hljs-number">0</span> </span><br><span class="line">total_reward = <span class="hljs-number">0</span></span><br><span class="line">regret_list = [] </span><br><span class="line">index_list = [] </span><br><span class="line">impressions = [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>] </span><br><span class="line">clicks = [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]</span><br><span class="line">ctr = &#123;<span class="hljs-number">0</span>: [], <span class="hljs-number">1</span>: []&#125;</span><br><span class="line">total_reward = <span class="hljs-number">0</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(n):</span><br><span class="line">    </span><br><span class="line">    index = <span class="hljs-number">0</span></span><br><span class="line">    max_upper_bound = <span class="hljs-number">0</span></span><br><span class="line">    <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>]:</span><br><span class="line">        <span class="hljs-keyword">if</span> (impressions[k] &gt; <span class="hljs-number">0</span>):</span><br><span class="line">            CTR = clicks[k] / impressions[k]</span><br><span class="line">            delta = math.sqrt(<span class="hljs-number">2</span> * math.log(i+<span class="hljs-number">1</span>) / impressions[k])</span><br><span class="line">            upper_bound = CTR + delta</span><br><span class="line">            ctr[k].append(CTR)</span><br><span class="line">        <span class="hljs-keyword">else</span>:</span><br><span class="line">            upper_bound = <span class="hljs-number">1e400</span></span><br><span class="line">        <span class="hljs-keyword">if</span> upper_bound &gt; max_upper_bound:</span><br><span class="line">            max_upper_bound = upper_bound</span><br><span class="line">            index = k</span><br><span class="line">    index_list.append(index)</span><br><span class="line">    impressions[index] += <span class="hljs-number">1</span></span><br><span class="line">    reward = bernoulli.rvs(actual_ctr[index])</span><br><span class="line">    </span><br><span class="line">    clicks[index] += reward</span><br><span class="line">    total_reward += reward</span><br><span class="line">    </span><br><span class="line">    regret += max(actual_ctr) - actual_ctr[index]</span><br><span class="line">    regret_list.append(regret)</span><br></pre></td></tr></table></figure><p><img src="/images/newplot (4).png" height="100%" width="100%"></p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Ad #0 has been shown 19.2 % of the time.</span><br><span class="line">Ad #1 has been shown 80.80000000000001 % of the time.</span><br><span class="line">Total Reward (Number of Clicks): 596</span><br></pre></td></tr></table></figure><p>결과는 다음과 같습니다. Regret이 생각보다 높네요, UCB알고리즘도 현업에서 자주 사용하는 알고리즘입니다만, 이 알고리즘은 가장 기본적인 알고리즘이기 때문에 그런 것 같습니다.</p><h2 id="결론-및-성능-비교"><a href="#결론-및-성능-비교" class="headerlink" title="결론 및 성능 비교"></a>결론 및 성능 비교</h2><p>이제 살펴봤던 모든 알고리즘의 성능을 비교해 볼 시간입니다. 기대가 되네요, 나온 결과를 시각화를 해서 살펴 보겠습니다.</p><p><img src="/images/newplot (5).png" height="100%" width="100%"><br>1000번의 시도에 어떤 광고를 얼마나 노출시켰는 지에 대한 막대그래프입니다.<br>Random Selection은 CTR이 낮은 광고를 너무 많이 노출 시켰네요, 그 다음은 UCB1, Epsilon Greedy, Thompson Sampling 순 입니다. Thompson Sampling이 가장 좋네요! 하지만 놀라운 것은 Epsilon Greedy입니다. 정말 간단한 알고리즘인데 성능이 좋군요.</p><p><img src="/images/newplot (6).png" height="100%" width="100%"><br>다음 자료는 Regret에 대한 것입니다. 시도가 늘어날 수록, Random Selection이나 UCB는 쭉 쭉 증가하는 것이 보입니다. 하지만 Thomspon Sampling은 굉장히 안정적으로 Regret이 유지되네요.</p><p><img src="/images/newplot (7).png" height="100%" width="100%"><br>마지막은 1000번의 시도에서 총 몇번의 클릭을 받았는가에 대한 시각화 자료입니다. 클릭이 많다면 더 효과적으로 실험을 하면서 광고를 했다고 할 수 있겠네요. 역시 Thompson Sampling이 가장 많은 클릭 수를 얻었습니다. 그 다음은 Epsilon Greedy, UCB1, Random Selection 순 입니다.</p><p>물론 Regret이 낮다고 가장 높은 보상이 있는 것은 아닙니다. 이 실험에서는 우연히 Thompson Sampling이 Regret도 낮고, 높은 보상을 얻었습니다. 알고리즘은 적절한 광고를(right ads) 보여줄 뿐 이고, 유저가 클릭하는 것은 보장하지 않습니다.</p><p>일반적으로 Thompson Sampling이 좋은 결과를 보여줍니다. 하지만 다른 알고리즘을 보면서 어떻게, 그리고 언제 그 알고리즘이 유용할지 생각해봐야 합니다. 어떤 문제를 풀 지는 각 개인 마다 다르기 때문에, 여러 알고리즘들 중에서 문제에 적합한 것을 선택할 수 있어야 합니다. 어떤 사전 정보를 갖고 있고, 알고리즘 적용 후에 어떤 정보를 알고싶은지를  명확하게 설정하는 것이 더 중요하다고 할 수 있겠습니다.</p>]]></content:encoded>
      
      <comments>http://tkdguq05.github.io/2019/07/18/Bandit/#disqus_thread</comments>
    </item>
    
    <item>
      <title>글또 3기에 들어서면서... 상반기 회고와 다짐</title>
      <link>http://tkdguq05.github.io/2019/07/07/geultto/</link>
      <guid>http://tkdguq05.github.io/2019/07/07/geultto/</guid>
      <pubDate>Sun, 07 Jul 2019 13:47:22 GMT</pubDate>
      <description>
      
        
        
          &lt;h2 id=&quot;상반기-회고와-나의-다짐&quot;&gt;&lt;a href=&quot;#상반기-회고와-나의-다짐&quot; class=&quot;headerlink&quot; title=&quot;상반기 회고와 나의 다짐&quot;&gt;&lt;/a&gt;상반기 회고와 나의 다짐&lt;/h2&gt;&lt;h3 id=&quot;상반기-회고-2019-01-01-201
        
      
      </description>
      
      <content:encoded><![CDATA[<h2 id="상반기-회고와-나의-다짐"><a href="#상반기-회고와-나의-다짐" class="headerlink" title="상반기 회고와 나의 다짐"></a>상반기 회고와 나의 다짐</h2><h3 id="상반기-회고-2019-01-01-2019-06-24-도서관"><a href="#상반기-회고-2019-01-01-2019-06-24-도서관" class="headerlink" title="상반기 회고 (2019.01.01 ~ 2019.06.24, 도서관)"></a>상반기 회고 (2019.01.01 ~ 2019.06.24, 도서관)</h3><p><img src="/images/espana.jpeg" height="80%" width="70%"><br>새해 첫 날은 스페인에서 보냈었네요, 공부만 하다가 처음으로 짬이 나서! 계획했었던 영국~스페인 여행을 2주일 정도 갔었습니다. 항상 아침에 조깅을 하면서 ‘한국 돌아가서 뭘해볼까…’ 이런 고민들을 했었고 그 중 제일 처음으로 해야겠다고 생각했던 것이 블로그였습니다.</p><p><code>일단 블로그부터 제대로 구축하자!</code> 라는 계획으로 hexo 블로그를 만들었고, 여러 테마들을 돌려보면서 괜찮은 것들을 살펴봤습니다. 한 한달정도 블로그랑 씨름하다보니 어느정도 구축이 되었고, 배운 내용들을 글로 정리하기 시작했습니다.</p><p>사실 올해에는 취업 생각이 없었습니다. 데이터 이론이나 알고리즘 등 준비해야 할 것도 많다고 생각했고, 개인 프로젝트도 더 필요하다고 느꼈습니다. 하지만 3월에 상반기 대기업 취업 공고가 나니까 마음이 급해지기 시작했죠. ‘내가 공부는 정말 많이 했지만 내가 진짜 제대로 알고 있는걸까?’, ‘이 상태로 취업은 가능할까?’, ‘공부를 이렇게 하는게 맞나?’ 이런 고민들이었습니다. </p><p>이런 고민들로 3월부터 6월 동안 취업준비를 급하게 시작했습니다. 결국 데이터 관련 일은 데이터를 직접 만져봐야 얻는 게 있다는 결론을 내렸기 때문입니다. 이력서도 많이 쓰고 면접도 많이 봤습니다. 첫 면접부터 마지막 면접까지 하나하나 기억이 다 나네요, 쓰라렸지만 좋은 경험을 많이 했다고 생각합니다. 사실 상반기 회고를 하면서 면접에 관해서 글이 길어졌는데, 너무 무거운 내용들이 많아서 일단 나중에 정리해서 업로드 할 생각입니다. 이번 글은 조금 가벼운 느낌으로!</p><p><img src="/images/library.jpeg" alt="살다시피 했던 경영도서관"><br>그래서 상반기 회고를 다시 하자면 저는 도서관에서 거의 살았었습니다. 아침 일찍 나가서 저녁 늦게 까지 책을 쌓아놓고 노트북 두들기면서 한 자리에만 있었습니다. 그때 공부를 하면서 느낀 건 공부를 오래하고 싶더라도 체력이 부족하면 불가능 하다는 것이었습니다. 운동도 시작했고, 식단 조절도 해보면서 건강을 챙겼습니다. 우연히 운동 좋아하는 후배들을 알게 되면서 좋은 습관들을 쌓게 된 것 같네요.</p><h3 id="글쓰는-습관"><a href="#글쓰는-습관" class="headerlink" title="글쓰는 습관"></a>글쓰는 습관</h3><p>취업 준비도 준비지만 또 다른 좋은 습관을 들이려고 노력한 것은 글쓰는 습관이었습니다. 배운 내용을 혼자 공부해서 갖고 있는 것보다, 글을 쓰고 공유하고, 얘기하는 것이 저에게 훨씬 더 큰 가치를 가져다 줄 수 있겠구나 하는 생각이 들었습니다. 부족하지만 이론을 정리한 걸 글로 작성하고, 알고리즘 문제 푼 것들도 어떤 생각의 흐름으로 풀었는지 기록했습니다. 이외로 면접 준비하면서 이걸 다시 보게 되니까 정리하는데 도움이 많이 되는 것 같았습니다. 특히 이론에 관해서 글을 쓸때는 완벽하게 알지 못하면 글을 쓰지 못하기 때문에, 어디가 부족한지 스스로 알 수 있게 되어서 더 좋은 것 같습니다.</p><p>그 외에 상반기에 했던 것들은 다 취업 준비가 대부분이었던 것 같네요.</p><p>회고를 해보니 너무 정신없이 살았던 것 같습니다. 정리 안되고 정신없는 거 별로 안 좋아하는데 상반기를 정리해보니 제 자신이 정리 안하고 살았었네요. 하반기에는 계획을 제대로 세워서 하나씩 클리어 하는 재미로 살아봐야겠습니다.</p><p>상반기 회고를 두 번 해보니 얻어지는 것이 있었습니다. 사실 취업준비를 하면서 많이 지쳤었거든요, 데이터 얘기만 들어도 싫고, 개발이나 알고리즘, 코드만 봐도 어지럽고 도망치고 싶었습니다. 하지만 취업도 했고, 상반기를 냉철하게, 처절하게 다시 들여다보고 나니, 다시 시작할 힘이 나는 느낌입니다. 바닥에 다시 내려왔고, 어디부터 공부를 해야할지 이제 감이 잡히는 느낌입니다.</p><h3 id="어떤-글을-쓸까-다짐"><a href="#어떤-글을-쓸까-다짐" class="headerlink" title="어떤 글을 쓸까? / 다짐"></a>어떤 글을 쓸까? / 다짐</h3><p>글또 3기를 하면서 가끔은 넋두리 같은, 오늘 같은 이야기를 하게 될 것 같고, 캐글 대회에 참여하고 잘 되거나, 안되었던 것들을 정리할 계획입니다. 또 일하면서 필요한 부분을 공부하면서, 예를들어 AWS(사실 GCP를 더 공부하고 싶었는데 ㅠㅠ 회사는 AWS를 쓰는군요…)나 Apache Spark, NoSQL(MongoDB) 등을 정리한 내용을 공유할 것 같습니다.</p><p>하반기에 계획했었던 일 중 하나가 글또 3기 들어가는 것이였는데요, 벌써 체크 하나하게 되어서 너무 기쁩니다. 최소 12개의 글을 쓰게 될텐데 그 과정이 의외로 도전적일 것 같아 재밌을 것 같네요. 도전적인 자세로 하반기를 살아봐야겠습니다. 내일은 월요일, 도전이 생각보다 꽤 빨리 시작되는 느낌입니다.</p>]]></content:encoded>
      
      <comments>http://tkdguq05.github.io/2019/07/07/geultto/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Classification Metrics</title>
      <link>http://tkdguq05.github.io/2019/05/29/Metrics/</link>
      <guid>http://tkdguq05.github.io/2019/05/29/Metrics/</guid>
      <pubDate>Wed, 29 May 2019 05:27:17 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Classification-Metrics&quot;&gt;&lt;a href=&quot;#Classification-Metrics&quot; class=&quot;headerlink&quot; title=&quot;Classification Metrics&quot;&gt;&lt;/a&gt;Classification Metri
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Classification-Metrics"><a href="#Classification-Metrics" class="headerlink" title="Classification Metrics"></a>Classification Metrics</h1><h1 id="분류-모델의-평가지표에-대해서-알아보자"><a href="#분류-모델의-평가지표에-대해서-알아보자" class="headerlink" title="분류 모델의 평가지표에 대해서 알아보자"></a>분류 모델의 평가지표에 대해서 알아보자</h1><p>Classification 모델을 만든 후에 모델의 성능이 어떤지 알기 위해서는 성능 평가 지표가 필요하다.<br>분류 모델의 성능지표를 알아보면서, 데이터의 상태에 따라서 어떤 지표를 사용해야하는지 공부해보자.</p><p>0과 1로 결정값이 한정되는 이진 분류 성능 평가 지표에 대해서 집중적으로 다뤄보자.</p><h3 id="분류-성능-평가-지표"><a href="#분류-성능-평가-지표" class="headerlink" title="분류 성능 평가 지표"></a>분류 성능 평가 지표</h3><ul><li>정확도(Accuracy)</li><li>오차행렬(Confusion Matrix)</li><li>정밀도(Precision)</li><li>재현율(Recall)</li><li>F1스코어</li><li>ROC AUC</li></ul><h3 id="정확도-Accuracy"><a href="#정확도-Accuracy" class="headerlink" title="정확도(Accuracy)"></a>정확도(Accuracy)</h3><p>정확도는 실제 데이터에서 예측 데이터가 얼마나 같은지를 판단하는 지표이다.<br>$$Accuracy = {TP+TN\over TP+TN+FP+FN}$$<br>정확도는 직관적으로 모델 예측 성능을 나타내는 평가 지표이며, 기본적으로 많이 사용하는 지표중 하나이다.<br>하지만 정확도는 치명적인 약점이 존재하는데, 바로 불균형한 데이터 셋에서는 제대로 평가가 안된다는 것이다. 예를 들어보자 1000개의 샘플에 10개만 문제가 있는 샘플이다. 이럴 경우에 엉터리 분류기, 즉 모든 샘플에 대해서 정상이라고 분류하는 분류기를 이용해서 분류하고 정확도로 성능 평가를 한다면, 결과는 990/1000, 99%의 정확도를 보이게 된다.<br>엉터리 분류기가 과연 좋은 분류기일지 생각해보자. 만약 이 분류기에 문제가 있는 샘플을 더 추가한다면, 정확도는 기하급수적으로 떨어지게 될 것이다.</p><h3 id="오차행렬-Confusion-Matrix"><a href="#오차행렬-Confusion-Matrix" class="headerlink" title="오차행렬(Confusion Matrix)"></a>오차행렬(Confusion Matrix)</h3><p>오차행렬은 학습된 분류 모델이 예측을 수행하면서 얼마나 헷갈리고 있는지도 함께 보여주는 지표이다. 즉, 이진 분류의 예측 오류가 얼마인지와 어떤 유형의 예측 오류가 발생하고 있는지를 같이 나타내 주는 지표이다.</p><p>오차행렬은 다음과 같이 표현한다.</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center"><strong>Negative(0)</strong></th><th style="text-align:center"><strong>Positive(1)</strong></th></tr></thead><tbody><tr><td style="text-align:center">Negative(0)</td><td style="text-align:center">TN(True Negative)</td><td style="text-align:center">FP(False Positive)</td></tr><tr><td style="text-align:center">Positive(1)</td><td style="text-align:center">FN(False Negative)</td><td style="text-align:center">TP(True Positive)</td></tr></tbody></table><p>위의 표에서 진하게 표시된 것이 예측 클래스에 대한 것이고(Predicted Calss) 옅게 표시된 것이 실제 클래스(Actual Class)이다.</p><ul><li>TP는 예측값을 Positive값 1으로 예측했고, 실제 값 역시 Positive값 1</li><li>TN는 예측값을 Negative 0으로 예측했고, 실제 값 역시 Negative값 0</li><li>FP는 예측값을 Positive값 1으로 예측했고, 실제 값은 Negative 값 0</li><li>FN는 예측값을 Negative값 0으로 예측했고, 실제 값 역시 Positive값 1</li></ul><p>오차행렬을 기반으로 해서 정확도의 식을 다시 보면 결국, True에 해당하는 값인 TP와 TN에 값이 좌우되고 있다는 것을 알 수 있다. 정확도 = 예측 결과와 실제 값이 동일한 건수 / 전체 데이터 수 라고 다시 말할 수 있다.</p><p>불균형한 이진 분류 데이터 셋에서는 Positive 건수가 매우 작기 때문에 이러한 데이터로 학습된 ML 알고리즘은 Positive보다는 Negative로 예측 정확도가 높아지는 경향이 발생한다. TN값이 높아진다는 것이다. 결과적으로 불균형 데이터 셋에서는 Positive에 대한 예측 정확도를 판단하지 못하고 Negative에 대한 예측 정확도만으로 분류의 정확도가 매우 높게 나타나는 수치적인 판단 오류를 일으키게 된다.</p><p>이런 판단 오류를 극복하기 위해서 정밀도(Precision)와 재현율(Recall)이 성능지표로 사용된다.</p><h3 id="정밀도와-재현율-Precision-and-Recall"><a href="#정밀도와-재현율-Precision-and-Recall" class="headerlink" title="정밀도와 재현율 (Precision and Recall)"></a>정밀도와 재현율 (Precision and Recall)</h3><p>정밀도와 재현율은 다음과 같은 공식으로 정의된다.<br>$$Precision = {TP \over FP+TP}$$<br>$$Recall = {TP \over FN+TP}$$<br>정밀도는 <code>예측</code>을 Positive로 한 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율을 뜻한다. 정밀도의공식에서 분모는 예측을 Positive로 한 모든 데이터 건수이다. Positive 예측 성능을 더욱 정밀하게 측정하기 위한 평가 지표로 양성 예측도라고 불린다.</p><p>재현율은 <code>실제 값</code>이 Positive인 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율을 뜻한다. 공식의 분모는 실제 값이 Positive인 모든 데이터 건수이다. 민감도 또는 TPR(True Positive Rate)라고도 불린다.</p><p>정밀도와 재현율은 중요하게 생각하는 부분이 서로 다르기 때문에, 주어진 업무 특성에 따라서 특정 평가 지표가 더 중요한 지표로 간주될 수 있다. 재현율이 중요한 경우를 생각해보자. 재현율이 중요 지표로 사용되는 경우는 실제 Positive 양성 데이터를 Negative로 잘못 판단하게 되면 크리티컬한 영향이 발생하는 경우이다. 예를 들어 암 판단 모델은 재현율이 중요한데, 실제 Positive인 경우, 즉, 암환자를 Negative, 정상으로 분류하는 경우 오류의 대가가 생명이 될 수 있을 정도로 치명적이다. 만약 정상환자를 암환자로 분류하는 경우에는, 재검진을 하는 정도의 비용이 소모된다.(Positive–&gt;Negative로 잘못분류) </p><p>정밀도가 중요한 경우를 생각해보자. 스팸메일 여부를 확인하는 예를 들어보면, 실제 Positive인 스팸 메일을 Negative 정상 메일이라고 분류하게 되면 사용자가 불편함을 느끼는 정도지만, 정상메일을 Spam으로 분류해 버리면 업무메일 등이 스팸으로 처리되어 메일을 받지 못하게 돼 업무에 차질이 생길 수 있다.(Negative–&gt;Positive로 잘못분류)</p><p>정리하자면,</p><ul><li>재현율이 더 중요한 경우, 실제 Positive 양성 데이터 예측을 Negative로 잘못 판단하게 되면 업무 상 큰 차질이 발생하는 경우</li><li>정밀도가 더 중요한 경우, 실제 Negative 음성 데이터 예측을 Positive로 잘못 판단하게 되면 업무 상 큰 차질이 발생하는 경우</li></ul><p>공식을 다시살펴보면, Precision은 FN이 분모에 사용되고, Recall은 FP가 분모에 사용된다. 재현율은 FN을 낮추는 데, 정밀도는 FP를 낮추는 데 초점이 맞춰진다. 가장 좋은 것은 둘다 높은 것인데, 두 성능 지표가 상호 보완적이기 때문에 Trade off가 존재한다.</p><h3 id="정밀도-재현율-트레이드-오프"><a href="#정밀도-재현율-트레이드-오프" class="headerlink" title="정밀도/재현율 트레이드 오프"></a>정밀도/재현율 트레이드 오프</h3><p>정밀도나 재현율은 분류의 결정 임계값을 조정해 정밀도나 재현율의 수치를 높일 수 있다. sklearn의 분류 모델들에서 threshold를 조절할 수 있는 파라미터를 찾아보면 된다. threshold값을 낮추면 보통 재현율 값이 올라가고 정밀도 값이 떨어진다. threshold값은 Positive 예측값을 결정하는 확률의 기준이 되고 낮출 수록 True값이 많아지기 때문이다. </p><p>Positive 예측값이 많아지면 상대적으로 Recall 값이 높아진다. 양성 예측을 많이 하다보니 실제 양성을 음성으로 예측하는 횟수가 상대적으로 줄어들기 때문이다(FN값이 떨어진다). </p><ul><li>임계값 증가하면 Negative 예측 값이 증가한다(FP값이 떨어짐) ==&gt; Precision 증가</li><li>임계값 감소하면 Positive 예측 값이 증가한다(FN값이 떨어짐) ==&gt; Recall 증가</li></ul><h3 id="정밀도와-재현율의-맹점"><a href="#정밀도와-재현율의-맹점" class="headerlink" title="정밀도와 재현율의 맹점"></a>정밀도와 재현율의 맹점</h3><p>Positive 예측의 임계값을 변경함에 따라 Precision과 Recall의 수치가 변경되는 것을 확인해 봤다. Threshold의 이런 변경은 업무 환경과 목적에 맞게 두 수치를 상호 보완할 수 있는 수준에서 적용되어야 한다. 단순히 성능지표로서 숫자를 올리는 수단으로 사용되면 안된다. </p><h4 id="정밀도-100-만들기"><a href="#정밀도-100-만들기" class="headerlink" title="정밀도 100% 만들기"></a>정밀도 100% 만들기</h4><p>확실한 기준이 되는 것만 Positive로 예측하고 나머지는 모두 Negative로 예측한다. 정밀도 = TP / (TP+FP) 이다. 예를 들어 암환자를 예측한다고 해보자. 전체환자 1000명 중에 확실한 Positive 징후만 가진 환자가 단 1명이라면(죽기 일보직전의) 한명만 Positive로 예측하고 나머지는 모두 Negative로 예측하더라도 FP는 0, TP는 1이기 때문에, 정밀도는 1/(1+0)으로 100%가 된다. Precision은 100%지만, 초기 암진단을 예측하는 경우는 희박하고, 위험한 정도의 암환자도 정상이라고 분류할 수 있기 때문에 좋은 분류기라고 할 수 없을 것이다.</p><h4 id="재현율-100-만들기"><a href="#재현율-100-만들기" class="headerlink" title="재현율 100% 만들기"></a>재현율 100% 만들기</h4><p>모든 환자를 Positive로 예측하면 된다. 재현율 = TP / (TP+FN)이므로 전체 환자 1000명을 다 Positive로 예측하는 것이다. 이 중 실제 양성인 사람이 30명 정도라도 TN이 수치에 포함되지 않고 FN은 아예 0이므로 30/(30+0)으로 100%가 된다. 이렇게 되면 재현율은 100%지만 모델을 정말 신뢰할 수 있는지에 대해 의심이 발생할 것이다. 이런 모델은 정상인 사람도 암 환자로 예측하게 되므로, 재검사 비율을 매우 높이게 된다. 병원에서 재검사 비용을 대줘야 한다면, 혹은 환자로 분류된 사람이 재검사 비용을 내야 한다면, 병원이 손해를 막심하게 보거나, 고객들이 병원에 대해 신뢰를 하지 않을 것이다.</p><p>따라서 정밀도와 재현율을 적절하게 고려한 평가 지표가 필요하게 된다.</p><h3 id="F1-Score"><a href="#F1-Score" class="headerlink" title="F1 Score"></a>F1 Score</h3><p>F1-Score는 정밀도와 재현율을 조화 평균한 지표이다. F1-Score는 정밀도와 재현율이 어느 한 쪽으로 치우치지 않는 수치를 나타낼 때 상대적으로 높은 값을 가진다. 공식은 다음과 같다.<br>$$F1={2\over{1\over{recall}}+{1\over{precision}}}=2\times{precision*\space recall\over precision+recall}$$ </p><p>만일 A 예측 모델의 경우 Precision이 0.9, Recall이 0.1로 극단적인 차이가 나고, B 예측 모델은 Precision과 Recall이 0.5로 큰 차이가 없다면 A의 F1-Score는 0.18이고, B의 F1-Score는 0.5로 B의 모델이 좋은 점수를 얻게 된다. 사실 F1 Score는 Precision과 Recall에 동일한 가중치인 0.5를 적용한 값이다. F-Measure는 $\beta$를 이용해 가중치를 조절한다. 공식을 살펴보자.</p><p>$F_\beta=$$(1+\beta^2)(Precision * Recall)\over{\beta^2 Precision + Recall}$</p><p>$\beta$가 1보다 크면 Recall이 강조되고 1보다 작으면 Precision이 강조된다. 1일때의 점수를 $F_1$점수라고 한다.</p><h3 id="ROC-amp-AUC"><a href="#ROC-amp-AUC" class="headerlink" title="ROC &amp; AUC"></a>ROC &amp; AUC</h3><p>ROC곡선(Receiver Operation Characteristic Curve)은 수신자 판단 곡선으로, 2차대전 때 통신 장비 성능 평가를 위해 고안된 수치이다. 요즘에는 이진 분류의 성능 평가 지표로 자주 사용된다. ROC Curve는 FPR(False Positive Rate)이 변할 때 TPR(True Positive Rate)이 어떻게 변하는지를 나타내는 곡선이다. FPR을 x축으로, TPR을 y축으로 잡으면 FPR에 대한 TPR의 변화가 곡선 형태로 나타난다.</p><p>TPR은 True Positive Rate의 약자이며, Recall을 나타낸다. 따라서 TPR은 TP/(TP+FN) 이다. 민감도라고도 불리며 민감도에 대응하는 지표로 TNR(True Negative Rate)이라고 불리는 특이성이 있다.</p><ul><li>민감도(TPR)는 실제값 Positive가 정확히 예측되어야 하는 수준을 나타낸다.(질병이 있는 사람은 질병이 있는 것으로 양성 판정)</li><li>특이성은(TNR) 실제값 Negative가 정확이 예측되어야 하는 수준을 나타낸다.(정상인 사람은 정상으로 음성 판정)</li></ul><p>TNR은 TN/(TN+FP)이며 X축의 기준인 FPR은 FP/(FP+TN)이므로 1-TNR로 표현할 수 있다.</p><p>ROC 곡선은 FPR을 0부터 1까지 변경하며 TPR의 변화 값을 구한다. Threshold값을 변경하면서, 처음에는 1로 지정해 FPR을 0으로 만든다. Threshold가 1일 때 Positive 예측 기준이 매우 높기 때문에 분류기가 Threshold보다 높은 확률을 가진 데이터를 Positive로 예측할 수 없다. 즉, 아예 Positive로 예측을 하지 않기 때문에 FP가 0이 되어 FPR이 0이된다. FPR = FP/(FP+TN)</p><p>반대로, FPR을 1로 만들려면 TN을 0으로 만들면 된다. Threshold를 0으로 지정하게 되면, 분류기가 모든 데이터에 대해서 Positive로 예측을 하게 된다. 이렇게 되면 Negative 예측은 없기 때문에 FPR이 1이 된다.</p><p>일반적으로 ROC Curve자체는 FPR과 TPR의 변화 값을 보는 데 이용하고, 분류의 성능 지표로 실제로 사용되는 것은 AUC(Area Under Curve)이다. 이 값은 ROC 곡선 밑의 면적을 구한 것으로, 일반적으로 1에 가까울수록 좋은 수치이다. AUC가 커지려면, FPR이 작은 상태에서 얼마나 큰 TPR을 구할 수 있는 지가 중요하다. 가운데 직선에서 멀어지고 좌상단 모서리로 곡선이 바짝 붙을 수록 직사각형에 가까운 곡선이 되어 면적이 1에 가까워진다. 가운데의 직선은 랜덤 수준의 이진 분류 AUC값으로 0.5이다. </p>]]></content:encoded>
      
      <comments>http://tkdguq05.github.io/2019/05/29/Metrics/#disqus_thread</comments>
    </item>
    
    <item>
      <title>PCA</title>
      <link>http://tkdguq05.github.io/2019/05/23/PCA/</link>
      <guid>http://tkdguq05.github.io/2019/05/23/PCA/</guid>
      <pubDate>Thu, 23 May 2019 06:28:50 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Dimensional-Reduction에-쓰이는-PCA에-대해-알아보자&quot;&gt;&lt;a href=&quot;#Dimensional-Reduction에-쓰이는-PCA에-대해-알아보자&quot; class=&quot;headerlink&quot; title=&quot;Dimensional Re
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Dimensional-Reduction에-쓰이는-PCA에-대해-알아보자"><a href="#Dimensional-Reduction에-쓰이는-PCA에-대해-알아보자" class="headerlink" title="Dimensional Reduction에 쓰이는 PCA에 대해 알아보자"></a>Dimensional Reduction에 쓰이는 PCA에 대해 알아보자</h1><h2 id="PCA-Principal-Component-Analysis"><a href="#PCA-Principal-Component-Analysis" class="headerlink" title="PCA(Principal Component Analysis)"></a>PCA(Principal Component Analysis)</h2><p>데이터 분석을 하다보면 답답한 경우가 자주 발생한다. 모델을 돌려야 하는데 feature가 너무 많아서 연산 코스트가 너무 많이 들고, 계산하는데 너무 오랜 시간이 걸리는 것이다. 결과를 봤더니, 복잡한 feature때문에 지저분하게 나오고, 노이즈도 많이 껴있는 것 같다. PCA는 이런 경우에 자주 사용되는 알고리즘이다. PCA는 그러니까 relative하지만 redundant한 feature를 제거하는데 자주 사용되거나 데이터를 단순화 할때 사용된다.</p><p>데이터를 단순화하는데는 다음의 두 가지 방법이 있다.</p><ul><li>차원 축소(Dimensional Reduction) : 데이터를 표현하는 속성의 수를 축소</li><li>요소 분석(Factor Analysis) : 관찰 가능한 데이터 = 잠재적인 변수(latent variable)와 noise의 선형결합</li></ul><p>우리는 차원 축소에 대한 내용을 살펴볼 것이다.</p><p>아까의 상황을 다시 가져와보자. 이전의 예에서 복잡한 feature들은 사실 highly correlated 되어 있기 때문에 문제가 있는 것이다. 변수들의 서로 연관되어 있으면 설명량은 올라가지만, 좋은 모델이라고 볼 수 없고, 어떤 변수가 타겟에 어떻게 영향을 주는지 알 수 없다. 불필요한(서로 연관되어 있거나, 결과와 상관없는) 변수들은, 변수들을 모으고 분석하는데 드는 비용을 증가시켜서, 예측 모델 또는 분류 모델을 만들 때 전체 비용을 증가시키는 원인이 된다.</p><p>따라서 불필요한 변수들을 제거할 필요가 있고, Machine Learning 영역에서는 본래 모델이 가지고 있던 성질이나 정확도를 최대한 유지하면서 차원을 줄이는 방법을 통하여 위에서 설명된 문제점을 해결하려고 한다.</p><p>모델의 차원(dimensionality)은 모델에 사용되는 독립(independence) 변수 또는 입력(input) 변수의 개수(number)를 의미한다. 우리가 GLM(Generalized Linear Model)을 사용하는 이유처럼 독립변수가 타겟에 미치는 영향을 제대로 알기 위해서 독립적인 변수가 필요한 것이다. 통계에서 항상 IID 조건을 사용하는 것과 의미가 비슷할 것이다.</p><p>정리하자면 PCA를 사용하는 이유는 다음과 같다.</p><ul><li>feature가 너무 많으면 연산에 사용되는 cost가 너무 높고, 시간도 너무 오래 걸리기 때문에, 변수들을 줄여줄 필요가 있다.</li><li>많은 feature들 중에서는 상관관계가 높은 feature들이 있다(high correlated). 이런 feature들은 모델의 설명량은 높일 수 있지만, 모델의 성능은 떨어트릴 수 있다. 또한 우리가 흥미 있어 하는 결과와 상관없는 변수들이 존재할 수 있는 상황이 발생할 수 있다.</li></ul><h3 id="Dimensional-Reduction"><a href="#Dimensional-Reduction" class="headerlink" title="Dimensional Reduction"></a>Dimensional Reduction</h3><p>Dimensional Reduction의 핵심 아이디어는, 상관도가 높은(interrelated, correlated) 변수들이 많이 존재하는 데이터 집합의 차원(Dimensionality)을 줄이면서, 동시에 데이터 집합에 존재하고 있는 차이(Variation, 정보)를 최대한 유지하는 것이다. 즉, 차원을 줄이되 “정보 손실을 최소화”하는 것이다. 여기서 정보란 데이터간의 거리, 실제적인 위치를 정보라고 표현한다. 다시말하면 위치, 상대적인 거리를 뜻한다. 하지만 차원축소는 정보의 손실을 어느 정도 감수해야 한다.</p><p>Dimensional Reduction은 원래 공간에서 데이터가 퍼져 있는 정도를 변환된(축소된) 공간에서 얼마나 잘 유지하느냐를 척도로 삼는다. 원래 공간의 정보가 변환된 공간에서 얼마나 잘 유지하는지는 변환된 공간에서의 데이터의 분산으로 측정한다. 따라서, 변환된 공간에서 데이터의 분산을 최대로 유지 할 수 있는 좌표축을 찾아야 한다.</p><p>즉, PCA는 원래 공간에서 데이터가 분산되어 있는 주요한 방향(Principal direction)을 찾는 것이 목표가 된다.<br>여러축으로 구성되어 있는 데이터를 주성분 분석으로 통해 기존의 feature들과는 다른 새로운 축으로써 다시 구성해보되, 분산을 최대로 유지한다.</p><h3 id="PCA-수행방법"><a href="#PCA-수행방법" class="headerlink" title="PCA 수행방법"></a>PCA 수행방법</h3><p>PCA에서 데이터가 분산되어 있는 주요한 방향(Principal Component)을 찾는 단계는 다음과 같다.</p><ol><li>데이터를 투영(Projection)하기</li><li>투영된 공간에서 분산 측정하기</li><li>분산의 최대치는 어떻게 찾는가?</li></ol><p>데이터를 여러 축에 투영해보면서 투영된 공간에서 분산을 측정하고, 가장 분산이 큰 축을 선택하는 것이 바로 PCA이다.<br>새로운 축이 $u$이라고 했을때, 축으로 이동된 새 데이터 포인트 $X_{new} = u^TX$이다. (𝕦t 𝕩= 𝕦 ⋅ 𝕩 cos𝜃= 𝕩 cos𝜃) </p><p>이제 투영된 공간에서 분산을 측정해보자. 먼저, PCA를 실행하기 전에 데이터의 평균(mean)과 분산(variance)를 정규화(standardization) 해 준다.(Pre-process the data) 데이터는 특성 벡터로 표현되는데, 특성 벡터의 각 원소들에서 각각의 평균과 빼 주고, 분산의 제곱근으로 나누어 준다.</p><p>정규화 과정에서</p><ul><li>데이터에서 평균을 빼는것:데이터의 평균이 0이 되도록 만든다.</li><li>데이터에서 분산의 제곱근을 나누어 주는 것 : 데이터의 값들이 unit variance를 갖게 해 준다.</li></ul><h4 id="새-축으로-이동된-데이터의-분산-구하기"><a href="#새-축으로-이동된-데이터의-분산-구하기" class="headerlink" title="새 축으로 이동된 데이터의 분산 구하기"></a>새 축으로 이동된 데이터의 분산 구하기</h4><p>각각의 attribute의 평균이 0이 되고, 분산이 1이 된다. 즉 같은 “scale”을 가지게 되어, attribute간의 비교가 가능 해진다.<br>데이터 포인트 $x_{1}, x_{2}, x_{3}, x_{4}, x_{5}$가 있을 때, u의 축으로 투영된 데이터 포인트$x_{1}^Tu, x_{2}^Tu, x_{3}^Tu, x_{4}^Tu, x_{5}^Tu$의 분산을 구해보자.</p><p>먼저 평균값을 구해놓자.</p><p>$$\mu={1\over{m}}\sum_{i=1}^{m}x_i^Tu = 0$$<br>투영된 공간에서의 기댓값은 0이다. 왜냐하면 데이터 포인트들은 이미 standardizing을 한 상태이기 때문이다. 평균의 평균을 구하니까 0이 되는 것이다. </p><p>분산을 구해보자.</p><p>$$\sigma^2={1\over{m}}\sum_{i=1}^{m}(x_i^Tu - \mu)^2 ={1\over{m}}\sum_{i=1}^{m}(x_i^Tu)^2$$<br>($\mu$가 0이므로)</p><p>$$={1\over{m}}\sum_{i=1}^{m}(u^Tx_ix_i^Tu) = u^T({1\over{m}}\sum_{i=1}^{m}(x_ix_i^T))u$$</p><p>($u$는 unit vector이다.)</p><p>이것은 결론적으로<br>$$=u^T({1\over{m}}\sum_{i=1}^{m}(x_i-\mathbb{o})(x_i-\mathbb{o})^T)u$$</p><p>$$=u^T\sum u$$<br>식이 도출된다.</p><p>Σ는 공분산 행렬로 기존 데이터의 공분산 행렬을 사용한다.<br>결국 투영하려고 하는 축과 기존 데이터의 공분산 행렬의 곱으로 간단하게 새 축의 분산을 구할 수 있다.</p><h4 id="분산의-최대치-구하기"><a href="#분산의-최대치-구하기" class="headerlink" title="분산의 최대치 구하기"></a>분산의 최대치 구하기</h4><p>우리는 Principal Component, 즉, 주성분을 구하는 것이 목적이므로, 데이터의 분산이 최대가 되도록 만드는 축을 구해야 한다. 분산의 최대치를 구하기 위해서 변환된(투영된) 공간에서 분산을 최대화 해 줄 수 있는 벡터 $u$를 찾아야 한다. $u$는 unit vector라고 생각하자. 우리가 구하고자 하는 $u$는 방향이 중요하기 때문이다. 즉, $u^Tu = 1$이다.</p><p>따라서 문제는 $u$가 unit vector일 때의 $u^T\sum u$의 최대값을 구하는 조건부 최적화 문제가 된다.</p><p>$$\max u^T\sum u$$</p><p>$$s.t \space u^Tu=1$$</p><p>이 문제는 라그랑지 승수 (Laglange Multiplier)를 이용해 해결 할 수 있다.<br>$$\mathcal{L}(u,\lambda)= u^T\sum u - \lambda(u^Tu-1)$$</p><p>$\mathcal{L}(u,\lambda)$를 미분해서 $u$의 최대치를 구한다.</p><p>이렇게 구한 식을 나타내면<br>$$u^T\sum u = u^T\lambda u=\lambda u^T u=\lambda$$</p><p>즉, 분산을 최대화 하는 문제는 Σ의 eigenvalue를 최대화 하는 문제가 된다.<br>$$argmax_{u}u^T\sum u = argmax_{u}\lambda$$</p><p>따라서, 변환된(축소된) 공간에서 분산의 최대값은 Σ의 eigenvalue의 최대값이다.</p><p>분산의 최대값은, 𝕦가 Σ의 eigenvalue 중 가장 큰 값을 가지는 eigenvalue에 대응되는 eigenvector일 때 달성된다. 우리는 이것을 주성분이라고도 부른다.</p><p>이 다음의 주성분을 구하는 것은 간단하다. D차원에서 주성분은 데이터 공분산 행렬의 가장 큰 eigenvalue에서 부터 D번째로 큰 eigenvalue까지에 대응되는 D개의 eigenvector가 될 것이다.</p>]]></content:encoded>
      
      <comments>http://tkdguq05.github.io/2019/05/23/PCA/#disqus_thread</comments>
    </item>
    
    <item>
      <title>SQL_Recipe_01</title>
      <link>http://tkdguq05.github.io/2019/05/21/SQL-Recipe-01/</link>
      <guid>http://tkdguq05.github.io/2019/05/21/SQL-Recipe-01/</guid>
      <pubDate>Tue, 21 May 2019 08:52:21 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;데이터-분석을-위한-SQL-레시피-with-MySQL&quot;&gt;&lt;a href=&quot;#데이터-분석을-위한-SQL-레시피-with-MySQL&quot; class=&quot;headerlink&quot; title=&quot;데이터 분석을 위한 SQL 레시피 with MySQL&quot;&gt;&lt;/a
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="데이터-분석을-위한-SQL-레시피-with-MySQL"><a href="#데이터-분석을-위한-SQL-레시피-with-MySQL" class="headerlink" title="데이터 분석을 위한 SQL 레시피 with MySQL"></a>데이터 분석을 위한 SQL 레시피 with MySQL</h1><p>데이터 분석을 위한 SQL 레시피의 3장에 있는 코드 내용들을 실습하고 MySQL코드로 변형시켜보았다.<br>데이터 분석을 위한 SQL 레시피 책에서는 PostgreSQL, Redshift, BigQuery, Hive, SparkSQL의 코드를 다룬다. 책에 있는 코드는 어떤 건 그대로 쳤을 때 돌아가고, 몇몇 개는 MySQL 쿼리대로 수정을 해주어야 한다.</p><p>3장의 mst_users_with_dates 테이블을 가지고 실습을 진행한다.<br>실습 진행 전에 테이블을 만들어준다.</p><figure class="highlight sql hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">DROP</span> <span class="hljs-keyword">TABLE</span> <span class="hljs-keyword">IF</span> <span class="hljs-keyword">EXISTS</span> mst_users_with_dates;</span><br><span class="line"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> mst_users_with_dates (</span><br><span class="line">    user_id        <span class="hljs-built_in">varchar</span>(<span class="hljs-number">255</span>)</span><br><span class="line">  , register_stamp <span class="hljs-built_in">varchar</span>(<span class="hljs-number">255</span>)</span><br><span class="line">  , birth_date     <span class="hljs-built_in">varchar</span>(<span class="hljs-number">255</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><figure class="highlight sql hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">select</span> * <span class="hljs-keyword">from</span> mst_users_with_dates;</span><br></pre></td></tr></table></figure><p>위 코드로 테이블이 잘 만들어졌는지 확인해본다.</p><p>잘 만들어졌으면, 데이터를 삽입한다.<br><figure class="highlight sql hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">INSERT</span> <span class="hljs-keyword">INTO</span> mst_users_with_dates</span><br><span class="line"><span class="hljs-keyword">VALUES</span></span><br><span class="line">    (<span class="hljs-string">'U001'</span>, <span class="hljs-string">'2016-02-28 10:00:00'</span>, <span class="hljs-string">'2000-02-29'</span>)</span><br><span class="line">  , (<span class="hljs-string">'U002'</span>, <span class="hljs-string">'2016-02-29 10:00:00'</span>, <span class="hljs-string">'2000-02-29'</span>)</span><br><span class="line">  , (<span class="hljs-string">'U003'</span>, <span class="hljs-string">'2016-03-01 10:00:00'</span>, <span class="hljs-string">'2000-02-29'</span>)</span><br><span class="line">;</span><br></pre></td></tr></table></figure></p><p>먼저 날짜 데이터들의 차이를 계산해보자. 현재 날짜와 등록한 날짜를 빼주는 방식이다.<br><figure class="highlight sql hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">select</span> user_id, <span class="hljs-keyword">CURRENT_DATE</span> <span class="hljs-keyword">AS</span> today, </span><br><span class="line"><span class="hljs-built_in">date</span>(<span class="hljs-built_in">timestamp</span>(register_stamp)) <span class="hljs-keyword">AS</span> regitser_date,</span><br><span class="line"><span class="hljs-keyword">datediff</span>(<span class="hljs-keyword">CURRENT_DATE</span>(), <span class="hljs-built_in">date</span>(register_stamp)) <span class="hljs-keyword">AS</span> diff_days</span><br><span class="line"><span class="hljs-keyword">from</span> mst_users_with_dates ;</span><br></pre></td></tr></table></figure></p><p>이렇게 만들어주면 원하는 결과가 나온다. 책에 있는 결과와 조금은 다를 수 있는데, 왜냐하면 CURRENT_DATE를 하면 현재의 날짜를 가져와 주기 때문에, 책에 있는 2017-02-05가 아니라, 지금 작성하고 있는 2019-05-21로 계산된다.</p><p>여기까지는 datediff함수가 MySQL에도 있기 때문에 책에 있는 그대로 쳐도 잘 돌아간다.</p><p>이번에는 사용자의 생년월일로 나이를 계산해보자.<br>나이를 계산하기 위한 전용함수가 구현되어 있는 것은 PostgreSQL뿐이다. PostgreSQL에는 age함수가 구현이 되어있어 편하게 나이를 구할 수 있다. MySQL의 경우에는 책에 있는 코드를 MySQL의 언어로 변형시켜 주어야 한다.</p><figure class="highlight sql hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">SELECT</span> user_id, </span><br><span class="line"><span class="hljs-keyword">CURRENT_DATE</span> <span class="hljs-keyword">AS</span> today, <span class="hljs-built_in">date</span>(register_stamp) <span class="hljs-keyword">as</span> register_date,  birth_date,</span><br><span class="line">(<span class="hljs-keyword">YEAR</span>(<span class="hljs-keyword">CURRENT_DATE</span>)-<span class="hljs-keyword">YEAR</span>(birth_date))- (<span class="hljs-keyword">RIGHT</span>(<span class="hljs-keyword">CURRENT_DATE</span>,<span class="hljs-number">5</span>)&lt;<span class="hljs-keyword">RIGHT</span>(birth_date,<span class="hljs-number">5</span>)) <span class="hljs-keyword">AS</span> age,</span><br><span class="line">(<span class="hljs-keyword">YEAR</span>(register_stamp)-<span class="hljs-keyword">YEAR</span>(birth_date))- (<span class="hljs-keyword">RIGHT</span>(register_stamp,<span class="hljs-number">5</span>)&lt;<span class="hljs-keyword">RIGHT</span>(birth_date,<span class="hljs-number">5</span>)) <span class="hljs-keyword">AS</span> register_age</span><br><span class="line"><span class="hljs-keyword">FROM</span> mst_users_with_dates;</span><br></pre></td></tr></table></figure><p>책에 있는 코드와 다른점은 EXTRACT를 사용하지 않았다는 것이다. MySQL에는 EXTRACT가 없기 때문에 년도를 이용해 일일이 계산해 주어야 한다. YEAR함수를 이용해 년도만 가져와서 계산해준다. 주의해야 할 점은, YEAR함수에 today를 넣어주는 게 아니라 CURRENT_DATE를 넣어주어야 한다는 것이다. today를 넣어주면 syntax에러가 발생한다.</p><p>하지만 YEAR로 계산한 경우 연 부분만의 차이가 계산되므로, 해당 연의 생일을 넘었는지 제대로 계산이 되지 않는 문제가 발생한다.</p><figure class="highlight sql hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">SELECT</span> user_id,</span><br><span class="line"><span class="hljs-keyword">substring</span>(register_stamp, <span class="hljs-number">1</span>, <span class="hljs-number">10</span>) <span class="hljs-keyword">as</span> register_date, birth_date,</span><br><span class="line">  <span class="hljs-keyword">floor</span>(( <span class="hljs-keyword">cast</span>(<span class="hljs-keyword">replace</span>(<span class="hljs-keyword">substring</span>(register_stamp, <span class="hljs-number">1</span>,<span class="hljs-number">10</span>), <span class="hljs-string">'-'</span>, <span class="hljs-string">''</span>) <span class="hljs-keyword">AS</span> <span class="hljs-keyword">unsigned</span>) - <span class="hljs-keyword">cast</span>(<span class="hljs-keyword">replace</span>(birth_date, <span class="hljs-string">'-'</span>, <span class="hljs-string">''</span>) <span class="hljs-keyword">AS</span> <span class="hljs-keyword">unsigned</span>))  / <span class="hljs-number">10000</span>) <span class="hljs-keyword">as</span> register_age,</span><br><span class="line">  <span class="hljs-keyword">floor</span>(( <span class="hljs-keyword">cast</span>(<span class="hljs-keyword">replace</span>(<span class="hljs-keyword">CAST</span>(<span class="hljs-keyword">CURRENT_DATE</span> <span class="hljs-keyword">as</span> signed), <span class="hljs-string">'-'</span>, <span class="hljs-string">''</span>) <span class="hljs-keyword">as</span> <span class="hljs-keyword">unsigned</span>) - <span class="hljs-keyword">cast</span>(<span class="hljs-keyword">replace</span>(birth_date, <span class="hljs-string">'-'</span>, <span class="hljs-string">''</span>) <span class="hljs-keyword">AS</span> <span class="hljs-keyword">unsigned</span>)) / <span class="hljs-number">10000</span>) <span class="hljs-keyword">as</span> current_age</span><br><span class="line"><span class="hljs-keyword">from</span> mst_users_with_dates;</span><br></pre></td></tr></table></figure><p>이 코드로 실행시켜주면 문제가 해결된다. MySQL에서는 CAST함수 실행시에 주의해야 할 점이 있는데, 보통 프로그래밍 언어에서는 Integer나 String등으로 타입을 정해주는데, MySQL에서는 UNSIGNED–&gt;INTEGER이고, SIGNED–&gt;STRING임을 명심해야 한다. 코드를 바꿔주고 실행하면 문제없이 돌아가는 것을 확인할 수 있다.</p>]]></content:encoded>
      
      <comments>http://tkdguq05.github.io/2019/05/21/SQL-Recipe-01/#disqus_thread</comments>
    </item>
    
    <item>
      <title>cross_entropy_KL_divergence</title>
      <link>http://tkdguq05.github.io/2019/05/15/cross-entropy-KL-divergence/</link>
      <guid>http://tkdguq05.github.io/2019/05/15/cross-entropy-KL-divergence/</guid>
      <pubDate>Wed, 15 May 2019 07:23:21 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Cross-Entropy와-KL-Divergence에-대해서-알아보자&quot;&gt;&lt;a href=&quot;#Cross-Entropy와-KL-Divergence에-대해서-알아보자&quot; class=&quot;headerlink&quot; title=&quot;Cross Entropy와 K
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Cross-Entropy와-KL-Divergence에-대해서-알아보자"><a href="#Cross-Entropy와-KL-Divergence에-대해서-알아보자" class="headerlink" title="Cross Entropy와 KL-Divergence에 대해서 알아보자"></a>Cross Entropy와 KL-Divergence에 대해서 알아보자</h1><h3 id="Cross-Entropy"><a href="#Cross-Entropy" class="headerlink" title="Cross Entropy"></a>Cross Entropy</h3><p>크로스 엔트로피에 대해서 알아보기 전에, 엔트로피 식을 다시한번 확인해 보자<br>엔트로피는 $H(x)=-\sum P(x)log_2P(x)$로 확률분포 $P(X)$에 대한 기댓값이다. 엔트로피는 확률분포가 있어야 정의가 될 수 있다. 확률 분포의 불확실한 정도를 뜻하는 것이라고 생각하면 된다.</p><p>이제 크로스 엔트로피 식을 확인해 보자<br>$H(P,Q)=-\sum_{X} P(x)logQ(x)$(자연로그 또는 이진로그)<br>식을 자세히 보면, $P(x)$가 들어갈 자리에 $Q(x)$가 들어가 있다. 어떤 의미가 숨어져 있는 것 같은데,</p><p>이 수식이 의미하는 것이 무엇일까?</p><p>크로스 엔트로피(Cross Entropy)는 실제 데이터는 $P$의 분포로부터 생성되지만, 분포 $Q$를 사용해서 정보량을 측정해서 나타낸 평균적 bit수를 의미한다. 이제 수식이 눈에 들어오기 시작할 것이다.</p><p><code>실제 데이터는 분포 P로 부터 생성되는데, 우리가 실제 P에 대해서 몰라서 분포 Q의 정보(or 코딩 스킴)을 대신 활용하면 어떨까?</code>에 대한 답으로써 만들어졌다고 생각하면 편할 것이다.</p><p>크로스 엔트로피는 $H(P,Q)$와 같이 나타내고 일반적으로 $H(P,Q) &gt;=H(P)$이다. 항상 크로스 엔트로피가 크거나 같을 수 밖에 없는 것은 데이터의분포를 Q로 가정한 코딩방식을 사용하게 되면, 실제의 분포 P를 가정한 코딩방식 보다 질의응답에 필요한 코드의 수(code length)가 많아지게 되기 때문이다.</p><h3 id="KL-Divergence"><a href="#KL-Divergence" class="headerlink" title="KL-Divergence"></a>KL-Divergence</h3><p>KL-Divergence는 쿨백 라이블러 발산이라고 불리기도 한다. 이 역시 수식으로 먼저 확인해 보자<br>$D_{KL}(P||Q)=\sum_{X}P(x)log {P(x)\over{Q(x)}}$이다. 이 수식을 자세히 보면, Cross entropy 식이 들어가 있는 것을 확인 할 수 있다. 좀 더 풀어서 써보면</p><p>$D_{KL}(P||Q)=\sum_{X}P(x)log{1\over Q(x)}-P(x)log{1\over P(x)}$로<br>결국 $H(P,Q) - H(P)$, 즉 P와 Q의 크로스엔트로피에서 P의 엔트로피를 빼준 식이다. 이것은 결론적으로 Q를 이용한 정보량이 P의 분포와 얼마나 차이가 나는 지를 알려주는 것이다. 일종의 분포사이의 거리로 이해를 하면 된다. (KL divergence는 두 확률 분포 P와 Q의 차이를 측정한다. 하지만 엄밀히 말해서 거리는 아니다.)</p><p>다른 표현으로 데이터 인코딩 관점에서 보면 KL divergence는 데이터 소스의 분포인 P 대신 다른 분포 Q를 사용해서 인코딩하면 추가로 몇 bit의 낭비가 생기는지 나타낸다고 이해할 수 있다.</p><p>KL-Divergence는 거리함수가 아니다. 왜냐하면 교환법칙이 성립하지 않기 때문이다. Reverse KL은 별도의 개념으로 사용된다. 하지만, 두 분포가 다를수록 큰 값을 가지며 둘이 일치할 때에만 0이 되기 때문에 거리와 비슷한 용도로 사용할 수 있다.<br>[<a href="https://wiseodd.github.io/techblog/2016/12/21/forward-reverse-kl/]" target="_blank" rel="noopener">https://wiseodd.github.io/techblog/2016/12/21/forward-reverse-kl/]</a></p><p>Cross Entropy와 KL-Divergence가 어떤 관계에 있느냐고 묻는다면, KL-Divergence의 앞쪽 수식에 크로스 엔트로피가 있으므로, 크로스 엔트로피가 작을 수록, KL-Divergence값이 작아진다. 즉, 두 분포가 가까워진다고 말할 수 있겠다.</p>]]></content:encoded>
      
      <comments>http://tkdguq05.github.io/2019/05/15/cross-entropy-KL-divergence/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Boosting</title>
      <link>http://tkdguq05.github.io/2019/05/15/Boosting/</link>
      <guid>http://tkdguq05.github.io/2019/05/15/Boosting/</guid>
      <pubDate>Wed, 15 May 2019 05:20:51 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;부스팅-기법-Boosting-에-대해-알아보자&quot;&gt;&lt;a href=&quot;#부스팅-기법-Boosting-에-대해-알아보자&quot; class=&quot;headerlink&quot; title=&quot;부스팅 기법(Boosting)에 대해 알아보자&quot;&gt;&lt;/a&gt;부스팅 기법(Boos
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="부스팅-기법-Boosting-에-대해-알아보자"><a href="#부스팅-기법-Boosting-에-대해-알아보자" class="headerlink" title="부스팅 기법(Boosting)에 대해 알아보자"></a>부스팅 기법(Boosting)에 대해 알아보자</h1><h3 id="Weak-Learner"><a href="#Weak-Learner" class="headerlink" title="Weak Learner"></a>Weak Learner</h3><p>부스팅 기법에 대해 알아보기 전에 알아야 할 몇가지 용어들이 있다. 그 중 하나가 Weak Learner이다.<br>Weak Learner는 다른 말로 Simple Learner이라고도 불리우며, 간단한 학습기 정도로 보면 될 것이다. </p><p>대표적인 Weak Learner는 다음과 같다.</p><ul><li>Decision stumps : depth가 1인 decision tree</li><li>Shallow decision trees</li><li>Naïve Bayes</li><li>Logistic regression</li></ul><p>우리는 Weak Learner를 많이 가질 것이고, 많은 학습기들을 이용해서 예측작업을 할 것이다.<br>Weak Learner들의 앙상블을 통해 어떤 결과를 예측해보려는 것이다. 이렇게 다수의 Weak Learner들을 이용해서 학습하면, input space의 다른 부분들을 보완해줄 수 있다.</p><p>부스팅에 대해서 공부할 때 배깅이 자주 등장하는데 차이를 비교해보자면 다음과 같다.</p><blockquote><p>Bagging</p><ul><li>훈련 데이터에서 다수의 표본을 추출하고, 개별 트리의 결과를 병합하여 단일 예측 모델을 생성</li><li>각 bootstrap 과정이 독립적이므로 병렬 처리가 가능</li></ul></blockquote><blockquote><p>Boosting</p><ul><li>Bagging과는 달리 순차적으로 시행되며 bootstrap 과정이 없음</li><li>Original dataset에서 약간의 수정을 거친 데이터를 개별적으로 학습한 후, 결합되어 강력한 분류기 생성</li></ul></blockquote><p>부스팅의 아이디어는 간단하다. 약한 학습기들을 이용해서 학습된 학습기들을 결합해 strong learner를 만드는 것이다. Classifier의 경우 학습기들의 결합방법은 Majority voting방식이 될 것이고, Regressor의 경우 학습기들의 결합방법은 평균이 될 것이다.</p><p>부스팅의 알고리즘도 심플하다. 앙상블 내, $t$번째 분류기 $c_t$와 $t+1$번째 분류기 $c_{t+1}$이 연관성을 가지고 생성하는 것이다.</p><ol><li>훈련데이터 X의 샘플을 $c_t$가 옳게 분류하는 것과, 그렇지 않은 것으로 나눈다.</li><li>옳게 분류하는 샘플들은 인식이 가능하므로 가중치를 낮춘다.</li><li>틀리게 분류하는 샘플들은 가중치를 높인다.</li><li>$c_{t+1}$학습시키기 위한 정책으로 sampling과정에서 가중치가 높은 샘플이 뽑힐 확률이 높아지게 한다.</li></ol><h3 id="Ada-Boost-Adaptive-Boosting"><a href="#Ada-Boost-Adaptive-Boosting" class="headerlink" title="Ada Boost(Adaptive Boosting)"></a>Ada Boost(Adaptive Boosting)</h3><p>Yoav Freund &amp; Robert Schapire가 제안하였고, Weak learner를 반복적으로 사용하고, 그 결과를 합하여 모델의 accuracy를 향상시킨다.</p><p>AdaBoosting은 위에서 살펴본 알고리즘이 작동하는 방식과 거의 비슷하게 동작한다.</p><p>그림과 함께 살펴보자<br><img src="/images/adaboost.png" alt="Ada Boosting의 작동원리"><br>첫번째 그림에서 약한 학습기인, 결정 그루터기가 하나의 결정경계를 가지고 +와 -를 나누고 있다. 이렇게 나눴을 때 위쪽의 3개의 +들은 잘못 분류가 되어 가중치가 높아진다. 두번째 그림에서는 오른쪽의 - 두 개만 잘 분류가 되었고 결정경계 왼쪽의 대개의 -들은 잘못 분류가 되어버렸다. 이 역시 가중치가 높아지고 학습된 3개의 Weight를 결합해서 + -를 잘 분류해내는 하나의 강 분류기를 만들어낸다. 결국 Weak Learner들의 앙상블이다.</p><p>가중치 업데이트 규칙은 다음과 같다.<br>$w^{(i)} = w^{(i)}$, $\hat{y_j}{(i)}= y_{(i)}$ 일때<br>$w^{(i)} = w^{(i)}exp(\alpha_j)$, $\hat{y_j}{(i)}\neq y_{(i)}$ 일때<br>그런 다음 모든 샘플의 가중치를 정규화 한다.(즉, $\sum_{i}^{m}w^{(i)}$로 나눠준다.)</p><p>마지막으로 새 예측기가 업데이트된 가중치를 사용해 훈련되고 전체 과정이 반복된다. 새 예측기의 가중치가 계산되고 샘플의 가중치를 업데이트해서 또 다른 예측기를 훈련시키는 방식이다.</p><p>Adaboost는 지정된 예측기 수에 도달하거나 완벽한 예측기가 만들어지면 중지된다.</p><p>Adaboost의 예측은 $\hat{y}(x)=\sum_{i=1}^{N}\alpha_j$로 이루어진다.($N$은 예측기의 수)</p><h3 id="Gradient-Boosting"><a href="#Gradient-Boosting" class="headerlink" title="Gradient Boosting"></a>Gradient Boosting</h3><p>그래디언트 부스팅은 Ada부스팅처럼 이전까지의 오차를 보정하도록 예측기를 순차적으로 추가한다. 하지만 Ada처럼 반복마다 샘플의 가중치를 수정하는 대신 이전 예측기가 만든 잔여 오차(residual error)에 새로운 예측기를 학습시킨다. 다시말해서 약한 분류기가 이전 학습에서 발견하기 어려웠던 문제성 관측값, 즉, 예측이 틀린 관측값에 집중하게 하는 것이다.</p><p>다른 boosting 기법처럼 모델을 단계적으로 구축해 나가는 것은 같지만 임의의 미분 가능한 손실 함수를 최<br>적화하는 문제로 일반화한 방법이다. GB는 여러개의 간단한 모델의 ensemble을 학습한다.</p><blockquote><h4 id="Motivation-of-Gradient-Boosting"><a href="#Motivation-of-Gradient-Boosting" class="headerlink" title="Motivation of Gradient Boosting"></a>Motivation of Gradient Boosting</h4><p>($x_1$,$y_1$),($x_2$,$y_2$) …, ($x_n$,$y_n$) 총 n개의 데이터가 있고, 이 데이터를 이용하여 회귀모형 $F(x)$ 를 학습하는 프로젝트를 진행한다고 생각해보자. 팀원이 모델 $F$를 만들었다. 하지만 성능이 그다지 좋지 않다. $F(x_1)$ = 0.8의<br>예측값을 생성한다. 하지만 실제 $y_1$ = 0.9이다. $y_2$ = 1.3인데, $F(x_2)$ = 1.4의 값이 나온다. 이 모델의 성능을<br>향상시켜야 하는데 한가지 제약조건이 있다. 팀원이 만든 모델 $F$는 절대 건드리지 않고, 모델을 향상시켜야<br>한다. 어떤 방법이 있을까?</p></blockquote><p>방법은 간단하다. 원래 모델은 그냥 두고, 차이만큼을 더해주는 함수 $h(x)$를 만들어주면 되는 것이다.<br>완벽하게 우리의 목적을 달성시키지는 못하지만, 근사적으로 달성할수는 있다.</p><p>그렇다면$h(x)$는 어떻게 구할 수 있을까?<br>$h(x_1) = y_1 - F(x_1)$<br>$h(x_2) = y_2 - F(x_2)$<br>$…$<br>$h(x_n) = y_n - F(x_n)$ 이므로,$(x1, y_1-F(x_1))$, $(x2, y_2-F(x_2))$,$…,$,$(x_n, y_n-F(x_n))$을 학습하면 된다.</p><p>학습데이터를 이용하여 75%정도의 정확도까지 모델을 학습하고, 나머지 미설명 부분은 오차항에 남겨둔다.<br>$Y = F(x) + E$<br>오차항을 이용하여 다른 모델을 학습시킨 후, 그 전 모델에서는 미설명 부분이었으나 이번 학습에서는 설명<br>이 되는 부분을 찾아내 원 모델에 추가한다. 단, 추가 모델은 반드시 전체 정확도를 향상시켜야만 한다.<br>$Gradeint(E) = G(x) + E2$</p><p>모델이 약 80%의 정확도를 갖게 되면 식은 다음과 같게 된다.<br>$Y + F(x) + G(x) + E2$</p><p>이런 방법을 계속해서 사용해 나가고, GB는 단순 합보다 가중 평균을 사용하여(다른 모델보다 정확도가 높은 예측 결과를 가진 모델에 더 높은 중요도 점수를 부여) 모델의 정확도를 더 개선할 수 있다<br>$Y=\alpha{F(x)}+\beta{G(x)}+\gamma{H(x)} + E$ $…$</p><h3 id="Gradient-Boosting의-Loss-Function"><a href="#Gradient-Boosting의-Loss-Function" class="headerlink" title="Gradient Boosting의 Loss Function"></a>Gradient Boosting의 Loss Function</h3><p>손실 함수는 해결하려는 문제에 따라 다르다. 부스팅에서는 처음부터 최적화를 하는 것이 아니라, 각 단계별로 이전 단계에서 설명되지 못한 손실에 관해 최적화를 수행한다.</p><ul><li>회귀 문제 : Least squares method (최소 자승법)</li><li>분류 문제 : Log loss function (로그 손실 함수)</li></ul><p>손실 함수를 최소화하기 위해 약한 분류기를 추가할 가법 모델(additive model)</p><ul><li>기존 트리는 변동이 없고 새로운 트리가 하나씩 추가된다.</li><li>기울기 하강 절차가 사용되어 트리가 추가될 때의 손실을 최소화한다.</li></ul><p>Leaf node마다 가중치, score가 부여가 된다. Gini계수 등을 사용하지 않는다.<br>분류 / 회귀 : Sklearn에서는 (friedman) mse를 사용한다.</p>]]></content:encoded>
      
      <comments>http://tkdguq05.github.io/2019/05/15/Boosting/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Information_Theroy_Entropy</title>
      <link>http://tkdguq05.github.io/2019/05/14/Information-Theroy-Entropy/</link>
      <guid>http://tkdguq05.github.io/2019/05/14/Information-Theroy-Entropy/</guid>
      <pubDate>Tue, 14 May 2019 07:28:58 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;정보이론-기초-정보량-Information-과-엔트로피-Entropy-에-대해-알아보자&quot;&gt;&lt;a href=&quot;#정보이론-기초-정보량-Information-과-엔트로피-Entropy-에-대해-알아보자&quot; class=&quot;headerlink&quot; tit
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="정보이론-기초-정보량-Information-과-엔트로피-Entropy-에-대해-알아보자"><a href="#정보이론-기초-정보량-Information-과-엔트로피-Entropy-에-대해-알아보자" class="headerlink" title="정보이론 기초, 정보량(Information)과 엔트로피(Entropy)에 대해 알아보자"></a>정보이론 기초, 정보량(Information)과 엔트로피(Entropy)에 대해 알아보자</h1><h2 id="정보량-Information"><a href="#정보량-Information" class="headerlink" title="정보량 (Information)"></a>정보량 (Information)</h2><p>정보량은 말 그대로 얼마나 정보를 갖고 있는 지를 뜻하는 말이고 정보이론이란 불확실성을 다루는 학문이다. 하지만 일상에서 정보량에 대해서 접하기는 상당히 힘들고, 정보량이라는 단어를 일상에서 사용하는 사람은 매우 드물다.</p><p>알기 쉬운 예를 들어보자.</p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">간만에 친구들과 약속을 잡아서 놀기로 했다. 12일 13일 14일 15일 중으로 날짜를 잡기로 했고</span><br><span class="line">카카오톡 투표를 통해서 가장 많이 나온 날짜를 약속날로 잡자고 했다.</span><br></pre></td></tr></table></figure><p>흔히 있는 상황이다. 약속날 후보로 5월 12일 13일 14일 15일이 있다고 해보자. 총 4개의 옵션이 있는 것이다. 근데 투표를 만든 사람이 자비롭게 중복투표를 허용해놨고, ‘음 난 다좋은데~’라고 생각하는 주관없는 친구가 모든 날짜를 다 눌러놨다고 생각해보자.</p><p>이 친구의 투표가 가진 정보량은 얼마일까?<br>직관적으로 생각했을 때 0이다. 하지만 <code>수학적으로</code> 왜 그런 것일까?</p><p>정보량의 공식을 보자.<br>정보량  $h(x) = \sum_{x}log_2p(x)$ 이다.</p><p>이 공식을 토대로 주관없는 친구의 5월 12일 날짜에 대한 정보량을 구해보면,<br>$p(x) = 1$이므로, $log_21 = 0$이란 값이 나온다.<br>13일, 14일, 15일 모두 같은 결과가 나오고, 주관없는 친구의 투표에 대한 정보량은 0이다.</p><p><del>어떻게 보면 어떤 사람의 주관은 일정의 정보량을 뜻하는 듯하다. 아무거나 빌런은 결국 어떤 정보도 갖고 있지 않다는 것이다.</del> </p><p>정보량은 여기서 주관을 뜻하기도 하지만, 보통 정보량은 놀라움의 정도를 뜻한다.<br>축구 경기중에 골키퍼가 골을 넣는 사건은 굉장히 놀랍다. 이는 굉장히 정보량이 많다는 것을 뜻한다.<br>왜냐면 정보량은 확률에 반비례하기 때문이다.<br><img src="/images/info.png" alt="Information with Probability"></p><p>이번에는 예를 바꿔서, 우리가 쉽게 알 수 있는 주사위 case를 갖고 와 보자.<br>주사위를 던져서 짝수가 나타날 사상 $E_1$의 정보량은 몇일까?<br>공식에 의해서 $p(x) = {1\over2}$이므로<br>$P(E_1) = {1\over2}\longrightarrow I = -log_2{1\over2}=1(bit)$ 가 된다.</p><h2 id="엔트로피-Entropy"><a href="#엔트로피-Entropy" class="headerlink" title="엔트로피(Entropy)"></a>엔트로피(Entropy)</h2><p>엔트로피는 흔히 열역학에서 자주 볼 수 있는 단어지만, 정보이론에서도 사용되는 말이기도 하다. 엔트로피라는 말에 대해서는 정보이론의 아버지인 Shannon이 정립하였다.</p><p>엔트로피의 공식을 먼저 확인해보자.<br>$H(X) = -\sum_{X}P(X)log_2P(X)$이다.</p><p>확률과 통계를 기본부터 잘 다져온 사람이라면 익숙한 공식이 눈에 들어올 것이다.<br>바로 기댓값이다. 수식을 그럼 천천히 다시봤을때, 엔트로피 공식이 뜻하는 것은 바로 확률분포 $P(X)$에 대한 기댓값이다. 확률분포가 있어야 정의가 될 수 있다. 확률 분포의 불확실한 정도를 뜻하는 것이라고 생각하면 된다.</p><p>엔트로피는 정보이론에서 사용되는 단어이므로, 이 역시 불확실도를 나타내는 척도로 사용된다.<br>직관적으로 이해하기 위해 그림을 통해 살펴보자.</p><p><img src="/images/entropy.png" alt="Entropy Distribution"></p><p>위 그림에서 보면 왼쪽의 분포는 몰려있고, 즉 정규분포로 따지자면 표본오차가 작은 모양이고, 오른쪽의 분포는 넓게 퍼진, 표본오차가 매우 큰 모습이다. 정보이론을 따라 분포를 다시 보면 왼쪽의 그림은 불균형한 분포로 불확실성이 적은 모양이다. 다시말해 엔트로피 값이 낮은 분포이다. 반면에 오른쪽 그림은 균등한 분포이며, 어떤 값이 나올지 모르는, 불확실성이 높은 모양이다. 즉, 엔트로피 값이 높은 분포라고 할 수 있다.</p><p>결론적으로, 엔트로피는 확률분포 P(X)에서 일어날 수 있는 모든 사건들의 정보량의 기댓값으로, P(X)의 불확실성 정도를 평가하는 척도로 사용된다.</p><p>엔트로피와 관련된 것으로 크로스 엔트로피(Cross-Entropy)가 있는데, 이것은 다음 포스트에 적도록 하겠다.</p><p>P.S 다시 엔트로피와 크로스 엔트로피에 대해 공부한 이유는, 면접을 최근에 보게 되었는데 이 부분에 대해서 제대로 공부를 하지 못해 대답을 우물쭈물 했기 때문이다. 데이터 사이언스를 공부하면서 느끼는 것은 항상 이런 것이다. 내가 진짜 알고있는지 아닌지 확인하기 어렵다는 것이다. 최대한 많이 부딪혀 봐야겠다. 그것이 캐글이 되었든, 아니면 면접이 되었든, 실제로 일을 하는 것이든, 직접 경험해 봐야 많이 필요성을 느낄 수 있고 많이 배울 수 있게 되는 것 같다.</p>]]></content:encoded>
      
      <comments>http://tkdguq05.github.io/2019/05/14/Information-Theroy-Entropy/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Ensemble_Model</title>
      <link>http://tkdguq05.github.io/2019/05/05/Ensemble-Model/</link>
      <guid>http://tkdguq05.github.io/2019/05/05/Ensemble-Model/</guid>
      <pubDate>Sun, 05 May 2019 07:19:05 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Ensemble에-대해-자세히-알아보자-Bagging-Bootstrap-그리고-RandomForest&quot;&gt;&lt;a href=&quot;#Ensemble에-대해-자세히-알아보자-Bagging-Bootstrap-그리고-RandomForest&quot; class=
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Ensemble에-대해-자세히-알아보자-Bagging-Bootstrap-그리고-RandomForest"><a href="#Ensemble에-대해-자세히-알아보자-Bagging-Bootstrap-그리고-RandomForest" class="headerlink" title="Ensemble에 대해 자세히 알아보자 (Bagging, Bootstrap, 그리고 RandomForest)"></a>Ensemble에 대해 자세히 알아보자 (Bagging, Bootstrap, 그리고 RandomForest)</h1><p>앙상블 모델에 대해서 공부하기 전에, 그 배경부터 알아볼 필요가 있다.</p><h3 id="NFL-No-Free-Lunch"><a href="#NFL-No-Free-Lunch" class="headerlink" title="NFL (No Free Lunch)"></a>NFL (No Free Lunch)</h3><p>No Free Lunch 이론은 David H. Wolpert가 정리한 이론으로 모든 문제에 대해 다른 모든 알고리즘을 능가하는 모델은 없다는 이론이다. ‘어떤 특정 정책에 의해 얼핏 보면 이득을 얻는 것 같지만, 그것은 한 측면의 이득일 뿐이고 반드시 이면에 다른 측면이 있고 그 측면에서 손해가 발생한다.’는 것이 핵심이다.</p><p>이 이론에 따라서 혼성모델의 필요성이 대두되었다. 혼성모델이란 여러 알고리즘을 결합하는 모델이다. 이 모델은 특정 문제가 주어진 상황에서 그 문제를 가장 높은 성능으로 풀 수 있는 알고리즘에 대한 필요성에 의해서 제시되었다.</p><h3 id="Resampling"><a href="#Resampling" class="headerlink" title="Resampling"></a>Resampling</h3><p>리샘플링은 데이터가 부족할 때 같은 샘플을 여러번 사용하는 것을 말한다. 성능 통계치의 신뢰도를 높이기 위해 사용된다. Resample을 하는 이유는 다음과 같다.</p><ul><li>실제 상황에서는 만족할 만한 큰 샘플을 얻기가 힘들다.</li><li>Bias-Variance Trade off를 통해 큰 샘플이 중요하다는 것을 알 수 있다.<ul><li>sample의 집합이 커지면 variance가 감소한다!, MSE도 감소한다!</li></ul></li><li>모델의 선택은 별도의 검증이 필요하다.(검증용 데이터, 큰 샘플의 필요성)</li></ul><h3 id="Bootstrap-Statistical-term-for-“roll-n-face-dice-n-times”"><a href="#Bootstrap-Statistical-term-for-“roll-n-face-dice-n-times”" class="headerlink" title="Bootstrap, Statistical term for “roll n-face dice n times”"></a>Bootstrap, Statistical term for “roll n-face dice n times”</h3><p>부트스트랩은 Resampling을 이용하여, 분류기의 성능을 측정하는 방법 중 하나이다. 통계에서는 추정치에 대한 검증용(가설 검증)으로 많이 사용된다. 부트스트랩의 장점은 한번도 뽑히지 않은 데이터가 발생한다는 것이다. 이를 통해 데이터를 아낄 수 있게 된다.</p><h3 id="Ensemble"><a href="#Ensemble" class="headerlink" title="Ensemble"></a>Ensemble</h3><p>앙상블 모델은 혼성모델 중 하나이다. 앙상블은 두가지 방식이 존재한다.</p><ul><li>같은 문제에 대해 서로 다른 여러 알고리즘이 해를 구하고, 결합 알고리즘이 그들을 결합하여 최종 해를 만드는 방식</li><li>문제와 유사한 여러 하위 문제들에 대해 하나의 알고리즘이 해를 구하고, 결합 알고리즘이 그들을 결합하여 최종 해를 만드는 방식</li></ul><p>앙상블의 동기는 단순히 통계적, 수학적일 뿐만 아니라, 사람들의 심리 등 여러부분을 관통하는 내용이기도 하다.<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">어느 도시에서는 소를 광장에 매어 놓고 참가자들에게 체중을 추정하여 적어 내게 하고 실제 체중에 가장 가까운 사람에게</span><br><span class="line">상품을 주는 대회가 있다고 한다. 수백 명이 참가하는데 그들이 적어낸 숫자들을 평균해 보면 답과 아주 근사하다고 한다.</span><br></pre></td></tr></table></figure></p><p>사람들은 중요한 결정을 할때 여러 사람의 의견을 들어보고 결정하려는 경향이 있고, 이런 경향은, 통계학이 아닌 다른 분야에서도 사용되는 개념이다.</p><blockquote><h4 id="다양성"><a href="#다양성" class="headerlink" title="다양성"></a>다양성</h4><p>앙상블 모델의 핵심은 다양성이다. 앙상블에 참여한 모델이 모두 같은 결과를 낸다면, 그것은 앙상블 모델로써 어떠한 장점도 갖고 있지 않다. 한 분류기가 틀리는 어떤 문제를, 다른 분류기에서는 맞출 수 있어야 앙상블 모델로써 가치가 있을 것이다. </p></blockquote><p>앙상블 분류기 시스템은 앙상블 생성, 앙상블 선택, 앙상블 결합의 단계를 거친다.</p><blockquote><h4 id="앙상블-생성"><a href="#앙상블-생성" class="headerlink" title="앙상블 생성"></a>앙상블 생성</h4><ul><li>Resample을 이용해서 (Bagging, Bootstrap) 샘플 집합들을 생성하고, 분류기를 훈련한다.</li><li>Feature Vector의 subspace를 이용해서 샘플 부분 집합을 생성하고 분류기를 훈련한다.</li><li>앙상블의 분류기는 요소분류기와 기초분류기로 구분된다.</li></ul></blockquote><blockquote><h4 id="앙상블-결합"><a href="#앙상블-결합" class="headerlink" title="앙상블 결합"></a>앙상블 결합</h4><p>요소 분류기(기초 학습기)들의 출력을 결합하여 하나의 분류 결과를 만드는 과정이다.<br>요소 분류기의 출력은 세가지의 방식으로 나뉜다.</p><ul><li>Class Label<ul><li>Majority Vote : class 라벨이 많이 나온 쪽으로 분류한다.</li><li>Weighted Majority Vote : 성능 좋은 분류기에 가중치를 부여한다.(Adaboost)</li><li>Behavior knowledge space(BKS/행위지식공간) : 경험한 케이스를 테이블로 갖고 분류기 결과를 보고 경험적으로 결정한다(테이블에서 찾아서). 다수결 방법의 성능을 고도화 할때 사용됨</li></ul></li><li>Class Ranking <ul><li>Borda 계수</li></ul></li><li>Class Probability<ul><li>Softmax</li></ul></li></ul></blockquote><h3 id="Bagging-Bootstrap-Aggregating"><a href="#Bagging-Bootstrap-Aggregating" class="headerlink" title="Bagging (Bootstrap + Aggregating)"></a>Bagging (Bootstrap + Aggregating)</h3><p>부트스트랩을 다중 분류기 생성 기법으로 확장한 것이다. 부트스트랩 된 샘플 집합에서 훈련을 하고, 입력 값에 대해 분류기들의 평균값이나, 다수결 투표를 취한다. 샘플링은 복원추출하는 방식으로 하고, 훈련된 분류기의 결과를 모두 종합하기 때문에 Bagging이라고 부른다.</p><ul><li>반복적인 복원 추출 (Bootstrap)</li><li>결과를 모두 종합 (Aggregation)</li></ul><h4 id="Bagging-배깅은-언제-사용할까"><a href="#Bagging-배깅은-언제-사용할까" class="headerlink" title="Bagging, 배깅은 언제 사용할까?"></a>Bagging, 배깅은 언제 사용할까?</h4><p>배깅은 편향이 작고 분산이 높은 모델에 사용하면 효과적이다. </p><ul><li>트리 분류기와 같이 불안정성을 보이는 분류기에 큰 효과를 발휘</li><li>훈련 집합이 달라지면 차이가 큰 트리가 생성 ⇒ 다양성 확보</li><li>Bias를 변화시키지 않고 variance를 감소시킨다.(Bias를 쪼오오오오끔 희생한다.)</li></ul><p>배깅은 분산을 감소시키기 위해, 훈련데이터에서 많은 샘플링을 하고(Bootstrap), 샘플들로 별도의 Decision Tree를 구성한 후, 회귀나 분류문제를 푸는데 사용된다. 회귀는 분류기 결과의 평균값을 사용하고, 분류는 최빈값을 취한다.</p><p>배깅은 이미 저분산 모델인 경우 별로 효과가 없다. Bias-Variance Tradeoff 를조금만 생각해보자. 분산이 이미 줄어있는 상태에서는 더 줄일 분산이 없다. 배깅은 오직 분산을 줄이는 데 효과적이다.</p><h3 id="Out-of-Bag-OOB-Error-Estimation"><a href="#Out-of-Bag-OOB-Error-Estimation" class="headerlink" title="Out-of-Bag (OOB) Error Estimation"></a>Out-of-Bag (OOB) Error Estimation</h3><p>샘플에 대해 Bootstrap을 하게 되면 부트스트랩 샘플은 전체 훈련데이터의 약 63.2%를 차지하게 된다.(왜 그러한가에 답은 $\lim_{n\to\infty} (1-{1\over n})^n$을 풀면 답이 나온다. $1\over e$로 0.378이 나온다. 자세한 내용은 링크를 참조하면 된다. [<a href="https://www.quora.com/Why-is-the-limit-1-frac-1-n-n-equal-to-frac-1-e]" target="_blank" rel="noopener">https://www.quora.com/Why-is-the-limit-1-frac-1-n-n-equal-to-frac-1-e]</a>)</p><p>부트스트랩되지 않은 샘플들은 한번도 사용되지 않은 샘플들로 검증데이터에 활용할 수 있다. 이런 training observations은 out-of-bag observations이라고 불린다.</p><h4 id="OOB-estimate-of-test-error"><a href="#OOB-estimate-of-test-error" class="headerlink" title="OOB estimate of test error"></a>OOB estimate of test error</h4><ul><li>부트스트랩 샘플을 이용하여 개별 학습기를 학습한 후, OOB에 속하는 샘플들에 대한 예측값을 모두 구한다.</li><li>OOB의 실제 라벨값과 OOB의 예측값을 이용하여 OOB error를  구한다.</li><li>모든 부트스트랩 샘플 sets에 대하여 위의 과정을 반복하면, 샘플 sets 수 만큼의, errors를 모을 수 있다.</li><li>OOB errors의 평균값을 이용하여 bagging 모델의 최종 테스트 error를 계산한다.</li></ul><h3 id="Weakness-of-Bagging"><a href="#Weakness-of-Bagging" class="headerlink" title="Weakness of Bagging"></a>Weakness of Bagging</h3><p>배깅은 엄청나게 효과적인 것처럼 보이지만 약점이 존재한다. 배깅은 feature를 모두 사용하고, row를 랜덤하게 선택하는 것이다. Decision Tree를 만든다고 해보자, 만약 영향력이 높은, Information Gain이 높은 모델을 사용한다고 했을때, 특정 Feature만 계속 선택되서 트리가 만들어질 가능성이 있다. 즉, 중요한 칼럼들이 트리의 초기 분기때 모든 표본에 그대로 존재하게 된다. 이렇게 되면 만들어진 대다수의 트리들의 결과가 비슷해진다. 이것이 반복되면 트리간의 상관관계가 발생해서 분산 감소의 효과가 줄어들게 된다.<br>(배깅의 약점은 IID condition이다. IID 조건을 만족하는 경우 분산은 $Var={\sigma^2\over n}$이 되지만, IID를 만족하지 못하는 경우, 상관관계가 발생하여 $Corr = p$이라고 할때, $Var = p\sigma^2$가 된다.)</p><p>그래서 혁신적인 아이디어와 함께 등장하게 된 것이 Random Forest이다.</p><h3 id="Random-Forest"><a href="#Random-Forest" class="headerlink" title="Random Forest"></a>Random Forest</h3><p>랜덤 포레스트는 일반적으로 bagging 방법(또는 pasting)을 적용한 결정 트리의 앙상블이다.<br>랜덤 포레스트 알고리즘은 트리의 노드를 분할할 때 전체 특성 중에서 최선의 특성을 찾는 대신 무작위로 선택한 특성 후보 중에서 최적의 특성을 찾는 식으로 무작위성을 더 주입한다. 트리를 더욱 다양하게 생성하고 (트리의 의존성을 낮추고, 다양성을 증가) 편향을 손해 보는 대신 분산을 낮추어 전체적으로 더 훌륭한 모델을 생성한다.</p><p>Random Forest는 쉽게 말해 Tree 모델에 Bagging과 Subsampling기법을 사용한 모델이다.<br>훈련 데이터에서 bootstrap 샘플을 뽑아내고, 노드 분기 시, 모든 Feature가 아니라, 일정 Feature만 사용하는 것이 특징이다. 이를 통해 Tree간의 Correlation을 줄이고, 분산을 감소시킬 수 있다.</p><blockquote><h4 id="Subspace-Sampling"><a href="#Subspace-Sampling" class="headerlink" title="Subspace Sampling"></a>Subspace Sampling</h4><p>샘플링 시에는 일반적으로 전체 변수가 p라고 할 때, $m = \sqrt{p}$를 사용한다.<br>(m = p이면 Bagging이다. 또한 회귀에서는 경험적으로 $m ={p\over3}$를 사용한다.)</p></blockquote><blockquote><h4 id="Random-Forest-모델의-장단점"><a href="#Random-Forest-모델의-장단점" class="headerlink" title="Random Forest 모델의 장단점?"></a>Random Forest 모델의 장단점?</h4><p>장점 : 굉장히 간편하다. 스케일링도 필요없고 파라미터 튜닝을 많이 안해도 성능이 뛰어나다. 의사결정의 트리의와 배깅의 단점은 극복하고 장점만을 가져온 것이라고 할 수 있다.</p></blockquote><p>단점 : 차원이 높고 매우 희소한 데이터에서는 잘 작동하지 않는다. 이런 희소한 데이터에는 선형 모델이 더 적합할 수 있다.</p>]]></content:encoded>
      
      <comments>http://tkdguq05.github.io/2019/05/05/Ensemble-Model/#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
